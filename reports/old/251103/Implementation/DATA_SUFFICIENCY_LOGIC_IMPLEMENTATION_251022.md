# ë°ì´í„° ì¶©ë¶„ì„± íŒë‹¨ ë¡œì§ êµ¬í˜„ ë°©ì•ˆ ë¶„ì„ ë³´ê³ ì„œ

**ì‘ì„±ì¼**: 2025-10-22
**ë²„ì „**: 1.0
**ë¶„ì„ ëŒ€ìƒ**: LangGraph 0.6 Multi-Agent ì‹œìŠ¤í…œ ë°ì´í„° ì¶©ë¶„ì„± íŒë‹¨ ë¡œì§
**í•µì‹¬ ì§ˆë¬¸**: Supervisor ë ˆë²¨ vs Execute Node ë ˆë²¨ ì¤‘ ì–´ë””ì— êµ¬í˜„í•˜ëŠ” ê²ƒì´ ìµœì ì¸ê°€?

---

## ğŸ“‹ ëª©ì°¨

1. [Executive Summary](#executive-summary)
2. [í˜„ì¬ ì‹œìŠ¤í…œ êµ¬ì¡° ë¶„ì„](#í˜„ì¬-ì‹œìŠ¤í…œ-êµ¬ì¡°-ë¶„ì„)
3. [ì ‘ê·¼ ë°©ì‹ 1: Supervisor ë ˆë²¨ êµ¬í˜„](#ì ‘ê·¼-ë°©ì‹-1-supervisor-ë ˆë²¨-êµ¬í˜„)
4. [ì ‘ê·¼ ë°©ì‹ 2: Execute Node ê³ ë„í™”](#ì ‘ê·¼-ë°©ì‹-2-execute-node-ê³ ë„í™”)
5. [ë¹„êµ ë¶„ì„ ë° ê¶Œì¥ì‚¬í•­](#ë¹„êµ-ë¶„ì„-ë°-ê¶Œì¥ì‚¬í•­)
6. [ë‹¨ê³„ë³„ êµ¬í˜„ ê°€ì´ë“œ](#ë‹¨ê³„ë³„-êµ¬í˜„-ê°€ì´ë“œ)
7. [ê²°ë¡ ](#ê²°ë¡ )

---

## 1. Executive Summary

### í•µì‹¬ ë°œê²¬ì‚¬í•­

**âœ… ìµœì  í•´ë‹µ: Hybrid ì ‘ê·¼ (Supervisor + Execute Node ë¶„ë‹´)**

ë°ì´í„° ì¶©ë¶„ì„± íŒë‹¨ ë¡œì§ì„ **ë‹¨ì¼ ì§€ì ì— ì§‘ì¤‘**ì‹œí‚¤ëŠ” ê²ƒë³´ë‹¤, **Supervisorì™€ Execute Node ì–‘ìª½ì— ë¶„ë‹´**í•˜ëŠ” ê²ƒì´ ê°€ì¥ íš¨ê³¼ì ì…ë‹ˆë‹¤.

### ê¶Œì¥ ì•„í‚¤í…ì²˜

```
Planning Node (Supervisor)
    â”œâ”€â”€ Intent ë¶„ì„
    â”œâ”€â”€ Chat History ë¡œë“œ
    â””â”€â”€ ğŸ†• ë°ì´í„° ì¶©ë¶„ì„± 1ì°¨ íŒë‹¨ (LLM)
        â”œâ”€â”€ "ì´ì „ ë°ì´í„°ë¡œ ì¶©ë¶„" â†’ SearchTeam ì œì™¸
        â”œâ”€â”€ "ìƒˆ ê²€ìƒ‰ í•„ìš”" â†’ SearchTeam í¬í•¨
        â””â”€â”€ "ë¶ˆí™•ì‹¤" â†’ SearchTeam í¬í•¨ (ì•ˆì „)

Execute Teams Node (Supervisor)
    â””â”€â”€ ğŸ†• SearchExecutor ì‹¤í–‰ ì „ 2ì°¨ ê²€ì¦
        â”œâ”€â”€ Checkpointingì—ì„œ ì´ì „ ë°ì´í„° ë¡œë“œ
        â”œâ”€â”€ ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬ (ì‹ ì„ ë„, ì™„ì „ì„±)
        â””â”€â”€ ì¡°ê±´ ì¶©ì¡± ì‹œ SearchTeam ê±´ë„ˆë›°ê¸°

SearchExecutor (Execute Node)
    â””â”€â”€ ğŸ†• prepare_search_node ë‚´ë¶€ 3ì°¨ ê²€ì¦
        â”œâ”€â”€ input_data í™•ì¸
        â”œâ”€â”€ search_scope ì¬í‰ê°€
        â””â”€â”€ ì‹¤ì œ ê²€ìƒ‰ ê±´ë„ˆë›°ê¸° ê²°ì •
```

### ë¹„êµ í‘œ

| í•­ëª© | Supervisor ë ˆë²¨ | Execute Node ë ˆë²¨ | **Hybrid (ê¶Œì¥)** |
|------|----------------|------------------|------------------|
| **êµ¬í˜„ ìœ„ì¹˜** | `planning_node` | `prepare_search_node` | ì–‘ìª½ ëª¨ë‘ |
| **íŒë‹¨ ì‹œì ** | ê³„íš ìˆ˜ë¦½ ì‹œ | ì‹¤í–‰ ì§ì „ | ê³„íš + ì‹¤í–‰ |
| **ì ‘ê·¼ ê°€ëŠ¥ ë°ì´í„°** | Chat History, Long-term Memory | Checkpointing, ì´ì „ íŒ€ ê²°ê³¼ | ëª¨ë“  ë°ì´í„° |
| **ë³µì¡ë„** | â­â­â­ ì¤‘ê°„ | â­â­ ë‚®ìŒ | â­â­â­â­ ë†’ìŒ |
| **ì •í™•ë„** | â­â­â­ ì¤‘ê°„ | â­â­ ë‚®ìŒ | â­â­â­â­â­ ë§¤ìš° ë†’ìŒ |
| **ìœ ì—°ì„±** | â­â­ ë‚®ìŒ | â­â­â­â­ ë†’ìŒ | â­â­â­â­â­ ë§¤ìš° ë†’ìŒ |
| **ì„±ëŠ¥ ì˜í–¥** | âœ… ì¡°ê¸° ì¢…ë£Œ ê°€ëŠ¥ | âš ï¸ ëŠ¦ì€ ì¢…ë£Œ | âœ… ìµœì  |
| **ìœ ì§€ë³´ìˆ˜ì„±** | â­â­â­ ì¤‘ê°„ | â­â­â­â­ ë†’ìŒ | â­â­â­ ì¤‘ê°„ |

### ê¶Œì¥ì‚¬í•­ ìš”ì•½

1. **Phase 1 (1ì£¼)**: Supervisor ë ˆë²¨ êµ¬í˜„ (1ì°¨ íŒë‹¨)
   - Planning Nodeì—ì„œ LLM ê¸°ë°˜ ì¶©ë¶„ì„± íŒë‹¨
   - ëª…í™•í•œ ê²½ìš° SearchTeam ì œì™¸
   - ë¶ˆí™•ì‹¤í•œ ê²½ìš° Execute Nodeë¡œ ìœ„ì„

2. **Phase 2 (2ì£¼)**: Execute Node ê³ ë„í™” (2ì°¨ ê²€ì¦)
   - SearchExecutorì—ì„œ ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬
   - ì¡°ê±´ ì¶©ì¡± ì‹œ ì‹¤ì œ ê²€ìƒ‰ ê±´ë„ˆë›°ê¸°
   - Fallback ë¡œì§ ê°•í™”

3. **Phase 3 (3ì£¼)**: Hybrid í†µí•© (ìµœì í™”)
   - ì–‘ìª½ ë¡œì§ í†µí•© ë° ì¡°ìœ¨
   - A/B í…ŒìŠ¤íŠ¸ ë° ì •í™•ë„ ê²€ì¦
   - Human-in-the-Loop ì¶”ê°€

---

## 2. í˜„ì¬ ì‹œìŠ¤í…œ êµ¬ì¡° ë¶„ì„

### 2.1 LangGraph ì›Œí¬í”Œë¡œìš°

```python
# team_supervisor.py - _build_graph()
workflow = StateGraph(MainSupervisorState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("initialize", self.initialize_node)
workflow.add_node("planning", self.planning_node)              # â† Supervisor ë ˆë²¨
workflow.add_node("execute_teams", self.execute_teams_node)    # â† Execute Node ë ˆë²¨
workflow.add_node("aggregate", self.aggregate_results_node)
workflow.add_node("generate_response", self.generate_response_node)

# ì—£ì§€ êµ¬ì„±
workflow.add_edge(START, "initialize")
workflow.add_edge("initialize", "planning")

# âœ… ê³„íš í›„ ë¼ìš°íŒ… (í˜„ì¬ ë°ì´í„° ì¶©ë¶„ì„± íŒë‹¨ ì—†ìŒ)
workflow.add_conditional_edges(
    "planning",
    self._route_after_planning,
    {
        "execute": "execute_teams",
        "respond": "generate_response"
    }
)

workflow.add_edge("execute_teams", "aggregate")
```

### 2.2 ë°ì´í„° íë¦„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Planning Node (Supervisor)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Chat History ë¡œë“œ (ìµœê·¼ 3ê°œ ëŒ€í™”)              â”‚
â”‚ 2. Long-term Memory ë¡œë“œ (3-Tier)               â”‚
â”‚ 3. Intent ë¶„ì„ (LLM #1)                          â”‚
â”‚ 4. Agent ì„ íƒ (LLM #2)                           â”‚
â”‚ 5. Execution Plan ìƒì„±                           â”‚
â”‚    â””â”€> active_teams: ["search", "analysis"]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Execute Teams Node (Supervisor)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ for team in active_teams:                       â”‚
â”‚     â””â”€> _execute_single_team(team)              â”‚
â”‚         â”œâ”€> SearchExecutor.execute()            â”‚
â”‚         â””â”€> AnalysisExecutor.execute()          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SearchExecutor (Execute Node)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. prepare_search_node                          â”‚
â”‚    â”œâ”€> keywords ì¶”ì¶œ                             â”‚
â”‚    â””â”€> search_scope ê²°ì •                         â”‚
â”‚ 2. route_search_node                             â”‚
â”‚    â””â”€> search_scope ì—†ìœ¼ë©´ skip                  â”‚
â”‚ 3. execute_search_node                           â”‚
â”‚    â””â”€> ì‹¤ì œ ê²€ìƒ‰ ìˆ˜í–‰                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.3 í˜„ì¬ íŒë‹¨ ì§€ì  ë¶€ì¬ ë¬¸ì œ

**ë¬¸ì œì **:
1. **Planning Node**: Intentë§Œ ë¶„ì„, ë°ì´í„° ì¶©ë¶„ì„± íŒë‹¨ ì—†ìŒ
2. **Execute Teams Node**: active_teamsë¥¼ **ë¬´ì¡°ê±´ ì‹¤í–‰**
3. **SearchExecutor**: search_scope ì—†ìœ¼ë©´ skip (í•˜ì§€ë§Œ ì´ë¯¸ SearchTeam í˜¸ì¶œë¨)

**ê²°ê³¼**:
- ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆì–´ë„ SearchTeam í•­ìƒ ì‹¤í–‰
- ë¶ˆí•„ìš”í•œ LLM í˜¸ì¶œ ë° ê²€ìƒ‰ ë„êµ¬ ì‹¤í–‰
- 3~5ì´ˆ ë‚­ë¹„

---

## 3. ì ‘ê·¼ ë°©ì‹ 1: Supervisor ë ˆë²¨ êµ¬í˜„

### 3.1 ì•„í‚¤í…ì²˜ ê°œìš”

**í•µì‹¬ ì•„ì´ë””ì–´**: Planning Nodeì—ì„œ ë°ì´í„° ì¶©ë¶„ì„±ì„ íŒë‹¨í•˜ê³ , `active_teams`ì—ì„œ SearchTeam ì œì™¸

```python
# team_supervisor.py - planning_node()

async def planning_node(self, state: MainSupervisorState) -> MainSupervisorState:
    # 1. Intent ë¶„ì„
    intent_result = await self.planning_agent.analyze_intent(query, context)

    # ğŸ†• 2. ë°ì´í„° ì¶©ë¶„ì„± íŒë‹¨ (LLM ê¸°ë°˜)
    sufficiency_result = await self._check_data_sufficiency(
        query=query,
        intent=intent_result,
        chat_history=chat_history,
        tiered_memories=state.get("tiered_memories", {})
    )

    # ğŸ†• 3. Execution Plan ìˆ˜ì •
    if sufficiency_result["is_sufficient"]:
        # SearchTeam ì œì™¸
        execution_plan = await self.planning_agent.create_execution_plan(
            intent_result,
            skip_teams=["search_team"]
        )
        state["data_reused"] = True
        state["reused_data_source"] = sufficiency_result["data_source"]
    else:
        # ì •ìƒ ê³„íš
        execution_plan = await self.planning_agent.create_execution_plan(intent_result)

    # 4. active_teams ê²°ì •
    # ...
```

### 3.2 ë°ì´í„° ì¶©ë¶„ì„± íŒë‹¨ ë¡œì§

**ì½”ë“œ ìœ„ì¹˜**: `team_supervisor.py` - ìƒˆ ë©”ì„œë“œ ì¶”ê°€

```python
async def _check_data_sufficiency(
    self,
    query: str,
    intent: IntentResult,
    chat_history: List[Dict],
    tiered_memories: Dict
) -> Dict[str, Any]:
    """
    ë°ì´í„° ì¶©ë¶„ì„± íŒë‹¨ (LLM ê¸°ë°˜)

    Returns:
        {
            "is_sufficient": bool,           # ì¶©ë¶„í•œê°€?
            "confidence": float,             # í™•ì‹ ë„ (0~1)
            "data_source": str,              # "chat_history" | "long_term_memory" | "none"
            "missing_data_types": List[str], # ë¶€ì¡±í•œ ë°ì´í„° íƒ€ì…
            "reasoning": str                 # íŒë‹¨ ê·¼ê±°
        }
    """
    if not self.planning_agent.llm_service:
        return {"is_sufficient": False, "confidence": 0.0, "data_source": "none"}

    try:
        # í•„ìš”í•œ ë°ì´í„° íƒ€ì… ê²°ì •
        required_data_types = self._get_required_data_types(intent)

        # Chat History ë¶„ì„
        available_in_chat = await self._extract_available_data_from_history(
            chat_history,
            required_data_types
        )

        # Long-term Memory ë¶„ì„ (í•„ìš” ì‹œ)
        available_in_memory = {}
        if not available_in_chat:
            available_in_memory = await self._extract_available_data_from_memory(
                tiered_memories,
                required_data_types
            )

        # LLMì—ê²Œ ì¶©ë¶„ì„± íŒë‹¨ ìš”ì²­
        result = await self.planning_agent.llm_service.complete_json_async(
            prompt_name="data_sufficiency_check",
            variables={
                "query": query,
                "intent_type": intent.intent_type.value,
                "required_data_types": required_data_types,
                "available_in_chat": available_in_chat,
                "available_in_memory": available_in_memory,
                "chat_history": self._format_chat_history(chat_history)
            },
            temperature=0.1
        )

        return {
            "is_sufficient": result.get("is_sufficient", False),
            "confidence": result.get("confidence", 0.0),
            "data_source": result.get("data_source", "none"),
            "missing_data_types": result.get("missing_data_types", []),
            "reasoning": result.get("reasoning", "")
        }

    except Exception as e:
        logger.error(f"Data sufficiency check failed: {e}")
        # ì•ˆì „ì„ ìœ„í•´ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤ê³  íŒë‹¨
        return {"is_sufficient": False, "confidence": 0.0, "data_source": "none"}
```

### 3.3 í•„ìš”í•œ ë°ì´í„° íƒ€ì… ê²°ì •

```python
def _get_required_data_types(self, intent: IntentResult) -> List[str]:
    """
    Intentì— ë”°ë¼ í•„ìš”í•œ ë°ì´í„° íƒ€ì… ê²°ì •

    Returns:
        ["legal_data", "market_data", "loan_data", "contract_data"]
    """
    intent_to_data = {
        IntentType.LEGAL_CONSULT: ["legal_data"],
        IntentType.MARKET_INQUIRY: ["market_data"],
        IntentType.LOAN_CONSULT: ["loan_data"],
        IntentType.CONTRACT_REVIEW: ["legal_data", "contract_data"],
        IntentType.COMPREHENSIVE: ["legal_data", "market_data"],
        IntentType.RISK_ANALYSIS: ["legal_data", "market_data"],
    }

    return intent_to_data.get(intent.intent_type, ["legal_data", "market_data"])
```

### 3.4 Chat Historyì—ì„œ ë°ì´í„° ì¶”ì¶œ

```python
async def _extract_available_data_from_history(
    self,
    chat_history: List[Dict],
    required_data_types: List[str]
) -> Dict[str, Any]:
    """
    Chat Historyì—ì„œ í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œ

    Returns:
        {
            "legal_data": {"found": True, "content": "...", "recency": "3ë¶„ ì „"},
            "market_data": {"found": False}
        }
    """
    if not chat_history:
        return {}

    available = {}

    # ê° ë°ì´í„° íƒ€ì…ë³„ë¡œ ê²€ìƒ‰
    for data_type in required_data_types:
        # í‚¤ì›Œë“œ íŒ¨í„´
        patterns = {
            "legal_data": ["ë²•", "ì „ì„¸", "ì„ëŒ€ì°¨", "ê³„ì•½", "ë³´ì¦ê¸ˆ"],
            "market_data": ["ì‹œì„¸", "ê°€ê²©", "ë§¤ë§¤ê°€", "ì „ì„¸ê°€"],
            "loan_data": ["ëŒ€ì¶œ", "ê¸ˆë¦¬", "í•œë„", "LTV"],
            "contract_data": ["ê³„ì•½ì„œ", "íŠ¹ì•½", "ì¡°í•­"]
        }

        keywords = patterns.get(data_type, [])

        # Chat Historyì—ì„œ ê²€ìƒ‰
        for i, msg in enumerate(reversed(chat_history)):
            if msg["role"] == "assistant":
                content = msg["content"]
                if any(kw in content for kw in keywords):
                    available[data_type] = {
                        "found": True,
                        "content": content[:200],  # ìƒ˜í”Œ
                        "message_index": len(chat_history) - i - 1,
                        "recency": f"{(len(chat_history) - i) // 2}ê°œ ëŒ€í™” ì „"
                    }
                    break

        # ì°¾ì§€ ëª»í•œ ê²½ìš°
        if data_type not in available:
            available[data_type] = {"found": False}

    return available
```

### 3.5 í”„ë¡¬í”„íŠ¸ ì„¤ê³„

**íŒŒì¼ ìœ„ì¹˜**: `backend/app/service_agent/llm_manager/prompts/cognitive/data_sufficiency_check.txt`

```
# ë°ì´í„° ì¶©ë¶„ì„± íŒë‹¨

## í˜„ì¬ ìƒí™©

ì‚¬ìš©ì ì¿¼ë¦¬: {query}
ì˜ë„ íƒ€ì…: {intent_type}

## í•„ìš”í•œ ë°ì´í„°

ë‹¤ìŒ ë°ì´í„° íƒ€ì…ì´ í•„ìš”í•©ë‹ˆë‹¤:
{required_data_types}

## ì´ì „ ëŒ€í™”ì—ì„œ ë°œê²¬ëœ ë°ì´í„°

### Chat History (ìµœê·¼ ëŒ€í™”)
{available_in_chat}

### Long-term Memory (ê³¼ê±° ëŒ€í™”)
{available_in_memory}

## ëŒ€í™” íˆìŠ¤í† ë¦¬

{chat_history}

---

## íŒë‹¨ ê¸°ì¤€

1. **ì™„ì „ì„±**: í•„ìš”í•œ ëª¨ë“  ë°ì´í„° íƒ€ì…ì´ ìˆëŠ”ê°€?
2. **ì‹ ì„ ë„**: ë°ì´í„°ê°€ ì—¬ì „íˆ ìœ íš¨í•œê°€?
   - ë²•ë¥  ë°ì´í„°: í•­ìƒ ìœ íš¨ (ë²•ë ¹ ë³€ê²½ ì œì™¸)
   - ì‹œì„¸ ë°ì´í„°: 1ì£¼ì¼ ì´ë‚´ ìœ íš¨
   - ëŒ€ì¶œ ë°ì´í„°: 1ì¼ ì´ë‚´ ìœ íš¨
3. **ê´€ë ¨ì„±**: í˜„ì¬ ì¿¼ë¦¬ì™€ ì¼ì¹˜í•˜ëŠ”ê°€?
   - ì§€ì—­, ê¸ˆì•¡, ì¡°ê±´ ë“±ì´ ë™ì¼í•œê°€?

## ì¶œë ¥ JSON

{
  "is_sufficient": true/false,
  "confidence": 0.0~1.0,
  "data_source": "chat_history" | "long_term_memory" | "none",
  "missing_data_types": ["market_data"],
  "reasoning": "ì´ì „ ëŒ€í™”(3ê°œ ëŒ€í™” ì „)ì—ì„œ ê°•ë‚¨êµ¬ ì‹œì„¸ ì •ë³´(5ì–µ~7ì–µ) ì œê³µë¨. ì‹ ì„ ë„ ì–‘í˜¸ (3ë¶„ ì „). í˜„ì¬ ì¿¼ë¦¬ì™€ ì§€ì—­ ì¼ì¹˜. ë²•ë¥  ë°ì´í„°ë§Œ ì¶”ê°€ ê²€ìƒ‰ í•„ìš”."
}

## ì£¼ì˜ì‚¬í•­

- ë¶ˆí™•ì‹¤í•œ ê²½ìš° `is_sufficient: false` ë°˜í™˜ (ì•ˆì „ ìš°ì„ )
- confidence < 0.8ì¸ ê²½ìš° `is_sufficient: false` ê¶Œì¥
- ë°ì´í„°ê°€ ë¶€ë¶„ì ìœ¼ë¡œë§Œ ìˆì–´ë„ ìœ ìš©í•˜ë©´ `is_sufficient: true` ê°€ëŠ¥
  (ì˜ˆ: ì‹œì„¸ ë°ì´í„°ë§Œ ìˆì–´ë„ ëŒ€ëµì  ë¶„ì„ ê°€ëŠ¥)
```

### 3.6 ì¥ì  ë° ë‹¨ì 

**ì¥ì **:
1. âœ… **ì¡°ê¸° ìµœì í™”**: Planning ë‹¨ê³„ì—ì„œ ë¶ˆí•„ìš”í•œ íŒ€ ì œì™¸
2. âœ… **ì¤‘ì•™ ì§‘ì¤‘**: ëª¨ë“  íŒë‹¨ ë¡œì§ì´ í•œ ê³³ì— ì§‘ì¤‘
3. âœ… **ëª…í™•í•œ ê³„íš**: active_teamsê°€ ëª…í™•í•˜ê²Œ ê²°ì •ë¨
4. âœ… **WebSocket ì•Œë¦¼**: ì‚¬ìš©ìì—ê²Œ "ì´ì „ ë°ì´í„° ì¬ì‚¬ìš©" ì•Œë¦¼ ê°€ëŠ¥

**ë‹¨ì **:
1. âŒ **Planning Node ë³µì¡ë„ ì¦ê°€**: ì´ë¯¸ ë³µì¡í•œ ë¡œì§ì´ ë” ë³µì¡í•´ì§
2. âŒ **Checkpointing ë°ì´í„° ì ‘ê·¼ ì–´ë ¤ì›€**: Planning Nodeì—ì„œ ì´ì „ SearchTeam ê²°ê³¼ ì ‘ê·¼ ì–´ë ¤ì›€
3. âŒ **ìœ ì—°ì„± ë¶€ì¡±**: ê³„íš í›„ ë³€ê²½ ë¶ˆê°€
4. âŒ **í…ŒìŠ¤íŠ¸ ì–´ë ¤ì›€**: Planning ë¡œì§ê³¼ ê°•í•˜ê²Œ ê²°í•©

### 3.7 êµ¬í˜„ ë³µì¡ë„

**íŒŒì¼ ìˆ˜ì • ëª©ë¡**:
1. `team_supervisor.py` - `planning_node()` ìˆ˜ì •
2. `team_supervisor.py` - `_check_data_sufficiency()` ì¶”ê°€
3. `team_supervisor.py` - `_extract_available_data_from_history()` ì¶”ê°€
4. `team_supervisor.py` - `_extract_available_data_from_memory()` ì¶”ê°€
5. `planning_agent.py` - `create_execution_plan()` ìˆ˜ì • (skip_teams íŒŒë¼ë¯¸í„° ì¶”ê°€)
6. `prompts/cognitive/data_sufficiency_check.txt` - ìƒˆ í”„ë¡¬í”„íŠ¸ ì¶”ê°€

**ì˜ˆìƒ êµ¬í˜„ ì‹œê°„**: 3~5ì¼

---

## 4. ì ‘ê·¼ ë°©ì‹ 2: Execute Node ê³ ë„í™”

### 4.1 ì•„í‚¤í…ì²˜ ê°œìš”

**í•µì‹¬ ì•„ì´ë””ì–´**: SearchExecutor ë‚´ë¶€ì—ì„œ ì‹¤í–‰ ì „ ë°ì´í„° í™•ì¸ í›„ ê±´ë„ˆë›°ê¸°

```python
# search_executor.py - prepare_search_node()

async def prepare_search_node(self, state: SearchTeamState) -> SearchTeamState:
    logger.info("[SearchTeam] Preparing search")

    # ğŸ†• 1. ì´ì „ ê²€ìƒ‰ ê²°ê³¼ í™•ì¸ (Checkpointing ë˜ëŠ” ì£¼ì…ëœ ë°ì´í„°)
    previous_data = state.get("injected_previous_data") or await self._load_previous_search_data(state)

    # ğŸ†• 2. ë°ì´í„° ì¶©ë¶„ì„± ê²€ì¦
    if previous_data:
        sufficiency = self._check_data_quality(previous_data, state)

        if sufficiency["is_sufficient"]:
            # ê²€ìƒ‰ ê±´ë„ˆë›°ê¸°
            state["search_scope"] = []  # â† route_decisionì—ì„œ "skip" ë°˜í™˜
            state["using_cached_data"] = True
            state["cached_data_source"] = sufficiency["source"]

            # ì´ì „ ë°ì´í„°ë¥¼ ê²°ê³¼ë¡œ ì‚¬ìš©
            state["legal_results"] = previous_data.get("legal_search", [])
            state["real_estate_results"] = previous_data.get("real_estate_search", [])
            state["loan_results"] = previous_data.get("loan_search", [])

            logger.info(f"[SearchTeam] Using cached data from {sufficiency['source']}")
            return state

    # ğŸ†• 3. ìƒˆ ê²€ìƒ‰ í•„ìš” (ê¸°ì¡´ ë¡œì§ ê³„ì†)
    if not state.get("keywords"):
        query = state.get("shared_context", {}).get("query", "")
        state["keywords"] = self._extract_keywords(query)

    if not state.get("search_scope"):
        state["search_scope"] = self._determine_search_scope(state["keywords"])

    return state
```

### 4.2 ì´ì „ ê²€ìƒ‰ ë°ì´í„° ë¡œë“œ

```python
async def _load_previous_search_data(self, state: SearchTeamState) -> Optional[Dict]:
    """
    Checkpointing ë˜ëŠ” Long-term Memoryì—ì„œ ì´ì „ ê²€ìƒ‰ ë°ì´í„° ë¡œë“œ

    Returns:
        {
            "legal_search": [...],
            "real_estate_search": [...],
            "loan_search": [...]
        }
    """
    # ë°©ë²• 1: Checkpointing (ê°€ì¥ ìµœê·¼)
    # Note: SearchExecutorëŠ” checkpointer ì ‘ê·¼ ë¶ˆê°€
    # â†’ Supervisorì—ì„œ ì£¼ì…í•´ì•¼ í•¨

    # ë°©ë²• 2: Long-term Memory
    # Note: SearchExecutorëŠ” DB ì ‘ê·¼ ë¶ˆê°€
    # â†’ Supervisorì—ì„œ ì£¼ì…í•´ì•¼ í•¨

    # ë°©ë²• 3: shared_contextì—ì„œ ì¶”ì¶œ
    shared_context = state.get("shared_context", {})
    previous_data = shared_context.get("previous_search_results")

    return previous_data
```

### 4.3 ë°ì´í„° í’ˆì§ˆ ê²€ì¦

```python
def _check_data_quality(
    self,
    previous_data: Dict,
    state: SearchTeamState
) -> Dict[str, Any]:
    """
    ì´ì „ ë°ì´í„°ì˜ í’ˆì§ˆ ê²€ì¦

    Returns:
        {
            "is_sufficient": bool,
            "confidence": float,
            "source": str,
            "issues": List[str]  # í’ˆì§ˆ ì´ìŠˆ
        }
    """
    issues = []
    confidence = 1.0

    # 1. ì™„ì „ì„± ê²€ì‚¬
    query = state.get("shared_context", {}).get("query", "")
    required_types = self._determine_required_data_types(query)

    available_types = []
    if previous_data.get("legal_search"):
        available_types.append("legal")
    if previous_data.get("real_estate_search"):
        available_types.append("market")
    if previous_data.get("loan_search"):
        available_types.append("loan")

    missing = set(required_types) - set(available_types)
    if missing:
        issues.append(f"Missing data types: {missing}")
        confidence -= 0.3

    # 2. ë°ì´í„° ì–‘ ê²€ì‚¬
    for data_type, results in previous_data.items():
        if isinstance(results, list) and len(results) < 3:
            issues.append(f"{data_type} has insufficient results ({len(results)})")
            confidence -= 0.2

    # 3. ì‹ ì„ ë„ ê²€ì‚¬ (íƒ€ì„ìŠ¤íƒ¬í”„ í•„ìš”)
    # Note: í˜„ì¬ ë°ì´í„°ì— íƒ€ì„ìŠ¤íƒ¬í”„ ì—†ìŒ
    # â†’ Supervisorì—ì„œ metadata ì „ë‹¬ í•„ìš”

    # 4. ê´€ë ¨ì„± ê²€ì‚¬ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­)
    keywords = state.get("keywords", {})
    # TODO: ì´ì „ ë°ì´í„°ì˜ í‚¤ì›Œë“œì™€ ë¹„êµ

    # ìµœì¢… íŒë‹¨
    is_sufficient = confidence > 0.7 and not missing

    return {
        "is_sufficient": is_sufficient,
        "confidence": max(confidence, 0.0),
        "source": "previous_search",
        "issues": issues
    }
```

### 4.4 Supervisorì—ì„œ ë°ì´í„° ì£¼ì…

**ì½”ë“œ ìœ„ì¹˜**: `team_supervisor.py` - `_execute_single_team()`

```python
async def _execute_single_team(
    self,
    team_name: str,
    shared_state: SharedState,
    main_state: MainSupervisorState
) -> Any:
    """ë‹¨ì¼ íŒ€ ì‹¤í–‰"""
    team = self.teams[team_name]

    if team_name == "search":
        # ğŸ†• ì´ì „ ê²€ìƒ‰ ê²°ê³¼ ë¡œë“œ (Checkpointing)
        previous_search_data = None
        if self.checkpointer and main_state.get("chat_session_id"):
            previous_search_data = await self._get_previous_search_results(
                main_state["chat_session_id"]
            )

        # ğŸ†• shared_stateì— ì£¼ì…
        if previous_search_data:
            shared_state["previous_search_results"] = previous_search_data
            shared_state["previous_search_metadata"] = {
                "timestamp": previous_search_data.get("timestamp"),
                "query": previous_search_data.get("query")
            }

        return await team.execute(shared_state)

    # ...
```

```python
async def _get_previous_search_results(
    self,
    chat_session_id: str
) -> Optional[Dict]:
    """
    Checkpointingì—ì„œ ì´ì „ SearchTeam ê²°ê³¼ ë¡œë“œ

    Returns:
        {
            "legal_search": [...],
            "real_estate_search": [...],
            "loan_search": [...],
            "timestamp": "2025-10-22T10:30:00",
            "query": "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ì‹œì„¸"
        }
    """
    if not self.checkpointer:
        return None

    try:
        config = {"configurable": {"thread_id": chat_session_id}}
        prev_checkpoint = await self.checkpointer.aget(config)

        if prev_checkpoint and prev_checkpoint.values:
            prev_state = prev_checkpoint.values
            team_results = prev_state.get("team_results", {})

            if "search" in team_results:
                return {
                    **team_results["search"],
                    "timestamp": prev_state.get("end_time"),
                    "query": prev_state.get("query")
                }

    except Exception as e:
        logger.warning(f"Failed to load previous search results: {e}")

    return None
```

### 4.5 ì¥ì  ë° ë‹¨ì 

**ì¥ì **:
1. âœ… **ë†’ì€ ìœ ì—°ì„±**: ì‹¤í–‰ ì§ì „ ìµœì¢… íŒë‹¨ ê°€ëŠ¥
2. âœ… **Checkpointing í™œìš©**: ì´ì „ ê²°ê³¼ ì‰½ê²Œ ì ‘ê·¼
3. âœ… **ê´€ì‹¬ì‚¬ ë¶„ë¦¬**: Planningê³¼ Execution ë¶„ë¦¬
4. âœ… **í…ŒìŠ¤íŠ¸ ìš©ì´**: SearchExecutor ë…ë¦½ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥

**ë‹¨ì **:
1. âŒ **ëŠ¦ì€ ìµœì í™”**: Planning ë‹¨ê³„ì—ì„œ ì´ë¯¸ active_teamsì— í¬í•¨ë¨
2. âŒ **ì¤‘ë³µ ë¡œì§**: SearchExecutor ë‚´ë¶€ ë³µì¡ë„ ì¦ê°€
3. âŒ **ë°ì´í„° ì£¼ì… í•„ìš”**: Supervisorì—ì„œ ë°ì´í„° ì£¼ì… ë¡œì§ í•„ìš”
4. âŒ **WebSocket ì•Œë¦¼ ì–´ë ¤ì›€**: Planning ì‹œì ì— ì•Œë¦¼ ë¶ˆê°€

### 4.6 êµ¬í˜„ ë³µì¡ë„

**íŒŒì¼ ìˆ˜ì • ëª©ë¡**:
1. `search_executor.py` - `prepare_search_node()` ìˆ˜ì •
2. `search_executor.py` - `_load_previous_search_data()` ì¶”ê°€
3. `search_executor.py` - `_check_data_quality()` ì¶”ê°€
4. `team_supervisor.py` - `_execute_single_team()` ìˆ˜ì •
5. `team_supervisor.py` - `_get_previous_search_results()` ì¶”ê°€
6. `separated_states.py` - SharedStateì— `previous_search_results` í•„ë“œ ì¶”ê°€

**ì˜ˆìƒ êµ¬í˜„ ì‹œê°„**: 2~3ì¼

---

## 5. ë¹„êµ ë¶„ì„ ë° ê¶Œì¥ì‚¬í•­

### 5.1 ìƒì„¸ ë¹„êµí‘œ

| í‰ê°€ í•­ëª© | Supervisor ë ˆë²¨ | Execute Node ë ˆë²¨ | **Hybrid (ê¶Œì¥)** |
|----------|----------------|------------------|------------------|
| **1. ì„±ëŠ¥ ìµœì í™”** |
| ì¡°ê¸° ì¢…ë£Œ | âœ… Planning ë‹¨ê³„ | âŒ Execute ë‹¨ê³„ (ëŠ¦ìŒ) | âœ… Planning ë‹¨ê³„ |
| SearchTeam í˜¸ì¶œ íšŒí”¼ | âœ… ì™„ì „ íšŒí”¼ | âš ï¸ í˜¸ì¶œì€ í•˜ì§€ë§Œ ë¹ ë¥´ê²Œ ì¢…ë£Œ | âœ… ì™„ì „ íšŒí”¼ |
| ë¶ˆí•„ìš”í•œ LLM í˜¸ì¶œ ê°ì†Œ | âœ… ìµœëŒ€ | âš ï¸ ì¤‘ê°„ | âœ… ìµœëŒ€ |
| **2. ì •í™•ë„** |
| ë°ì´í„° ì ‘ê·¼ ë²”ìœ„ | â­â­â­ Chat History, Long-term Memory | â­â­â­â­ Checkpointing ì¶”ê°€ | â­â­â­â­â­ ëª¨ë“  ì†ŒìŠ¤ |
| í’ˆì§ˆ ê²€ì¦ | â­â­ LLM íŒë‹¨ë§Œ | â­â­â­â­ ê·œì¹™ ê¸°ë°˜ ê²€ì¦ | â­â­â­â­â­ LLM + ê·œì¹™ |
| ì˜¤íŒë‹¨ ë¦¬ìŠ¤í¬ | â­â­ ì¤‘ê°„ | â­â­â­ ë‚®ìŒ (Fallback) | â­â­â­â­ ë§¤ìš° ë‚®ìŒ |
| **3. êµ¬í˜„ ë³µì¡ë„** |
| ì½”ë“œ ë³€ê²½ ë²”ìœ„ | â­â­â­ ì¤‘ê°„ (6ê°œ íŒŒì¼) | â­â­ ë‚®ìŒ (6ê°œ íŒŒì¼) | â­â­â­â­ ë†’ìŒ (8ê°œ íŒŒì¼) |
| í”„ë¡¬í”„íŠ¸ ì„¤ê³„ | â­â­â­â­ ë³µì¡ | â­â­ ë‹¨ìˆœ | â­â­â­â­ ë³µì¡ |
| í…ŒìŠ¤íŠ¸ ë³µì¡ë„ | â­â­â­ ì¤‘ê°„ | â­â­ ë‚®ìŒ | â­â­â­â­ ë†’ìŒ |
| **4. ìœ ì§€ë³´ìˆ˜ì„±** |
| ì½”ë“œ ì‘ì§‘ë„ | â­â­ ë‚®ìŒ (Planning ë¹„ëŒ€í™”) | â­â­â­â­ ë†’ìŒ (ê´€ì‹¬ì‚¬ ë¶„ë¦¬) | â­â­â­ ì¤‘ê°„ |
| ë””ë²„ê¹… ìš©ì´ì„± | â­â­â­ ì¤‘ê°„ | â­â­â­â­ ë†’ìŒ | â­â­â­ ì¤‘ê°„ |
| í™•ì¥ì„± | â­â­ ë‚®ìŒ | â­â­â­â­ ë†’ìŒ | â­â­â­â­ ë†’ìŒ |
| **5. ì‚¬ìš©ì ê²½í—˜** |
| ì‚¬ì „ ì•Œë¦¼ ê°€ëŠ¥ | âœ… "ì´ì „ ë°ì´í„° ì‚¬ìš© ì˜ˆì •" | âŒ ì•Œë¦¼ ë¶ˆê°€ | âœ… ëª…í™•í•œ ì•Œë¦¼ |
| íˆ¬ëª…ì„± | â­â­â­â­ ë†’ìŒ | â­â­ ë‚®ìŒ | â­â­â­â­â­ ë§¤ìš° ë†’ìŒ |
| Human-in-the-Loop | âœ… ê°€ëŠ¥ | âš ï¸ ì–´ë ¤ì›€ | âœ… ìµœì  |

### 5.2 Hybrid ì ‘ê·¼ì˜ ìš°ìˆ˜ì„±

**Hybrid = Supervisor (1ì°¨ íŒë‹¨) + Execute Node (2ì°¨ ê²€ì¦)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Planning Node (Supervisor)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1ì°¨ íŒë‹¨: ë°ì´í„° ì¶©ë¶„ì„± LLM ë¶„ì„                    â”‚
â”‚                                                  â”‚
â”‚ IF confidence > 0.9:                             â”‚
â”‚   â””â”€> active_teams = ["analysis"]               â”‚
â”‚   â””â”€> state["skip_search_reason"] = "ì¶©ë¶„í•¨"     â”‚
â”‚                                                  â”‚
â”‚ ELIF confidence > 0.6:                           â”‚
â”‚   â””â”€> active_teams = ["search", "analysis"]     â”‚
â”‚   â””â”€> state["search_verify_data"] = True        â”‚
â”‚                                                  â”‚
â”‚ ELSE:                                            â”‚
â”‚   â””â”€> active_teams = ["search", "analysis"]     â”‚
â”‚   â””â”€> state["search_verify_data"] = False       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Execute Teams Node (Supervisor)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ IF "search" in active_teams:                     â”‚
â”‚   â”œâ”€> ì´ì „ ë°ì´í„° ë¡œë“œ (Checkpointing)             â”‚
â”‚   â”œâ”€> shared_stateì— ì£¼ì…                         â”‚
â”‚   â””â”€> SearchExecutor.execute(shared_state)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SearchExecutor (Execute Node)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ì°¨ ê²€ì¦: ë°ì´í„° í’ˆì§ˆ ê·œì¹™ ê¸°ë°˜ ê²€ì‚¬                 â”‚
â”‚                                                  â”‚
â”‚ IF state["search_verify_data"] == True:          â”‚
â”‚   â”œâ”€> previous_data = state.get("previous_...")  â”‚
â”‚   â”œâ”€> quality = _check_data_quality(...)         â”‚
â”‚   â”‚                                              â”‚
â”‚   â””â”€> IF quality["is_sufficient"]:               â”‚
â”‚       â””â”€> search_scope = []  (skip)              â”‚
â”‚   â””â”€> ELSE:                                      â”‚
â”‚       â””â”€> ìƒˆ ê²€ìƒ‰ ìˆ˜í–‰                            â”‚
â”‚                                                  â”‚
â”‚ ELSE:                                            â”‚
â”‚   â””â”€> ìƒˆ ê²€ìƒ‰ ìˆ˜í–‰ (ê¸°ì¡´ ë¡œì§)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ì¥ì **:
1. âœ… **ì´ì¤‘ ì•ˆì „ë§**: LLM ì˜¤íŒë‹¨ ì‹œ ê·œì¹™ ê¸°ë°˜ ê²€ì¦ìœ¼ë¡œ ë³´ì™„
2. âœ… **ìµœì  ì„±ëŠ¥**: ëª…í™•í•œ ê²½ìš°(confidence > 0.9) ì¡°ê¸° ì¢…ë£Œ
3. âœ… **ìµœê³  ì •í™•ë„**: ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ í™œìš©
4. âœ… **ì‚¬ìš©ì ì‹ ë¢°**: Planning ì‹œì  ì•Œë¦¼ + Execute ì‹œì  ì¬í™•ì¸

**ë‹¨ì **:
1. âŒ **ë†’ì€ ë³µì¡ë„**: ì–‘ìª½ ëª¨ë‘ êµ¬í˜„ í•„ìš”
2. âŒ **ìœ ì§€ë³´ìˆ˜ ë¶€ë‹´**: ë‘ ê³³ì—ì„œ ë¡œì§ ê´€ë¦¬
3. âŒ **êµ¬í˜„ ì‹œê°„**: 4~6ì¼ ì†Œìš”

### 5.3 ìµœì¢… ê¶Œì¥ì‚¬í•­

**ë‹¨ê³„ë³„ êµ¬í˜„ ì „ëµ**:

#### Phase 1 (1ì£¼): Supervisor ë ˆë²¨ êµ¬í˜„ (1ì°¨ íŒë‹¨)

**ëª©í‘œ**: ëª…í™•í•œ ê²½ìš° SearchTeam ì œì™¸

**êµ¬í˜„**:
1. `planning_node()`ì— `_check_data_sufficiency()` ì¶”ê°€
2. confidence > 0.9ì¸ ê²½ìš° active_teamsì—ì„œ "search" ì œì™¸
3. WebSocket ì•Œë¦¼: "ì´ì „ ë°ì´í„° ì¬ì‚¬ìš© ì¤‘..."

**ê¸°ëŒ€ íš¨ê³¼**:
- ëª…í™•í•œ ê²½ìš° (ì˜ˆ: "ë°©ê¸ˆ ê²€ìƒ‰í•œ ë°ì´í„°ë¡œ ë¶„ì„í•´ì¤˜") 3~5ì´ˆ ë‹¨ì¶•
- ì „ì²´ ì¿¼ë¦¬ì˜ ì•½ 30% í•´ë‹¹

#### Phase 2 (2ì£¼): Execute Node ê³ ë„í™” (2ì°¨ ê²€ì¦)

**ëª©í‘œ**: ë¶ˆí™•ì‹¤í•œ ê²½ìš° 2ì°¨ ê²€ì¦

**êµ¬í˜„**:
1. `_execute_single_team()`ì—ì„œ ì´ì „ ë°ì´í„° ë¡œë“œ ë° ì£¼ì…
2. `prepare_search_node()`ì— `_check_data_quality()` ì¶”ê°€
3. ì¡°ê±´ ì¶©ì¡± ì‹œ search_scope = [] ì„¤ì •

**ê¸°ëŒ€ íš¨ê³¼**:
- Phase 1ì—ì„œ ë†“ì¹œ ê²½ìš° ì¶”ê°€ ìµœì í™” (ì•½ 20%)
- ì´ 50% ì¿¼ë¦¬ì—ì„œ SearchTeam ê±´ë„ˆë›°ê¸°

#### Phase 3 (3ì£¼): Hybrid í†µí•© ë° ìµœì í™”

**ëª©í‘œ**: ì–‘ìª½ ë¡œì§ ì¡°ìœ¨ ë° Human-in-the-Loop ì¶”ê°€

**êµ¬í˜„**:
1. Supervisorì™€ Execute Node ê°„ State ê³µìœ  ìµœì í™”
2. confidence ì„ê³„ê°’ ì¡°ì • (A/B í…ŒìŠ¤íŠ¸)
3. ë¶ˆí™•ì‹¤ ì‹œ ì‚¬ìš©ì í™•ì¸ ìš”ì²­ (WebSocket)

**ê¸°ëŒ€ íš¨ê³¼**:
- ìµœê³  ì •í™•ë„ ë° ì‚¬ìš©ì ì‹ ë¢°ë„
- ì´ 60~70% ì¿¼ë¦¬ ìµœì í™”

---

## 6. ë‹¨ê³„ë³„ êµ¬í˜„ ê°€ì´ë“œ

### 6.1 Phase 1: Supervisor ë ˆë²¨ êµ¬í˜„

#### Step 1: í”„ë¡¬í”„íŠ¸ ì‘ì„±

**íŒŒì¼ ìƒì„±**: `backend/app/service_agent/llm_manager/prompts/cognitive/data_sufficiency_check.txt`

```
# ë°ì´í„° ì¶©ë¶„ì„± íŒë‹¨ í”„ë¡¬í”„íŠ¸

## ëª©ì 
ì‚¬ìš©ìì˜ í˜„ì¬ ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì´ì „ ëŒ€í™”(Chat History ë˜ëŠ” Long-term Memory)ì— ì €ì¥ëœ ë°ì´í„°ë¡œ ì¶©ë¶„í•œì§€ íŒë‹¨í•©ë‹ˆë‹¤.

## ì…ë ¥ ì •ë³´

### 1. í˜„ì¬ ì¿¼ë¦¬
{query}

### 2. ì˜ë„ íƒ€ì…
{intent_type}

### 3. í•„ìš”í•œ ë°ì´í„° íƒ€ì…
{required_data_types}

### 4. Chat Historyì—ì„œ ë°œê²¬ëœ ë°ì´í„°
{available_in_chat}

### 5. Long-term Memoryì—ì„œ ë°œê²¬ëœ ë°ì´í„°
{available_in_memory}

### 6. ëŒ€í™” ì „ì²´ íˆìŠ¤í† ë¦¬
{chat_history}

---

## íŒë‹¨ ê¸°ì¤€

### 1. ì™„ì „ì„± (Completeness)
- í•„ìš”í•œ ëª¨ë“  ë°ì´í„° íƒ€ì…ì´ ìˆëŠ”ê°€?
- ì˜ˆ: "ì‹œì„¸ ë¶„ì„"ì´ë©´ market_data í•„ìˆ˜

### 2. ì‹ ì„ ë„ (Freshness)
- **ë²•ë¥  ë°ì´í„°**: í•­ìƒ ìœ íš¨ (ë²•ë ¹ ê°œì • ì œì™¸)
- **ì‹œì„¸ ë°ì´í„°**: 1ì£¼ì¼ ì´ë‚´ ìœ íš¨
- **ëŒ€ì¶œ ë°ì´í„°**: 1ì¼ ì´ë‚´ ìœ íš¨
- **ê³„ì•½ ë°ì´í„°**: í•­ìƒ ìœ íš¨ (íŠ¹ì • ê³„ì•½ì„œ)

### 3. ê´€ë ¨ì„± (Relevance)
- ì§€ì—­ì´ ë™ì¼í•œê°€? (ì˜ˆ: ê°•ë‚¨êµ¬ â†’ ê°•ë‚¨êµ¬)
- ê¸ˆì•¡ ë²”ìœ„ê°€ ìœ ì‚¬í•œê°€?
- ì¡°ê±´ì´ ì¼ì¹˜í•˜ëŠ”ê°€?

### 4. í’ˆì§ˆ (Quality)
- ë°ì´í„° ì–‘ì´ ì¶©ë¶„í•œê°€? (ìµœì†Œ 3ê°œ ì´ìƒ)
- êµ¬ì²´ì ì¸ ì •ë³´ì¸ê°€? (ë§‰ì—°í•œ ì„¤ëª… X)

---

## ì¶œë ¥ í˜•ì‹ (JSON)

{
  "is_sufficient": true/false,
  "confidence": 0.0~1.0,
  "data_source": "chat_history" | "long_term_memory" | "none",
  "missing_data_types": ["market_data"],
  "reasoning": "ì´ì „ ëŒ€í™”(3ê°œ ëŒ€í™” ì „)ì—ì„œ ê°•ë‚¨êµ¬ ì‹œì„¸ ì •ë³´(5ì–µ~7ì–µ) ì œê³µë¨. ì‹ ì„ ë„ ì–‘í˜¸ (3ë¶„ ì „). í˜„ì¬ ì¿¼ë¦¬ì™€ ì§€ì—­ ì¼ì¹˜. ì¶©ë¶„í•¨."
}

---

## ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ì¶©ë¶„í•¨

**ì¿¼ë¦¬**: "ë°©ê¸ˆ ê²€ìƒ‰í•œ ì‹œì„¸ë¡œ íˆ¬ì ìˆ˜ìµë¥  ê³„ì‚°í•´ì¤˜"
**Chat History**: "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ì „ì„¸ ì‹œì„¸ëŠ” 5ì–µ~7ì–µì…ë‹ˆë‹¤. (2ë¶„ ì „)"
**í•„ìš” ë°ì´í„°**: ["market_data"]

**ì¶œë ¥**:
{
  "is_sufficient": true,
  "confidence": 0.95,
  "data_source": "chat_history",
  "missing_data_types": [],
  "reasoning": "2ë¶„ ì „ ëŒ€í™”ì—ì„œ ê°•ë‚¨êµ¬ ì‹œì„¸ ì •ë³´ ì œê³µë¨. ì‹ ì„ ë„ ìš°ìˆ˜. íˆ¬ì ë¶„ì„ì— ì¶©ë¶„."
}

### ì˜ˆì‹œ 2: ë¶ˆì¶©ë¶„í•¨

**ì¿¼ë¦¬**: "ì„œì´ˆêµ¬ ì‹œì„¸ ë¶„ì„í•´ì¤˜"
**Chat History**: "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ì „ì„¸ ì‹œì„¸ëŠ” 5ì–µ~7ì–µì…ë‹ˆë‹¤. (2ë¶„ ì „)"
**í•„ìš” ë°ì´í„°**: ["market_data"]

**ì¶œë ¥**:
{
  "is_sufficient": false,
  "confidence": 0.3,
  "data_source": "none",
  "missing_data_types": ["market_data"],
  "reasoning": "ì§€ì—­ ë¶ˆì¼ì¹˜ (ê°•ë‚¨êµ¬ â‰  ì„œì´ˆêµ¬). ìƒˆë¡œìš´ ê²€ìƒ‰ í•„ìš”."
}

### ì˜ˆì‹œ 3: ë¶ˆí™•ì‹¤í•¨ (ì•ˆì „í•˜ê²Œ false ë°˜í™˜)

**ì¿¼ë¦¬**: "ìœ„í—˜ë„ ë¶„ì„í•´ì¤˜"
**Chat History**: "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ì „ì„¸ ì‹œì„¸ëŠ” 5ì–µ~7ì–µì…ë‹ˆë‹¤. (1ì£¼ì¼ ì „)"
**í•„ìš” ë°ì´í„°**: ["market_data", "legal_data"]

**ì¶œë ¥**:
{
  "is_sufficient": false,
  "confidence": 0.6,
  "data_source": "chat_history",
  "missing_data_types": ["legal_data"],
  "reasoning": "ì‹œì„¸ ë°ì´í„°ëŠ” ìˆìœ¼ë‚˜ 1ì£¼ì¼ ê²½ê³¼ë¡œ ì‹ ì„ ë„ ì˜ì‹¬. ë²•ë¥  ë°ì´í„° ì—†ìŒ. ì¬ê²€ìƒ‰ ê¶Œì¥."
}

---

## ì£¼ì˜ì‚¬í•­

1. **ì•ˆì „ ìš°ì„ **: ë¶ˆí™•ì‹¤í•˜ë©´ `is_sufficient: false` ë°˜í™˜
2. **Confidence ê¸°ì¤€**: < 0.8ì´ë©´ false ê¶Œì¥
3. **ë¶€ë¶„ ì¶©ì¡±**: ì¼ë¶€ ë°ì´í„°ë§Œ ìˆì–´ë„ ìœ ìš©í•˜ë©´ true ê°€ëŠ¥
4. **ì‹œê°„ í‘œí˜„ ì´í•´**: "ë°©ê¸ˆ", "ì•„ê¹Œ", "ì¡°ê¸ˆ ì „" â†’ ì‹ ì„ í•¨
```

#### Step 2: ë°ì´í„° ì¶©ë¶„ì„± íŒë‹¨ ë©”ì„œë“œ ì¶”ê°€

**íŒŒì¼ ìˆ˜ì •**: `backend/app/service_agent/supervisor/team_supervisor.py`

```python
# team_supervisor.py - ìƒˆ ë©”ì„œë“œ ì¶”ê°€ (planning_node ì´ì „)

async def _check_data_sufficiency(
    self,
    query: str,
    intent: IntentResult,
    chat_history: List[Dict],
    tiered_memories: Dict
) -> Dict[str, Any]:
    """
    ë°ì´í„° ì¶©ë¶„ì„± íŒë‹¨ (LLM ê¸°ë°˜)

    Args:
        query: ì‚¬ìš©ì ì¿¼ë¦¬
        intent: Intent ë¶„ì„ ê²°ê³¼
        chat_history: ìµœê·¼ ëŒ€í™” íˆìŠ¤í† ë¦¬
        tiered_memories: 3-Tier Long-term Memory

    Returns:
        {
            "is_sufficient": bool,
            "confidence": float,
            "data_source": str,
            "missing_data_types": List[str],
            "reasoning": str
        }
    """
    # LLM ì„œë¹„ìŠ¤ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
    if not self.planning_agent.llm_service:
        logger.warning("LLM service not available, skipping sufficiency check")
        return {
            "is_sufficient": False,
            "confidence": 0.0,
            "data_source": "none",
            "missing_data_types": [],
            "reasoning": "LLM not available"
        }

    try:
        # 1. í•„ìš”í•œ ë°ì´í„° íƒ€ì… ê²°ì •
        required_data_types = self._get_required_data_types(intent)

        # 2. Chat Historyì—ì„œ ì´ìš© ê°€ëŠ¥í•œ ë°ì´í„° ì¶”ì¶œ
        available_in_chat = self._extract_available_data_from_history(
            chat_history,
            required_data_types
        )

        # 3. Long-term Memoryì—ì„œ ì´ìš© ê°€ëŠ¥í•œ ë°ì´í„° ì¶”ì¶œ
        available_in_memory = self._extract_available_data_from_memory(
            tiered_memories,
            required_data_types
        )

        # 4. Chat History í¬ë§·íŒ…
        chat_history_text = self._format_chat_history(chat_history)

        # 5. LLMì—ê²Œ ì¶©ë¶„ì„± íŒë‹¨ ìš”ì²­
        result = await self.planning_agent.llm_service.complete_json_async(
            prompt_name="data_sufficiency_check",
            variables={
                "query": query,
                "intent_type": intent.intent_type.value,
                "required_data_types": json.dumps(required_data_types, ensure_ascii=False),
                "available_in_chat": json.dumps(available_in_chat, ensure_ascii=False, indent=2),
                "available_in_memory": json.dumps(available_in_memory, ensure_ascii=False, indent=2),
                "chat_history": chat_history_text
            },
            temperature=0.1,
            max_tokens=500
        )

        logger.info(f"[Sufficiency Check] Result: {result}")

        return {
            "is_sufficient": result.get("is_sufficient", False),
            "confidence": result.get("confidence", 0.0),
            "data_source": result.get("data_source", "none"),
            "missing_data_types": result.get("missing_data_types", []),
            "reasoning": result.get("reasoning", "")
        }

    except Exception as e:
        logger.error(f"Data sufficiency check failed: {e}", exc_info=True)
        # ì•ˆì „ì„ ìœ„í•´ ë¶ˆì¶©ë¶„í•˜ë‹¤ê³  íŒë‹¨
        return {
            "is_sufficient": False,
            "confidence": 0.0,
            "data_source": "none",
            "missing_data_types": required_data_types,
            "reasoning": f"Error: {str(e)}"
        }

def _get_required_data_types(self, intent: IntentResult) -> List[str]:
    """Intentì— ë”°ë¼ í•„ìš”í•œ ë°ì´í„° íƒ€ì… ê²°ì •"""
    intent_to_data = {
        IntentType.LEGAL_CONSULT: ["legal_data"],
        IntentType.MARKET_INQUIRY: ["market_data"],
        IntentType.LOAN_CONSULT: ["loan_data"],
        IntentType.CONTRACT_CREATION: [],  # ìƒˆë¡œ ì‘ì„±í•˜ë¯€ë¡œ ì´ì „ ë°ì´í„° ë¶ˆí•„ìš”
        IntentType.CONTRACT_REVIEW: ["legal_data", "contract_data"],
        IntentType.COMPREHENSIVE: ["legal_data", "market_data"],
        IntentType.RISK_ANALYSIS: ["legal_data", "market_data"],
    }

    return intent_to_data.get(intent.intent_type, ["legal_data", "market_data"])

def _extract_available_data_from_history(
    self,
    chat_history: List[Dict],
    required_data_types: List[str]
) -> Dict[str, Any]:
    """Chat Historyì—ì„œ í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œ"""
    if not chat_history:
        return {}

    available = {}

    # ë°ì´í„° íƒ€ì…ë³„ í‚¤ì›Œë“œ íŒ¨í„´
    patterns = {
        "legal_data": ["ë²•", "ì „ì„¸", "ì„ëŒ€ì°¨", "ê³„ì•½", "ë³´ì¦ê¸ˆ", "ê¶Œë¦¬", "ì˜ë¬´", "ê°±ì‹ "],
        "market_data": ["ì‹œì„¸", "ê°€ê²©", "ë§¤ë§¤ê°€", "ì „ì„¸ê°€", "í‰ê· ", "ê±°ë˜"],
        "loan_data": ["ëŒ€ì¶œ", "ê¸ˆë¦¬", "í•œë„", "LTV", "DTI", "DSR"],
        "contract_data": ["ê³„ì•½ì„œ", "íŠ¹ì•½", "ì¡°í•­", "ì„œëª…"]
    }

    # ê° ë°ì´í„° íƒ€ì…ë³„ë¡œ ê²€ìƒ‰
    for data_type in required_data_types:
        keywords = patterns.get(data_type, [])

        # Chat Historyë¥¼ ì—­ìˆœìœ¼ë¡œ íƒìƒ‰ (ìµœì‹ ë¶€í„°)
        for i, msg in enumerate(reversed(chat_history)):
            if msg["role"] == "assistant":
                content = msg["content"]

                # í‚¤ì›Œë“œ ë§¤ì¹­
                if any(kw in content for kw in keywords):
                    # ë°ì´í„° ë°œê²¬
                    conversation_index = len(chat_history) - i - 1
                    conversations_ago = (len(chat_history) - conversation_index) // 2

                    available[data_type] = {
                        "found": True,
                        "content": content[:300],  # ìƒ˜í”Œ (ìµœëŒ€ 300ì)
                        "conversation_index": conversation_index,
                        "recency": f"{conversations_ago}ê°œ ëŒ€í™” ì „"
                    }
                    break  # ê°€ì¥ ìµœê·¼ ê²ƒë§Œ

        # ì°¾ì§€ ëª»í•œ ê²½ìš°
        if data_type not in available:
            available[data_type] = {"found": False}

    return available

def _extract_available_data_from_memory(
    self,
    tiered_memories: Dict,
    required_data_types: List[str]
) -> Dict[str, Any]:
    """Long-term Memoryì—ì„œ í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œ"""
    if not tiered_memories:
        return {}

    available = {}

    # Short-term, Mid-term, Long-term ìˆœìœ¼ë¡œ ê²€ìƒ‰
    for tier in ["shortterm", "midterm", "longterm"]:
        memories = tiered_memories.get(tier, [])

        for data_type in required_data_types:
            if data_type in available:
                continue  # ì´ë¯¸ ì°¾ìŒ

            # ë©”ëª¨ë¦¬ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰ (ê°„ë‹¨í•œ ë²„ì „)
            for memory in memories:
                summary = memory.get("summary", "")
                # TODO: ë” ì •êµí•œ ë§¤ì¹­ ë¡œì§
                if data_type.replace("_data", "") in summary.lower():
                    available[data_type] = {
                        "found": True,
                        "content": summary[:300],
                        "tier": tier,
                        "session_id": memory.get("session_id")
                    }
                    break

    # ì°¾ì§€ ëª»í•œ ê²½ìš°
    for data_type in required_data_types:
        if data_type not in available:
            available[data_type] = {"found": False}

    return available

def _format_chat_history(self, chat_history: List[Dict]) -> str:
    """Chat Historyë¥¼ LLMì´ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if not chat_history:
        return "No chat history available."

    lines = []
    for i, msg in enumerate(chat_history):
        role = "ì‚¬ìš©ì" if msg["role"] == "user" else "AI"
        content = msg["content"][:500]  # ì œí•œ
        lines.append(f"[{i+1}] {role}: {content}")

    return "\n".join(lines)
```

#### Step 3: Planning Node ìˆ˜ì •

**íŒŒì¼ ìˆ˜ì •**: `backend/app/service_agent/supervisor/team_supervisor.py` - `planning_node()`

```python
async def planning_node(self, state: MainSupervisorState) -> MainSupervisorState:
    # ... (ê¸°ì¡´ ì½”ë“œ: Intent ë¶„ì„, Long-term Memory ë¡œë“œ ë“±)

    # IRRELEVANT/UNCLEAR ì¡°ê¸° ì¢…ë£Œ (ê¸°ì¡´ ì½”ë“œ)
    if intent_result.intent_type == IntentType.IRRELEVANT:
        # ...
        return state

    # ğŸ†• ë°ì´í„° ì¶©ë¶„ì„± íŒë‹¨ (ìƒˆ ì½”ë“œ)
    sufficiency_result = await self._check_data_sufficiency(
        query=query,
        intent=intent_result,
        chat_history=chat_history,
        tiered_memories=state.get("tiered_memories", {})
    )

    logger.info(
        f"[Sufficiency Check] is_sufficient={sufficiency_result['is_sufficient']}, "
        f"confidence={sufficiency_result['confidence']:.2f}, "
        f"source={sufficiency_result['data_source']}"
    )

    # ğŸ†• ì¶©ë¶„ì„± ê²°ê³¼ì— ë”°ë¼ Agent ì„ íƒ ìˆ˜ì •
    skip_search = False

    if sufficiency_result["is_sufficient"] and sufficiency_result["confidence"] > 0.9:
        # ë§¤ìš° í™•ì‹¤í•œ ê²½ìš°: SearchTeam ì™„ì „ ì œì™¸
        logger.info("[Sufficiency Check] Very high confidence, skipping SearchTeam completely")
        skip_search = True

        # Stateì— ê¸°ë¡
        state["data_reused"] = True
        state["reused_data_source"] = sufficiency_result["data_source"]
        state["sufficiency_reasoning"] = sufficiency_result["reasoning"]

        # WebSocket ì•Œë¦¼
        session_id = state.get("session_id")
        progress_callback = self._progress_callbacks.get(session_id) if session_id else None
        if progress_callback:
            try:
                await progress_callback("data_reuse_decision", {
                    "message": "ì´ì „ ëŒ€í™”ì˜ ë°ì´í„°ë¥¼ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.",
                    "source": sufficiency_result["data_source"],
                    "reasoning": sufficiency_result["reasoning"],
                    "confidence": sufficiency_result["confidence"]
                })
            except Exception as e:
                logger.error(f"Failed to send data_reuse_decision: {e}")

    elif sufficiency_result["is_sufficient"] and sufficiency_result["confidence"] > 0.6:
        # ì¤‘ê°„ í™•ì‹ : Execute Nodeì—ì„œ 2ì°¨ ê²€ì¦
        logger.info("[Sufficiency Check] Medium confidence, deferring to Execute Node")
        state["verify_search_data"] = True
        state["sufficiency_result"] = sufficiency_result

    else:
        # ë¶ˆì¶©ë¶„ ë˜ëŠ” ë‚®ì€ í™•ì‹ : ìƒˆ ê²€ìƒ‰ í•„ìš”
        logger.info("[Sufficiency Check] Insufficient or low confidence, new search required")
        state["verify_search_data"] = False

    # ì‹¤í–‰ ê³„íš ìƒì„± (ê¸°ì¡´ ì½”ë“œ ìˆ˜ì •)
    if skip_search:
        # ğŸ†• SearchTeam ì œì™¸í•œ Agentë§Œ ì„ íƒ
        filtered_agents = [a for a in intent_result.suggested_agents if a != "search_team"]

        # ê°•ì œë¡œ Agent ëª©ë¡ êµì²´
        intent_result.suggested_agents = filtered_agents if filtered_agents else ["analysis_team"]

    execution_plan = await self.planning_agent.create_execution_plan(intent_result)

    # ... (ë‚˜ë¨¸ì§€ ê¸°ì¡´ ì½”ë“œ: Planning State ìƒì„±, active_teams ê²°ì • ë“±)

    return state
```

### 6.2 Phase 2: Execute Node ê³ ë„í™”

#### Step 1: Supervisorì—ì„œ ì´ì „ ë°ì´í„° ë¡œë“œ ë° ì£¼ì…

**íŒŒì¼ ìˆ˜ì •**: `backend/app/service_agent/supervisor/team_supervisor.py` - `_execute_single_team()`

```python
async def _execute_single_team(
    self,
    team_name: str,
    shared_state: SharedState,
    main_state: MainSupervisorState
) -> Any:
    """ë‹¨ì¼ íŒ€ ì‹¤í–‰"""
    team = self.teams[team_name]

    if team_name == "search":
        # ğŸ†• Phase 2: ì´ì „ ê²€ìƒ‰ ê²°ê³¼ ë¡œë“œ ë° ì£¼ì…
        if main_state.get("verify_search_data"):
            previous_data = await self._get_previous_search_results(
                main_state.get("chat_session_id")
            )

            if previous_data:
                # shared_stateì— ì£¼ì…
                shared_state["previous_search_results"] = previous_data
                shared_state["previous_search_metadata"] = {
                    "timestamp": previous_data.get("timestamp"),
                    "query": previous_data.get("query")
                }
                shared_state["sufficiency_result"] = main_state.get("sufficiency_result")

                logger.info(f"[Execute] Injected previous search data from {previous_data.get('timestamp')}")

        return await team.execute(shared_state)

    elif team_name == "document":
        # ...
        return await team.execute(shared_state, document_type=doc_type)

    elif team_name == "analysis":
        # ...
        return await team.execute(shared_state, analysis_type="comprehensive", input_data=input_data)

    return {"status": "skipped"}

async def _get_previous_search_results(
    self,
    chat_session_id: Optional[str]
) -> Optional[Dict]:
    """
    Checkpointingì—ì„œ ì´ì „ SearchTeam ê²°ê³¼ ë¡œë“œ

    Returns:
        {
            "legal_search": [...],
            "real_estate_search": [...],
            "loan_search": [...],
            "timestamp": "2025-10-22T10:30:00",
            "query": "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ì‹œì„¸"
        }
    """
    if not self.checkpointer or not chat_session_id:
        return None

    try:
        config = {"configurable": {"thread_id": chat_session_id}}
        prev_checkpoint = await self.checkpointer.aget(config)

        if prev_checkpoint and prev_checkpoint.values:
            prev_state = prev_checkpoint.values
            team_results = prev_state.get("team_results", {})

            if "search" in team_results:
                # íƒ€ì„ìŠ¤íƒ¬í”„ ë° ì¿¼ë¦¬ ì¶”ê°€
                return {
                    **team_results["search"],
                    "timestamp": prev_state.get("end_time", datetime.now()).isoformat() if prev_state.get("end_time") else None,
                    "query": prev_state.get("query", "")
                }

        logger.info("[Checkpoint] No previous search results found")
        return None

    except Exception as e:
        logger.warning(f"Failed to load previous search results from checkpoint: {e}")
        return None
```

#### Step 2: SearchExecutor prepare_search_node ìˆ˜ì •

**íŒŒì¼ ìˆ˜ì •**: `backend/app/service_agent/execution_agents/search_executor.py`

```python
async def prepare_search_node(self, state: SearchTeamState) -> SearchTeamState:
    """
    ê²€ìƒ‰ ì¤€ë¹„ ë…¸ë“œ
    í‚¤ì›Œë“œ ì¶”ì¶œ ë° ê²€ìƒ‰ ë²”ìœ„ ì„¤ì •
    ğŸ†• Phase 2: ì´ì „ ë°ì´í„° ì¬ì‚¬ìš© ê²€ì¦
    """
    logger.info("[SearchTeam] Preparing search")

    # ì´ˆê¸°í™”
    state["team_name"] = self.team_name
    state["status"] = "in_progress"
    state["start_time"] = datetime.now()
    state["search_progress"] = {}

    # ğŸ†• Phase 2: ì´ì „ ê²€ìƒ‰ ë°ì´í„° í™•ì¸
    shared_context = state.get("shared_context", {})
    previous_data = shared_context.get("previous_search_results")
    sufficiency_result = shared_context.get("sufficiency_result")

    if previous_data and sufficiency_result:
        # ğŸ†• ë°ì´í„° í’ˆì§ˆ ê²€ì¦
        quality = self._check_data_quality(
            previous_data=previous_data,
            state=state,
            sufficiency_result=sufficiency_result
        )

        if quality["is_sufficient"]:
            # ğŸ†• ê²€ìƒ‰ ê±´ë„ˆë›°ê¸°
            logger.info(
                f"[SearchTeam] Using cached data (quality: {quality['confidence']:.2f}, "
                f"source: {quality['source']})"
            )

            # search_scopeë¥¼ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì„¤ì • â†’ route_decisionì—ì„œ "skip" ë°˜í™˜
            state["search_scope"] = []
            state["using_cached_data"] = True
            state["cached_data_source"] = quality["source"]
            state["cached_data_quality"] = quality

            # ğŸ†• ì´ì „ ë°ì´í„°ë¥¼ ê²°ê³¼ë¡œ ì‚¬ìš©
            state["legal_results"] = previous_data.get("legal_search", [])
            state["real_estate_results"] = previous_data.get("real_estate_search", [])
            state["loan_results"] = previous_data.get("loan_search", [])

            return state
        else:
            # í’ˆì§ˆ ë¶ˆì¶©ë¶„, ìƒˆ ê²€ìƒ‰ í•„ìš”
            logger.info(
                f"[SearchTeam] Cached data quality insufficient (confidence: {quality['confidence']:.2f}), "
                f"performing new search. Issues: {quality['issues']}"
            )

    # ğŸ†• í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì¿¼ë¦¬ì—ì„œ ì¶”ì¶œ (ê¸°ì¡´ ë¡œì§)
    if not state.get("keywords"):
        query = shared_context.get("query", "")
        state["keywords"] = self._extract_keywords(query)

    # ê²€ìƒ‰ ë²”ìœ„ê°€ ì—†ìœ¼ë©´ í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ê²°ì • (ê¸°ì¡´ ë¡œì§)
    if not state.get("search_scope"):
        state["search_scope"] = self._determine_search_scope(state["keywords"])

    logger.info(f"[SearchTeam] Search scope: {state['search_scope']}")
    return state
```

#### Step 3: ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë©”ì„œë“œ ì¶”ê°€

**íŒŒì¼ ìˆ˜ì •**: `backend/app/service_agent/execution_agents/search_executor.py`

```python
def _check_data_quality(
    self,
    previous_data: Dict,
    state: SearchTeamState,
    sufficiency_result: Dict
) -> Dict[str, Any]:
    """
    ì´ì „ ê²€ìƒ‰ ë°ì´í„°ì˜ í’ˆì§ˆ ê²€ì¦ (ê·œì¹™ ê¸°ë°˜)

    Args:
        previous_data: ì´ì „ ê²€ìƒ‰ ê²°ê³¼
        state: í˜„ì¬ State
        sufficiency_result: Supervisorì˜ ì¶©ë¶„ì„± íŒë‹¨ ê²°ê³¼

    Returns:
        {
            "is_sufficient": bool,
            "confidence": float,
            "source": str,
            "issues": List[str]
        }
    """
    issues = []
    confidence = sufficiency_result.get("confidence", 0.5)

    # 1. ì™„ì „ì„± ê²€ì‚¬: í•„ìš”í•œ ë°ì´í„° íƒ€ì…ì´ ëª¨ë‘ ìˆëŠ”ê°€?
    query = state.get("shared_context", {}).get("query", "")
    required_types = self._determine_required_data_types_from_query(query)

    available_types = []
    if previous_data.get("legal_search"):
        available_types.append("legal")
    if previous_data.get("real_estate_search"):
        available_types.append("market")
    if previous_data.get("loan_search"):
        available_types.append("loan")

    missing = set(required_types) - set(available_types)
    if missing:
        issues.append(f"Missing data types: {missing}")
        confidence -= 0.3

    # 2. ë°ì´í„° ì–‘ ê²€ì‚¬: ê° íƒ€ì…ë³„ë¡œ ì¶©ë¶„í•œ ê²°ê³¼ê°€ ìˆëŠ”ê°€?
    for data_type, results in previous_data.items():
        if data_type in ["legal_search", "real_estate_search", "loan_search"]:
            if isinstance(results, list):
                if len(results) == 0:
                    issues.append(f"{data_type} has no results")
                    confidence -= 0.4
                elif len(results) < 3:
                    issues.append(f"{data_type} has insufficient results ({len(results)} < 3)")
                    confidence -= 0.2

    # 3. ì‹ ì„ ë„ ê²€ì‚¬ (íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜)
    metadata = state.get("shared_context", {}).get("previous_search_metadata", {})
    timestamp_str = metadata.get("timestamp")

    if timestamp_str:
        try:
            from datetime import datetime, timedelta

            # ISO í˜•ì‹ íŒŒì‹±
            if isinstance(timestamp_str, str):
                timestamp = datetime.fromisoformat(timestamp_str)
            else:
                timestamp = timestamp_str

            age = datetime.now() - timestamp

            # ì‹ ì„ ë„ ê¸°ì¤€ (ë°ì´í„° íƒ€ì…ë³„)
            if "market" in required_types:
                # ì‹œì„¸ ë°ì´í„°: 1ì£¼ì¼ ì´ë‚´
                if age > timedelta(days=7):
                    issues.append(f"Market data is {age.days} days old (> 7 days)")
                    confidence -= 0.3
                elif age > timedelta(days=3):
                    issues.append(f"Market data is {age.days} days old (> 3 days, warning)")
                    confidence -= 0.1

            if "loan" in required_types:
                # ëŒ€ì¶œ ë°ì´í„°: 1ì¼ ì´ë‚´
                if age > timedelta(days=1):
                    issues.append(f"Loan data is {age.days} days old (> 1 day)")
                    confidence -= 0.4

            # ë²•ë¥  ë°ì´í„°ëŠ” ì‹ ì„ ë„ ê²€ì‚¬ ìƒëµ (í•­ìƒ ìœ íš¨)

        except Exception as e:
            logger.warning(f"Failed to parse timestamp: {e}")
            issues.append("Timestamp parsing failed, cannot verify freshness")
            confidence -= 0.1

    # 4. ê´€ë ¨ì„± ê²€ì‚¬ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­)
    previous_query = metadata.get("query", "")
    if previous_query:
        # ì§€ì—­ ë¹„êµ
        current_regions = self._extract_regions(query)
        previous_regions = self._extract_regions(previous_query)

        if current_regions and previous_regions:
            if not any(r in previous_regions for r in current_regions):
                issues.append(f"Region mismatch: {current_regions} vs {previous_regions}")
                confidence -= 0.4

    # ìµœì¢… íŒë‹¨
    confidence = max(confidence, 0.0)  # ìŒìˆ˜ ë°©ì§€
    is_sufficient = confidence > 0.7 and len(missing) == 0

    return {
        "is_sufficient": is_sufficient,
        "confidence": confidence,
        "source": sufficiency_result.get("data_source", "previous_search"),
        "issues": issues
    }

def _determine_required_data_types_from_query(self, query: str) -> List[str]:
    """ì¿¼ë¦¬ì—ì„œ í•„ìš”í•œ ë°ì´í„° íƒ€ì… ì¶”ë¡  (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­)"""
    types = []

    if any(kw in query for kw in ["ë²•", "ì „ì„¸", "ì„ëŒ€", "ê³„ì•½", "ë³´ì¦ê¸ˆ"]):
        types.append("legal")

    if any(kw in query for kw in ["ì‹œì„¸", "ê°€ê²©", "ë§¤ë§¤", "ê±°ë˜"]):
        types.append("market")

    if any(kw in query for kw in ["ëŒ€ì¶œ", "ê¸ˆë¦¬", "í•œë„"]):
        types.append("loan")

    # ê¸°ë³¸ê°’
    if not types:
        types = ["legal", "market"]

    return types

def _extract_regions(self, text: str) -> List[str]:
    """í…ìŠ¤íŠ¸ì—ì„œ ì§€ì—­ ì¶”ì¶œ"""
    regions = ["ê°•ë‚¨êµ¬", "ê°•ë¶êµ¬", "ê°•ë™êµ¬", "ê°•ì„œêµ¬", "ê´€ì•…êµ¬", "ê´‘ì§„êµ¬", "êµ¬ë¡œêµ¬",
              "ê¸ˆì²œêµ¬", "ë…¸ì›êµ¬", "ë„ë´‰êµ¬", "ë™ëŒ€ë¬¸êµ¬", "ë™ì‘êµ¬", "ë§ˆí¬êµ¬", "ì„œëŒ€ë¬¸êµ¬",
              "ì„œì´ˆêµ¬", "ì„±ë™êµ¬", "ì„±ë¶êµ¬", "ì†¡íŒŒêµ¬", "ì–‘ì²œêµ¬", "ì˜ë“±í¬êµ¬", "ìš©ì‚°êµ¬",
              "ì€í‰êµ¬", "ì¢…ë¡œêµ¬", "ì¤‘êµ¬", "ì¤‘ë‘êµ¬"]

    found = []
    for region in regions:
        if region in text:
            found.append(region)

    return found
```

### 6.3 Phase 3: Hybrid í†µí•© ë° ìµœì í™”

#### Step 1: State ê³µìœ  ìµœì í™”

**íŒŒì¼ ìˆ˜ì •**: `backend/app/service_agent/foundation/separated_states.py`

```python
# separated_states.py - SharedState í™•ì¥

class SharedState(TypedDict, total=False):
    # ... (ê¸°ì¡´ í•„ë“œ)

    # ğŸ†• Phase 3: ë°ì´í„° ì¬ì‚¬ìš© ê´€ë ¨ í•„ë“œ
    previous_search_results: Optional[Dict]           # ì´ì „ ê²€ìƒ‰ ê²°ê³¼
    previous_search_metadata: Optional[Dict]          # íƒ€ì„ìŠ¤íƒ¬í”„, ì¿¼ë¦¬ ë“±
    sufficiency_result: Optional[Dict]                # Supervisor ì¶©ë¶„ì„± íŒë‹¨
    verify_search_data: bool                          # 2ì°¨ ê²€ì¦ í•„ìš” ì—¬ë¶€
```

#### Step 2: A/B í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬

**íŒŒì¼ ìƒì„±**: `backend/app/service_agent/evaluation/ab_test.py`

```python
"""
A/B í…ŒìŠ¤íŠ¸: ë°ì´í„° ì¶©ë¶„ì„± íŒë‹¨ ì •í™•ë„ í‰ê°€
"""

import logging
from typing import Dict, Any, List
from datetime import datetime

logger = logging.getLogger(__name__)


class ABTestTracker:
    """
    A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¶”ì 

    Variant A: Supervisor ë ˆë²¨ë§Œ
    Variant B: Hybrid (Supervisor + Execute Node)
    """

    def __init__(self):
        self.results = {
            "variant_a": [],  # Supervisor only
            "variant_b": []   # Hybrid
        }

    def log_decision(
        self,
        variant: str,
        query: str,
        supervisor_decision: Dict,
        execute_node_decision: Optional[Dict],
        actual_result: str,  # "correct_skip" | "incorrect_skip" | "correct_search" | "incorrect_search"
        execution_time: float
    ):
        """A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¡œê¹…"""
        self.results[variant].append({
            "timestamp": datetime.now().isoformat(),
            "query": query,
            "supervisor_decision": supervisor_decision,
            "execute_node_decision": execute_node_decision,
            "actual_result": actual_result,
            "execution_time": execution_time
        })

    def get_metrics(self, variant: str) -> Dict:
        """ì§€í‘œ ê³„ì‚°"""
        results = self.results[variant]

        if not results:
            return {}

        total = len(results)
        correct_skips = sum(1 for r in results if r["actual_result"] == "correct_skip")
        incorrect_skips = sum(1 for r in results if r["actual_result"] == "incorrect_skip")
        correct_searches = sum(1 for r in results if r["actual_result"] == "correct_search")
        incorrect_searches = sum(1 for r in results if r["actual_result"] == "incorrect_search")

        accuracy = (correct_skips + correct_searches) / total if total > 0 else 0.0
        avg_time = sum(r["execution_time"] for r in results) / total if total > 0 else 0.0

        return {
            "total_requests": total,
            "correct_skips": correct_skips,
            "incorrect_skips": incorrect_skips,
            "correct_searches": correct_searches,
            "incorrect_searches": incorrect_searches,
            "accuracy": accuracy,
            "avg_execution_time": avg_time,
            "skip_rate": (correct_skips + incorrect_skips) / total if total > 0 else 0.0
        }
```

#### Step 3: Human-in-the-Loop í†µí•©

**íŒŒì¼ ìˆ˜ì •**: `backend/app/service_agent/supervisor/team_supervisor.py`

```python
# planning_node() ë‚´ë¶€ - ì¶©ë¶„ì„± íŒë‹¨ í›„

if sufficiency_result["is_sufficient"] and 0.6 < sufficiency_result["confidence"] <= 0.9:
    # ğŸ†• Phase 3: ì¤‘ê°„ í™•ì‹ ë„ â†’ ì‚¬ìš©ì í™•ì¸ ìš”ì²­
    logger.info("[Sufficiency Check] Medium confidence, requesting user confirmation")

    session_id = state.get("session_id")
    progress_callback = self._progress_callbacks.get(session_id) if session_id else None

    if progress_callback:
        try:
            # ì‚¬ìš©ì í™•ì¸ ìš”ì²­
            await progress_callback("user_confirmation_required", {
                "confirmation_id": f"conf_{datetime.now().timestamp()}",
                "message": "ì´ì „ ëŒ€í™”ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
                "context": {
                    "previous_data_summary": self._summarize_previous_data(sufficiency_result),
                    "data_age": self._calculate_data_age(sufficiency_result),
                    "uncertainty_reason": sufficiency_result.get("reasoning", "")
                },
                "options": [
                    {
                        "value": "use_previous",
                        "label": "ì˜ˆ, ì´ì „ ë°ì´í„° ì‚¬ìš©",
                        "description": "ê²€ìƒ‰ ì‹œê°„ 3~5ì´ˆ ë‹¨ì¶•"
                    },
                    {
                        "value": "search_new",
                        "label": "ì•„ë‹ˆìš”, ìµœì‹  ì •ë³´ ê²€ìƒ‰",
                        "description": "ìµœì‹  ë°ì´í„°ë¡œ ë¶„ì„"
                    }
                ]
            })

            # ì‚¬ìš©ì ì‘ë‹µ ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒ 30ì´ˆ)
            user_choice = await self._wait_for_user_confirmation(session_id, timeout=30.0)

            if user_choice == "use_previous":
                # SearchTeam ì œì™¸
                skip_search = True
                state["data_reused"] = True
                state["user_confirmed"] = True
            else:
                # ìƒˆ ê²€ìƒ‰
                skip_search = False
                state["user_confirmed"] = False

        except asyncio.TimeoutError:
            # íƒ€ì„ì•„ì›ƒ â†’ ì•ˆì „í•˜ê²Œ ìƒˆ ê²€ìƒ‰
            logger.warning("[Sufficiency Check] User confirmation timeout, performing new search")
            skip_search = False
        except Exception as e:
            logger.error(f"User confirmation failed: {e}")
            skip_search = False
```

---

## 7. ê²°ë¡ 

### 7.1 ìµœì¢… ê¶Œì¥ì‚¬í•­

**âœ… Hybrid ì ‘ê·¼ ë°©ì‹ì´ ìµœì **

1. **Supervisor ë ˆë²¨ (1ì°¨ íŒë‹¨)**:
   - LLM ê¸°ë°˜ ë°ì´í„° ì¶©ë¶„ì„± íŒë‹¨
   - ëª…í™•í•œ ê²½ìš° (confidence > 0.9) SearchTeam ì œì™¸
   - ì‚¬ìš©ìì—ê²Œ ì‚¬ì „ ì•Œë¦¼ ê°€ëŠ¥

2. **Execute Node ë ˆë²¨ (2ì°¨ ê²€ì¦)**:
   - ê·œì¹™ ê¸°ë°˜ ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬
   - ë¶ˆí™•ì‹¤í•œ ê²½ìš° ì•ˆì „ë§ ì—­í• 
   - Checkpointing í™œìš©í•œ ì´ì „ ë°ì´í„° ë¡œë“œ

3. **Human-in-the-Loop (3ì°¨ í™•ì¸)**:
   - ì¤‘ê°„ í™•ì‹ ë„ ì‹œ ì‚¬ìš©ì í™•ì¸
   - íˆ¬ëª…ì„± ë° ì‹ ë¢°ë„ í–¥ìƒ

### 7.2 êµ¬í˜„ ìš°ì„ ìˆœìœ„

| Phase | êµ¬í˜„ ë‚´ìš© | ì†Œìš” ì‹œê°„ | ì˜ˆìƒ íš¨ê³¼ |
|-------|---------|---------|---------|
| **Phase 1** | Supervisor ë ˆë²¨ êµ¬í˜„ | 1ì£¼ (3~5ì¼) | 30% ì¿¼ë¦¬ ìµœì í™” |
| **Phase 2** | Execute Node ê³ ë„í™” | 2ì£¼ (ì¶”ê°€ 3~5ì¼) | 50% ì¿¼ë¦¬ ìµœì í™” |
| **Phase 3** | Hybrid í†µí•© + HIL | 3ì£¼ (ì¶”ê°€ 5~7ì¼) | 60~70% ì¿¼ë¦¬ ìµœì í™” |

### 7.3 ê¸°ëŒ€ íš¨ê³¼

**ì„±ëŠ¥**:
- SearchTeam ê±´ë„ˆë›°ê¸°: **3~5ì´ˆ ë‹¨ì¶•**
- ì „ì²´ ì‘ë‹µ ì‹œê°„: **60% ê°ì†Œ** (ìµœì  ì¼€ì´ìŠ¤)

**ë¹„ìš©**:
- LLM í˜¸ì¶œ ê°ì†Œ: **40~50% ì ˆê°**
- ê²€ìƒ‰ ë„êµ¬ í˜¸ì¶œ ê°ì†Œ: **60~70% ì ˆê°**

**ì‚¬ìš©ì ê²½í—˜**:
- ë°˜ì‘ ì†ë„ í–¥ìƒ
- íˆ¬ëª…í•œ ì˜ì‚¬ê²°ì •
- ì‹ ë¢°ë„ í–¥ìƒ

### 7.4 ë¦¬ìŠ¤í¬ ë° ëŒ€ì‘

| ë¦¬ìŠ¤í¬ | í™•ë¥  | ì˜í–¥ë„ | ëŒ€ì‘ ë°©ì•ˆ |
|--------|------|--------|----------|
| LLM ì˜¤íŒë‹¨ | ì¤‘ê°„ | ë†’ìŒ | Execute Node 2ì°¨ ê²€ì¦ |
| Checkpointing ì‹¤íŒ¨ | ë‚®ìŒ | ì¤‘ê°„ | Fallback to ìƒˆ ê²€ìƒ‰ |
| ì‚¬ìš©ì í˜¼ë€ | ë‚®ìŒ | ë‚®ìŒ | ëª…í™•í•œ ì•Œë¦¼ ë©”ì‹œì§€ |
| êµ¬í˜„ ë³µì¡ë„ | ë†’ìŒ | ì¤‘ê°„ | ë‹¨ê³„ë³„ êµ¬í˜„ |

---

**ë³´ê³ ì„œ ì‘ì„± ì™„ë£Œ**
**ì‘ì„±ì**: Claude Code
**ì‘ì„±ì¼**: 2025-10-22
**ë²„ì „**: 1.0

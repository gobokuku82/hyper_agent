# ì§€ëŠ¥í˜• ë°ì´í„° ì¬ì‚¬ìš© ì‹œìŠ¤í…œ - ìµœì¢… í†µí•© ë³´ê³ ì„œ

**ì‘ì„±ì¼**: 2025-10-22
**ë²„ì „**: 2.0 (Final)
**ì‹œìŠ¤í…œ**: LangGraph 0.6 Multi-Agent ì±—ë´‡
**ëª©í‘œ**: ì±„íŒ… íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ë°ì´í„° ì¬ì‚¬ìš©ìœ¼ë¡œ ì‘ë‹µ ì‹œê°„ 60% ë‹¨ì¶•

---

## ğŸ“‹ Executive Summary

### í•µì‹¬ ëª©í‘œ

**"ì±„íŒ… íˆìŠ¤í† ë¦¬ì— í•„ìš”í•œ ë°ì´í„°ê°€ ìˆë‹¤ë©´, ì •ë³´ê²€ìƒ‰ ì—ì´ì „íŠ¸ë¥¼ ê±´ë„ˆë›°ê³  ë¶„ì„ ì—ì´ì „íŠ¸ë¥¼ ì§ì ‘ ì‹¤í–‰"**

### í†µí•© ì†”ë£¨ì…˜: 3-Tier Intelligent Data Reuse System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tier 1: Planning Agent (LLM-based Sufficiency Check)      â”‚
â”‚ â”œâ”€ Intent + Entity ë¶„ì„                                    â”‚
â”‚ â”œâ”€ íŒŒë¼ë¯¸í„° ë¹„êµ (ì´ì „ ëŒ€í™” vs í˜„ì¬ ìš”ì²­)                    â”‚
â”‚ â””â”€ Confidence > 0.9 â†’ SearchTeam ì œì™¸                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Tier 2: Execute Node (Rule-based Quality Check)           â”‚
â”‚ â”œâ”€ Checkpointing ë°ì´í„° ë¡œë“œ                                â”‚
â”‚ â”œâ”€ ë°ì´í„° í’ˆì§ˆ ê²€ì¦ (ì™„ì „ì„±, ì‹ ì„ ë„, ê´€ë ¨ì„±)                  â”‚
â”‚ â””â”€ Quality Score > 0.7 â†’ ê²€ìƒ‰ ê±´ë„ˆë›°ê¸°                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Tier 3: Human-in-the-Loop (User Confirmation)             â”‚
â”‚ â”œâ”€ Confidence 0.6~0.9 â†’ ì‚¬ìš©ì í™•ì¸ ìš”ì²­                    â”‚
â”‚ â””â”€ ì‚¬ìš©ì ì„ íƒì— ë”°ë¼ ì¬ì‚¬ìš© or ìƒˆ ê²€ìƒ‰                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ì˜ˆìƒ íš¨ê³¼

| ì§€í‘œ | í˜„ì¬ | êµ¬í˜„ í›„ | ê°œì„ ìœ¨ |
|------|------|---------|--------|
| **í‰ê·  ì‘ë‹µ ì‹œê°„** | 8~10ì´ˆ | 3~5ì´ˆ | **60%â†“** |
| **SearchTeam í˜¸ì¶œ** | 100% | 30~40% | **60~70%â†“** |
| **LLM í˜¸ì¶œ ë¹„ìš©** | 100% | 50~60% | **40~50%â†“** |
| **ì •í™•ë„** | 85% | 95%+ | **10%â†‘** |

---

## ğŸ“‹ ëª©ì°¨

1. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#1-ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
2. [í•µì‹¬ ê°œë… ë° ì •ì˜](#2-í•µì‹¬-ê°œë…-ë°-ì •ì˜)
3. [ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„](#3-ë‹¤ì–‘í•œ-ì‹œë‚˜ë¦¬ì˜¤-ë¶„ì„)
4. [ê³ ë„í™”ëœ ë¡œì§ ì„¤ê³„](#4-ê³ ë„í™”ëœ-ë¡œì§-ì„¤ê³„)
5. [ì™„ì „í•œ êµ¬í˜„ ì½”ë“œ](#5-ì™„ì „í•œ-êµ¬í˜„-ì½”ë“œ)
6. [í…ŒìŠ¤íŠ¸ ì „ëµ](#6-í…ŒìŠ¤íŠ¸-ì „ëµ)
7. [ë°°í¬ ê°€ì´ë“œ](#7-ë°°í¬-ê°€ì´ë“œ)
8. [FAQ ë° íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#8-faq-ë°-íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

---

## 1. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 1.1 ì „ì²´ ì›Œí¬í”Œë¡œìš°

```
ì‚¬ìš©ì ì¿¼ë¦¬
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Initialize Node                                      â”‚
â”‚    â””â”€ State ì´ˆê¸°í™”                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Planning Node (Tier 1 - LLM Intelligence)           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ 2.1 Chat History & Long-term Memory ë¡œë“œ          â”‚   â”‚
â”‚ â”‚     â””â”€ ìµœê·¼ 3ê°œ ëŒ€í™” + 3-Tier Memory              â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ 2.2 Intent & Entity ë¶„ì„ (LLM #1)                 â”‚   â”‚
â”‚ â”‚     â”œâ”€ Intent: MARKET_INQUIRY                     â”‚   â”‚
â”‚ â”‚     â””â”€ Entities: {region: "ê°•ë‚¨êµ¬", type: "ì•„íŒŒíŠ¸"} â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ 2.3 ì´ì „ ëŒ€í™”ì˜ Intent & Entities ë¡œë“œ             â”‚   â”‚
â”‚ â”‚     â””â”€ Checkpointingì—ì„œ ì¶”ì¶œ                      â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ 2.4 íŒŒë¼ë¯¸í„° ë¹„êµ (ê·œì¹™ ê¸°ë°˜)                       â”‚   â”‚
â”‚ â”‚     â”œâ”€ Intent ì¼ì¹˜? (MARKET â†” MARKET)            â”‚   â”‚
â”‚ â”‚     â”œâ”€ Region ì¼ì¹˜? (ê°•ë‚¨êµ¬ â†” ê°•ë‚¨êµ¬)              â”‚   â”‚
â”‚ â”‚     â””â”€ Match Score: 1.0                           â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ 2.5 ë°ì´í„° ì¶©ë¶„ì„± íŒë‹¨ (LLM #2)                     â”‚   â”‚
â”‚ â”‚     â”œâ”€ Match Score ê³ ë ¤                            â”‚   â”‚
â”‚ â”‚     â”œâ”€ ì‹ ì„ ë„ ê²€ì‚¬ (3ë¶„ ì „)                         â”‚   â”‚
â”‚ â”‚     â””â”€ Confidence: 0.95                           â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ 2.6 ê²°ì •                                           â”‚   â”‚
â”‚ â”‚     Confidence > 0.9 â†’ active_teams = ["analysis"]â”‚   â”‚
â”‚ â”‚     0.6~0.9 â†’ verify_search_data = True           â”‚   â”‚
â”‚ â”‚     < 0.6 â†’ active_teams = ["search", "analysis"] â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Execute Teams Node                                   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ 3.1 "search" in active_teams?                     â”‚   â”‚
â”‚ â”‚     â”œâ”€ Yes â†’ SearchExecutor í˜¸ì¶œ                   â”‚   â”‚
â”‚ â”‚     â””â”€ No â†’ AnalysisExecutor ì§ì ‘ í˜¸ì¶œ             â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ 3.2 SearchExecutor (Tier 2 - Rule-based)         â”‚   â”‚
â”‚ â”‚     â”œâ”€ Checkpointing ë°ì´í„° ë¡œë“œ                   â”‚   â”‚
â”‚ â”‚     â”œâ”€ ë°ì´í„° í’ˆì§ˆ ê²€ì¦ (ê·œì¹™ ê¸°ë°˜)                 â”‚   â”‚
â”‚ â”‚     â”‚   â”œâ”€ ì™„ì „ì„±: í•„ìš” ë°ì´í„° íƒ€ì… ëª¨ë‘ ìˆëŠ”ê°€?    â”‚   â”‚
â”‚ â”‚     â”‚   â”œâ”€ ì‹ ì„ ë„: ì‹œì„¸ < 7ì¼, ëŒ€ì¶œ < 1ì¼          â”‚   â”‚
â”‚ â”‚     â”‚   â””â”€ ê´€ë ¨ì„±: ì§€ì—­/ê¸ˆì•¡ ì •í™• ì¼ì¹˜             â”‚   â”‚
â”‚ â”‚     â””â”€ Quality > 0.7 â†’ skip, else â†’ ìƒˆ ê²€ìƒ‰       â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Aggregate & Generate Response                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 í•µì‹¬ ì»´í¬ë„ŒíŠ¸

| ì»´í¬ë„ŒíŠ¸ | ì—­í•  | ì…ë ¥ | ì¶œë ¥ |
|---------|------|------|------|
| **PlanningAgent** | Intent ë¶„ì„, ì¶©ë¶„ì„± íŒë‹¨ | Query, Chat History | IntentResult, SufficiencyResult |
| **DataReusabilityChecker** | íŒŒë¼ë¯¸í„° ë¹„êµ | Current Intent, Previous Intent | MatchResult |
| **SearchExecutor** | ê²€ìƒ‰ ì‹¤í–‰ ë˜ëŠ” ê±´ë„ˆë›°ê¸° | SharedState, Previous Data | SearchTeamState |
| **QualityValidator** | ë°ì´í„° í’ˆì§ˆ ê²€ì¦ | Previous Data | QualityScore |
| **HumanInTheLoopManager** | ì‚¬ìš©ì í™•ì¸ ìš”ì²­ | Confidence, Context | User Choice |

---

## 2. í•µì‹¬ ê°œë… ë° ì •ì˜

### 2.1 Intent & Entities

**Intent (ì˜ë„)**:
ì‚¬ìš©ìê°€ ë¬´ì—‡ì„ í•˜ê³  ì‹¶ì€ì§€ (MARKET_INQUIRY, LEGAL_CONSULT, ...)

**Entities (í•µì‹¬ íŒŒë¼ë¯¸í„°)**:
Intentë¥¼ êµ¬ì²´í™”í•˜ëŠ” ì¡°ê±´ (ì§€ì—­, ê¸ˆì•¡, ë¬¼ê±´ ì¢…ë¥˜ ë“±)

```python
# ì˜ˆì‹œ
Query: "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ì „ì„¸ ì‹œì„¸ 5ì–µ ì´í•˜"

Intent: MARKET_INQUIRY
Entities: {
    "region": "ê°•ë‚¨êµ¬",
    "property_type": "ì•„íŒŒíŠ¸",
    "transaction_type": "ì „ì„¸",
    "max_price": 500000000
}
```

### 2.2 ë°ì´í„° ì¬ì‚¬ìš© ì¡°ê±´

**3ê°€ì§€ í•„ìˆ˜ ì¡°ê±´**:

1. **Intent ì¼ì¹˜**: í˜„ì¬ Intent == ì´ì „ Intent
2. **Entities ì¼ì¹˜**: í•µì‹¬ íŒŒë¼ë¯¸í„° 80%+ ì¼ì¹˜
3. **ì‹ ì„ ë„ ì¶©ì¡±**: Intentë³„ ê¸°ì¤€ (MARKET: 7ì¼, LOAN: 1ì¼, LEGAL: ë¬´ì œí•œ)

### 2.3 Confidence Score ê³„ì‚°

```python
Confidence = (
    Intent_Match_Score * 0.3 +
    Entity_Match_Score * 0.4 +
    Freshness_Score * 0.2 +
    Data_Quality_Score * 0.1
)

# ì˜ˆì‹œ
Intent Match: 1.0 (ë™ì¼)
Entity Match: 1.0 (ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ == ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸)
Freshness: 1.0 (3ë¶„ ì „, ê¸°ì¤€ 7ì¼)
Quality: 0.9 (ë°ì´í„° 10ê°œ, ê¸°ì¤€ 3ê°œ)

Confidence = 1.0*0.3 + 1.0*0.4 + 1.0*0.2 + 0.9*0.1 = 0.99
```

### 2.4 Intentë³„ ì¬ì‚¬ìš© ì •ì±…

| Intent | í•µì‹¬ Entities | ì¼ì¹˜ ê¸°ì¤€ | ì‹ ì„ ë„ ê¸°ì¤€ | ì¬ì‚¬ìš© ì „ëµ |
|--------|--------------|---------|-----------|-----------|
| **MARKET_INQUIRY** | region, property_type, transaction_type | ì •í™• ì¼ì¹˜ | 7ì¼ | ì§€ì—­/íƒ€ì… ë‹¤ë¥´ë©´ ë¬´ì¡°ê±´ ìƒˆ ê²€ìƒ‰ |
| **LEGAL_CONSULT** | legal_topic, amount | ì£¼ì œ ìœ ì‚¬, ê¸ˆì•¡ Â±30% | ë¬´ì œí•œ (ë²• ê°œì • ì œì™¸) | ì£¼ì œ ê°™ìœ¼ë©´ ì¬ì‚¬ìš© ê°€ëŠ¥ |
| **LOAN_CONSULT** | loan_type, amount, income | íƒ€ì… ì¼ì¹˜, ê¸ˆì•¡ Â±20% | 1ì¼ | ê¸ˆì•¡ ì°¨ì´ í¬ë©´ ìƒˆ ê²€ìƒ‰ |
| **CONTRACT_CREATION** | contract_type | - | - | **ì¬ì‚¬ìš© ë¶ˆê°€** (ë§¤ë²ˆ ìƒˆë¡œ ì‘ì„±) |
| **CONTRACT_REVIEW** | contract_hash | ì •í™• ì¼ì¹˜ | ë¬´ì œí•œ | ë™ì¼ ê³„ì•½ì„œë§Œ ì¬ì‚¬ìš© |
| **COMPREHENSIVE** | ë³µí•© | ëª¨ë“  ì¡°ê±´ ì¶©ì¡± | ê°€ì¥ ì§§ì€ ê¸°ì¤€ | ì—„ê²©í•œ ê¸°ì¤€ ì ìš© |
| **RISK_ANALYSIS** | analysis_target | ì •í™• ì¼ì¹˜ | 7ì¼ | ëŒ€ìƒ ë™ì¼ ì‹œë§Œ ì¬ì‚¬ìš© |

---

## 3. ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„

### 3.1 ê¸°ë³¸ ì‹œë‚˜ë¦¬ì˜¤ (Simple Cases)

#### ì‹œë‚˜ë¦¬ì˜¤ 1: ì™„ì „ ì¼ì¹˜ â†’ ì¬ì‚¬ìš© âœ…

```
[ëŒ€í™” 1]
ì‚¬ìš©ì: "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ì „ì„¸ ì‹œì„¸ ì•Œë ¤ì¤˜"
AI: [SearchTeam ì‹¤í–‰]
    "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ì „ì„¸ ì‹œì„¸ëŠ” í‰ê·  6ì–µì…ë‹ˆë‹¤."
    Intent: MARKET_INQUIRY
    Entities: {region: "ê°•ë‚¨êµ¬", property_type: "ì•„íŒŒíŠ¸", transaction_type: "ì „ì„¸"}

[ëŒ€í™” 2 - 30ì´ˆ í›„]
ì‚¬ìš©ì: "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ë‹¤ì‹œ ì•Œë ¤ì¤˜"
AI: [ë°ì´í„° ì¬ì‚¬ìš© íŒë‹¨]
    Intent ì¼ì¹˜: âœ… MARKET_INQUIRY
    Entities ì¼ì¹˜: âœ… 100% (ê°•ë‚¨êµ¬, ì•„íŒŒíŠ¸, ì „ì„¸ ëª¨ë‘ ë™ì¼)
    ì‹ ì„ ë„: âœ… 30ì´ˆ ì „ (ê¸°ì¤€ 7ì¼)
    Confidence: 0.99

    â†’ SearchTeam ê±´ë„ˆë›°ê¸°, ì´ì „ ë°ì´í„° ì¬ì‚¬ìš©
    "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ì „ì„¸ ì‹œì„¸ëŠ” í‰ê·  6ì–µì…ë‹ˆë‹¤. (ë°©ê¸ˆ ì „ ê²€ìƒ‰ ê²°ê³¼)"
```

**ì ˆê° íš¨ê³¼**: SearchTeam 3~5ì´ˆ ì ˆì•½

---

#### ì‹œë‚˜ë¦¬ì˜¤ 2: ì§€ì—­ ë¶ˆì¼ì¹˜ â†’ ìƒˆ ê²€ìƒ‰ âŒ

```
[ëŒ€í™” 1]
ì‚¬ìš©ì: "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ì „ì„¸ ì‹œì„¸"
AI: "ê°•ë‚¨êµ¬ í‰ê·  6ì–µ"
    Entities: {region: "ê°•ë‚¨êµ¬", property_type: "ì•„íŒŒíŠ¸"}

[ëŒ€í™” 2]
ì‚¬ìš©ì: "ì„œì´ˆêµ¬ëŠ” ì–´ë•Œ?"
AI: [íŒŒë¼ë¯¸í„° ë¹„êµ]
    Intent ì¼ì¹˜: âœ… MARKET_INQUIRY
    Entities ì¼ì¹˜: âŒ 50% (ì§€ì—­ ë¶ˆì¼ì¹˜: ê°•ë‚¨êµ¬ â‰  ì„œì´ˆêµ¬)
    Match Score: 0.5
    Confidence: 0.3

    â†’ ìƒˆ ê²€ìƒ‰ í•„ìš”
    [SearchTeam ì‹¤í–‰] "ì„œì´ˆêµ¬ í‰ê·  7ì–µ"
```

**íŒë‹¨ ê·¼ê±°**: ì§€ì—­ì´ ë‹¤ë¥´ë¯€ë¡œ ë°ì´í„° ê´€ë ¨ì„± ì—†ìŒ

---

### 3.2 ë³µì¡í•œ ì‹œë‚˜ë¦¬ì˜¤ (Complex Cases)

#### ì‹œë‚˜ë¦¬ì˜¤ 3: ê¸ˆì•¡ ë²”ìœ„ ìœ ì‚¬ â†’ ì¡°ê±´ë¶€ ì¬ì‚¬ìš© âš ï¸

```
[ëŒ€í™” 1]
ì‚¬ìš©ì: "5ì–µ ì „ì„¸ìê¸ˆ ëŒ€ì¶œ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?"
AI: [SearchTeam ì‹¤í–‰]
    "5ì–µ ê¸°ì¤€ ìµœëŒ€ 4.5ì–µ ëŒ€ì¶œ ê°€ëŠ¥ (LTV 90%)"
    Intent: LOAN_CONSULT
    Entities: {loan_type: "ì „ì„¸ìê¸ˆëŒ€ì¶œ", amount: 500000000}

[ëŒ€í™” 2 - 10ë¶„ í›„]
ì‚¬ìš©ì: "5.5ì–µìœ¼ë¡œ ì˜¬ë¦¬ë©´ ì–¼ë§ˆê¹Œì§€ ê°€ëŠ¥í•´ìš”?"
AI: [íŒŒë¼ë¯¸í„° ë¹„êµ]
    Intent ì¼ì¹˜: âœ… LOAN_CONSULT
    Entity ì¼ì¹˜:
      - loan_type: âœ… "ì „ì„¸ìê¸ˆëŒ€ì¶œ" (ë™ì¼)
      - amount: âš ï¸ 5.5ì–µ vs 5ì–µ (10% ì°¨ì´)

    ê¸ˆì•¡ ì°¨ì´ íŒë‹¨:
      Diff = |5.5ì–µ - 5ì–µ| / 5ì–µ = 0.1 (10%)
      ê¸°ì¤€: Â±20% ì´ë‚´
      â†’ âœ… í—ˆìš© ë²”ìœ„

    Match Score: 0.95 (loan_type ì™„ì „ì¼ì¹˜, amount ë¶€ë¶„ì¼ì¹˜)
    Confidence: 0.85

    â†’ Tier 3 (Human-in-the-Loop) ë°œë™

    AI: "ì´ì „ ëŒ€ì¶œ ì •ë³´(5ì–µ ê¸°ì¤€)ë¥¼ í™œìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ?
         ê¸ˆì•¡ì´ 10% ì¦ê°€í–ˆìœ¼ë‚˜ LTV ê³„ì‚°ì€ ë™ì¼ ê³µì‹ ì ìš©ë©ë‹ˆë‹¤.

         [ì˜ˆ, í™œìš©] [ì•„ë‹ˆìš”, ìµœì‹  ì •ë³´ ê²€ìƒ‰]"

    ì‚¬ìš©ì: "ì˜ˆ, í™œìš©"

    AI: [AnalysisTeamë§Œ ì‹¤í–‰]
    "5.5ì–µ ê¸°ì¤€ ìµœëŒ€ 4.95ì–µ ëŒ€ì¶œ ê°€ëŠ¥ (LTV 90%)"
```

**ì ˆê° íš¨ê³¼**: SearchTeam ê±´ë„ˆë›°ê¸° + ì‚¬ìš©ì íˆ¬ëª…ì„± í™•ë³´

---

#### ì‹œë‚˜ë¦¬ì˜¤ 4: Intent ì „í™˜ â†’ ë¶€ë¶„ ì¬ì‚¬ìš© ğŸ”„

```
[ëŒ€í™” 1]
ì‚¬ìš©ì: "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ì‹œì„¸ ì•Œë ¤ì¤˜"
AI: "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ í‰ê·  6ì–µ"
    Intent: MARKET_INQUIRY
    Entities: {region: "ê°•ë‚¨êµ¬", property_type: "ì•„íŒŒíŠ¸"}
    SearchTeam Results: {
        legal_search: [],
        real_estate_search: [{region: "ê°•ë‚¨êµ¬", avg: 600000000}],
        loan_search: []
    }

[ëŒ€í™” 2]
ì‚¬ìš©ì: "ì´ ê°€ê²©ìœ¼ë¡œ ëŒ€ì¶œ ì–¼ë§ˆ ë°›ì„ ìˆ˜ ìˆì–´?"
AI: [Intent ë³€ê²½ ê°ì§€]
    Previous Intent: MARKET_INQUIRY
    Current Intent: LOAN_CONSULT
    Intent ì¼ì¹˜: âŒ

    í•˜ì§€ë§Œ ì´ì „ ë°ì´í„° í™œìš© ê°€ëŠ¥ì„± ê²€í† :
    - real_estate_search ë°ì´í„° ìˆìŒ (ê°€ê²© ì •ë³´)
    - LOAN_CONSULTì— í•„ìš”: ê¸ˆì•¡ (available)

    â†’ SearchTeam ë¶€ë¶„ ì‹¤í–‰
      â”œâ”€ legal_search: skip (ë¶ˆí•„ìš”)
      â”œâ”€ real_estate_search: skip (ì´ì „ ë°ì´í„° ì¬ì‚¬ìš©)
      â””â”€ loan_search: ì‹¤í–‰ (ìƒˆë¡œ í•„ìš”)

    [SearchTeam ë¶€ë¶„ ì‹¤í–‰] "6ì–µ ê¸°ì¤€ ìµœëŒ€ 5.4ì–µ ëŒ€ì¶œ"
```

**ê³ ë„í™” í¬ì¸íŠ¸**: Intent ë³€ê²½í•´ë„ ë°ì´í„° ë¶€ë¶„ ì¬ì‚¬ìš©

---

#### ì‹œë‚˜ë¦¬ì˜¤ 5: ì—°ì† ë¶„ì„ ìš”ì²­ â†’ ì „ì²´ ì¬ì‚¬ìš© ğŸ”—

```
[ëŒ€í™” 1]
ì‚¬ìš©ì: "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ì‹œì„¸"
AI: "í‰ê·  6ì–µ"
    SearchTeam Results: {real_estate_search: [...]}

[ëŒ€í™” 2]
ì‚¬ìš©ì: "ìœ„í—˜ë„ ë¶„ì„í•´ì¤˜"
AI: [Intent ë³€ê²½]
    Current Intent: RISK_ANALYSIS
    Previous Intent: MARKET_INQUIRY

    í•„ìš” ë°ì´í„°: real_estate_search, legal_search
    ì´ì „ ë°ì´í„°: real_estate_search âœ…, legal_search âŒ

    â†’ SearchTeam ë¶€ë¶„ ì‹¤í–‰
      â”œâ”€ real_estate_search: skip (ì¬ì‚¬ìš©)
      â””â”€ legal_search: ì‹¤í–‰

    [AnalysisTeam ì‹¤í–‰] "ìœ„í—˜ë„ ì¤‘ê°„ (ë²•ì  ì´ìŠˆ ì—†ìŒ)"

[ëŒ€í™” 3]
ì‚¬ìš©ì: "íˆ¬ì ìˆ˜ìµë¥ ì€?"
AI: [Intent ë³€ê²½]
    Current Intent: COMPREHENSIVE (íˆ¬ì ë¶„ì„)

    í•„ìš” ë°ì´í„°: real_estate_search, legal_search, loan_search
    ì´ì „ ë°ì´í„°:
      - real_estate_search: âœ… (ëŒ€í™” 1)
      - legal_search: âœ… (ëŒ€í™” 2)
      - loan_search: âŒ

    â†’ SearchTeam ë¶€ë¶„ ì‹¤í–‰
      â””â”€ loan_searchë§Œ ì‹¤í–‰

    [AnalysisTeam ì‹¤í–‰] "ì˜ˆìƒ ìˆ˜ìµë¥  3.2%"
```

**ê³ ë„í™” í¬ì¸íŠ¸**: ì—¬ëŸ¬ ëŒ€í™”ì˜ ë°ì´í„° ëˆ„ì  í™œìš©

---

### 3.3 ì—£ì§€ ì¼€ì´ìŠ¤ (Edge Cases)

#### ì—£ì§€ ì¼€ì´ìŠ¤ 1: ëª¨í˜¸í•œ ëŒ€ëª…ì‚¬ ì²˜ë¦¬

```
[ëŒ€í™” 1]
ì‚¬ìš©ì: "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ì‹œì„¸"
AI: "í‰ê·  6ì–µ"
    Entities: {region: "ê°•ë‚¨êµ¬", property_type: "ì•„íŒŒíŠ¸"}

[ëŒ€í™” 2]
ì‚¬ìš©ì: "ê±°ê¸° ëŒ€ì¶œì€?"
AI: [Entity Resolution]
    "ê±°ê¸°" â†’ Coreference Resolution â†’ "ê°•ë‚¨êµ¬"

    Resolved Entities: {region: "ê°•ë‚¨êµ¬", loan_type: "ì£¼íƒë‹´ë³´ëŒ€ì¶œ"}

    â†’ Intent ë³€ê²½ì´ì§€ë§Œ ì§€ì—­ ì •ë³´ ì¬ì‚¬ìš© ê°€ëŠ¥
```

**êµ¬í˜„**: Coreference Resolution ì¶”ê°€ í•„ìš”

---

#### ì—£ì§€ ì¼€ì´ìŠ¤ 2: ë‹¤ì¤‘ ì§€ì—­ ë¹„êµ ìš”ì²­

```
[ëŒ€í™” 1]
ì‚¬ìš©ì: "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ì‹œì„¸"
AI: "í‰ê·  6ì–µ"

[ëŒ€í™” 2]
ì‚¬ìš©ì: "ì„œì´ˆêµ¬, ì†¡íŒŒêµ¬ë‘ ë¹„êµí•´ì¤˜"
AI: [ë‹¤ì¤‘ ì§€ì—­ ê°ì§€]
    Entities: {regions: ["ê°•ë‚¨êµ¬", "ì„œì´ˆêµ¬", "ì†¡íŒŒêµ¬"]}

    ì´ì „ ë°ì´í„°: ê°•ë‚¨êµ¬ âœ…

    â†’ SearchTeam ë¶€ë¶„ ì‹¤í–‰
      â”œâ”€ ê°•ë‚¨êµ¬: skip (ì¬ì‚¬ìš©)
      â””â”€ ì„œì´ˆêµ¬, ì†¡íŒŒêµ¬: ì‹¤í–‰

    [AnalysisTeam ë¹„êµ ë¶„ì„]
    "ê°•ë‚¨ 6ì–µ, ì„œì´ˆ 7ì–µ, ì†¡íŒŒ 5.5ì–µ"
```

**ê³ ë„í™” í¬ì¸íŠ¸**: ë°°ì—´ í˜•íƒœ Entity ì²˜ë¦¬

---

#### ì—£ì§€ ì¼€ì´ìŠ¤ 3: ì‹œê°„ ê²½ê³¼ í›„ ì¬ì§ˆë¬¸

```
[ëŒ€í™” 1]
ì‚¬ìš©ì: "ê°•ë‚¨êµ¬ ì‹œì„¸"
AI: "í‰ê·  6ì–µ" (2ì£¼ ì „)

[ëŒ€í™” 2 - 2ì£¼ í›„]
ì‚¬ìš©ì: "ê°•ë‚¨êµ¬ ì‹œì„¸"
AI: [ì‹ ì„ ë„ ê²€ì‚¬]
    ë°ì´í„° ë‚˜ì´: 14ì¼
    ê¸°ì¤€: 7ì¼

    ì‹ ì„ ë„: âŒ ê¸°ì¤€ ì´ˆê³¼
    Confidence: 0.4

    â†’ ìƒˆ ê²€ìƒ‰ í•„ìš”
    [SearchTeam ì‹¤í–‰] "í‰ê·  6.2ì–µ (ìƒìŠ¹)"
```

**íŒë‹¨ ê·¼ê±°**: ì‹œì„¸ ë°ì´í„°ëŠ” ì‹ ì„ ë„ ì¤‘ìš”

---

#### ì—£ì§€ ì¼€ì´ìŠ¤ 4: ë²•ë¥  ê°œì • ê°ì§€

```
[ëŒ€í™” 1]
ì‚¬ìš©ì: "ì „ì„¸ê¸ˆ ì¸ìƒ í•œë„ëŠ”?"
AI: "5% ì´ë‚´" (2024ë…„ ë²•ë¥  ê¸°ì¤€)
    Entities: {legal_topic: "ì „ì„¸ê¸ˆ_ì¸ìƒ"}

[ëŒ€í™” 2 - ë²• ê°œì • í›„]
ì‚¬ìš©ì: "ì „ì„¸ê¸ˆ ì¸ìƒ í•œë„ ë‹¤ì‹œ ì•Œë ¤ì¤˜"
AI: [ë²•ë¥  ê°œì • ê°ì§€]
    Legal Database Version Check:
      - ì´ì „ ë²„ì „: 2024-01-01
      - í˜„ì¬ ë²„ì „: 2025-03-15
      â†’ ë³€ê²½ ê°ì§€

    Confidence: 0.0 (ë²•ë¥  ë³€ê²½ìœ¼ë¡œ ë¬´íš¨í™”)

    â†’ ìƒˆ ê²€ìƒ‰ í•„ìš”
    [SearchTeam ì‹¤í–‰] "7%ë¡œ ìƒí–¥ ì¡°ì •ë¨"
```

**êµ¬í˜„**: Legal DBì— ë²„ì „ ê´€ë¦¬ ì¶”ê°€

---

### 3.4 ì„±ëŠ¥ ìµœì í™” ì‹œë‚˜ë¦¬ì˜¤

#### ì‹œë‚˜ë¦¬ì˜¤ 6: ìºì‹œ íˆíŠ¸ìœ¨ ê·¹ëŒ€í™”

```
[10ë¶„ê°„ 5ê°œ ëŒ€í™”]

ëŒ€í™” 1: "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸" â†’ SearchTeam ì‹¤í–‰ (Cache Miss)
ëŒ€í™” 2: "ê°•ë‚¨êµ¬ ë¶„ì„" â†’ Cache Hit (ì¬ì‚¬ìš©)
ëŒ€í™” 3: "ì„œì´ˆêµ¬ ì•„íŒŒíŠ¸" â†’ SearchTeam ì‹¤í–‰ (ì§€ì—­ ë‹¤ë¦„)
ëŒ€í™” 4: "ê°•ë‚¨êµ¬ ëŒ€ì¶œ" â†’ Partial Hit (ë¶€ë¶„ ì¬ì‚¬ìš©)
ëŒ€í™” 5: "ê°•ë‚¨êµ¬ ìœ„í—˜ë„" â†’ Cache Hit

Cache Hit Rate: 3/5 = 60%
ì ˆê° ì‹œê°„: 3 Ã— 4ì´ˆ = 12ì´ˆ
```

---

## 4. ê³ ë„í™”ëœ ë¡œì§ ì„¤ê³„

### 4.1 Multi-Dimensional Parameter Matching

**ê¸°ì¡´ ë¡œì§ (ë‹¨ìˆœ)**:
```python
# ë‹¨ìˆœ ë¬¸ìì—´ ë¹„êµ
if current_region == previous_region:
    match = True
```

**ê³ ë„í™” ë¡œì§ (ë‹¤ì°¨ì›)**:
```python
class ParameterMatcher:
    """ë‹¤ì°¨ì› íŒŒë¼ë¯¸í„° ë§¤ì¹­"""

    def __init__(self):
        # ì§€ì—­ ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ (ê±°ë¦¬ ê¸°ë°˜)
        self.region_similarity = {
            ("ê°•ë‚¨êµ¬", "ì„œì´ˆêµ¬"): 0.8,  # ì¸ì ‘ ì§€ì—­
            ("ê°•ë‚¨êµ¬", "ì†¡íŒŒêµ¬"): 0.7,
            ("ê°•ë‚¨êµ¬", "ê°•ë¶êµ¬"): 0.1,  # ë¨¼ ì§€ì—­
        }

        # ë²•ë¥  ì£¼ì œ ìœ ì‚¬ë„ (ì˜ë¯¸ ê¸°ë°˜)
        self.legal_topic_similarity = {
            ("ì „ì„¸ê¸ˆ_ì¸ìƒ", "ì „ì„¸ê¸ˆ_ì¸í•˜"): 0.9,  # ê°™ì€ ì¹´í…Œê³ ë¦¬
            ("ì „ì„¸ê¸ˆ_ì¸ìƒ", "ê³„ì•½_ê°±ì‹ "): 0.6,    # ê´€ë ¨ ìˆìŒ
            ("ì „ì„¸ê¸ˆ_ì¸ìƒ", "ëŒ€ì¶œ_í•œë„"): 0.1,    # ë¬´ê´€
        }

    def match_region(
        self,
        current: str,
        previous: str,
        strict: bool = True
    ) -> float:
        """
        ì§€ì—­ ë§¤ì¹­ (ìœ ì—°ì„± ì œì–´ ê°€ëŠ¥)

        Args:
            current: í˜„ì¬ ì§€ì—­
            previous: ì´ì „ ì§€ì—­
            strict: Trueë©´ ì •í™• ì¼ì¹˜ë§Œ, Falseë©´ ìœ ì‚¬ ì§€ì—­ í—ˆìš©

        Returns:
            ìœ ì‚¬ë„ (0~1)
        """
        if current == previous:
            return 1.0

        if strict:
            return 0.0

        # ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ì¡°íšŒ
        similarity = self.region_similarity.get(
            (current, previous),
            self.region_similarity.get((previous, current), 0.0)
        )

        return similarity

    def match_amount(
        self,
        current: float,
        previous: float,
        tolerance: float = 0.2  # Â±20%
    ) -> float:
        """
        ê¸ˆì•¡ ë§¤ì¹­ (í—ˆìš© ë²”ìœ„ ë‚´)

        Returns:
            ìœ ì‚¬ë„ (0~1)
        """
        if previous == 0:
            return 0.0

        diff_ratio = abs(current - previous) / previous

        if diff_ratio <= tolerance:
            # ë²”ìœ„ ë‚´: ì°¨ì´ì— ë”°ë¼ ìœ ì‚¬ë„ ê°ì†Œ
            similarity = 1.0 - (diff_ratio / tolerance) * 0.3
            return similarity
        else:
            # ë²”ìœ„ ì´ˆê³¼
            return 0.0

    def match_legal_topic(
        self,
        current: str,
        previous: str
    ) -> float:
        """
        ë²•ë¥  ì£¼ì œ ë§¤ì¹­ (ì˜ë¯¸ ê¸°ë°˜)

        Returns:
            ìœ ì‚¬ë„ (0~1)
        """
        if current == previous:
            return 1.0

        # ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ì¡°íšŒ
        similarity = self.legal_topic_similarity.get(
            (current, previous),
            self.legal_topic_similarity.get((previous, current), 0.0)
        )

        return similarity
```

**í™œìš© ì˜ˆì‹œ**:
```python
matcher = ParameterMatcher()

# ê°•ë‚¨êµ¬ â†’ ì„œì´ˆêµ¬ (ì¸ì ‘ ì§€ì—­, ë¹„ì—„ê²© ëª¨ë“œ)
similarity = matcher.match_region("ì„œì´ˆêµ¬", "ê°•ë‚¨êµ¬", strict=False)
# â†’ 0.8 (ë¶€ë¶„ ì¬ì‚¬ìš© ê°€ëŠ¥)

# 5ì–µ â†’ 5.5ì–µ (10% ì°¨ì´)
similarity = matcher.match_amount(550000000, 500000000, tolerance=0.2)
# â†’ 0.85 (ì¬ì‚¬ìš© ê°€ëŠ¥)
```

---

### 4.2 Incremental Data Accumulation

**ê°œë…**: ì—¬ëŸ¬ ëŒ€í™”ì˜ ë°ì´í„°ë¥¼ **ëˆ„ì **í•˜ì—¬ í™œìš©

```python
class DataAccumulator:
    """ëŒ€í™” ê°„ ë°ì´í„° ëˆ„ì  ê´€ë¦¬"""

    def __init__(self):
        self.accumulated_data = {
            "legal_search": [],
            "real_estate_search": [],
            "loan_search": []
        }
        self.data_sources = {}  # ë°ì´í„° ì¶œì²˜ ì¶”ì 

    def accumulate(
        self,
        new_data: Dict,
        conversation_id: str,
        timestamp: datetime
    ):
        """
        ìƒˆ ë°ì´í„° ëˆ„ì 

        Args:
            new_data: SearchTeam ê²°ê³¼
            conversation_id: ëŒ€í™” ID
            timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        """
        for data_type, results in new_data.items():
            if results:
                # ë°ì´í„° ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
                self.accumulated_data[data_type].extend(results)
                self.accumulated_data[data_type] = self._deduplicate(
                    self.accumulated_data[data_type]
                )

                # ì¶œì²˜ ê¸°ë¡
                for item in results:
                    item_id = self._get_item_id(item)
                    self.data_sources[item_id] = {
                        "conversation_id": conversation_id,
                        "timestamp": timestamp
                    }

    def get_relevant_data(
        self,
        data_type: str,
        filters: Dict,
        max_age_days: int = 7
    ) -> List[Dict]:
        """
        ê´€ë ¨ ë°ì´í„° ì¡°íšŒ (í•„í„° + ì‹ ì„ ë„)

        Args:
            data_type: "legal_search", "real_estate_search", etc.
            filters: {"region": "ê°•ë‚¨êµ¬"}
            max_age_days: ìµœëŒ€ í—ˆìš© ë‚˜ì´ (ì¼)

        Returns:
            í•„í„°ë§ëœ ë°ì´í„°
        """
        all_data = self.accumulated_data.get(data_type, [])

        filtered = []
        for item in all_data:
            # í•„í„° ì¡°ê±´ í™•ì¸
            if self._matches_filters(item, filters):
                # ì‹ ì„ ë„ í™•ì¸
                item_id = self._get_item_id(item)
                source_info = self.data_sources.get(item_id)
                if source_info:
                    age = (datetime.now() - source_info["timestamp"]).days
                    if age <= max_age_days:
                        filtered.append(item)

        return filtered

    def _matches_filters(self, item: Dict, filters: Dict) -> bool:
        """í•„í„° ì¡°ê±´ ë§¤ì¹­"""
        for key, value in filters.items():
            if item.get(key) != value:
                return False
        return True

    def _deduplicate(self, items: List[Dict]) -> List[Dict]:
        """ì¤‘ë³µ ì œê±° (ID ê¸°ë°˜)"""
        seen = set()
        unique = []
        for item in items:
            item_id = self._get_item_id(item)
            if item_id not in seen:
                unique.append(item)
                seen.add(item_id)
        return unique

    def _get_item_id(self, item: Dict) -> str:
        """ì•„ì´í…œ ê³ ìœ  ID ìƒì„±"""
        # ê°„ë‹¨í•œ í•´ì‹œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë¡œì§ í•„ìš”)
        import hashlib
        item_str = json.dumps(item, sort_keys=True)
        return hashlib.md5(item_str.encode()).hexdigest()
```

**í™œìš© ì‹œë‚˜ë¦¬ì˜¤**:
```python
accumulator = DataAccumulator()

# ëŒ€í™” 1: "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸"
accumulator.accumulate(
    new_data={"real_estate_search": [ê°•ë‚¨êµ¬ ë°ì´í„°]},
    conversation_id="conv_1",
    timestamp=datetime.now()
)

# ëŒ€í™” 2: "ê°•ë‚¨êµ¬ ë²•ë¥ "
accumulator.accumulate(
    new_data={"legal_search": [ì „ì„¸ë²• ë°ì´í„°]},
    conversation_id="conv_2",
    timestamp=datetime.now()
)

# ëŒ€í™” 3: "ê°•ë‚¨êµ¬ ì¢…í•© ë¶„ì„"
# í•„ìš” ë°ì´í„°: real_estate_search, legal_search
real_estate_data = accumulator.get_relevant_data(
    "real_estate_search",
    filters={"region": "ê°•ë‚¨êµ¬"},
    max_age_days=7
)
legal_data = accumulator.get_relevant_data(
    "legal_search",
    filters={},  # ë²•ë¥ ì€ ì§€ì—­ ë¬´ê´€
    max_age_days=365
)

# â†’ ë‘ ëŒ€í™”ì˜ ë°ì´í„° ëª¨ë‘ í™œìš©!
```

---

### 4.3 Intelligent Partial Search

**ê°œë…**: í•„ìš”í•œ ë°ì´í„° íƒ€ì…ë§Œ **ì„ íƒì  ê²€ìƒ‰**

```python
class PartialSearchPlanner:
    """ë¶€ë¶„ ê²€ìƒ‰ ê³„íš ìˆ˜ë¦½"""

    def plan_partial_search(
        self,
        required_data_types: List[str],  # ["legal", "market", "loan"]
        available_data: Dict,  # ì´ì „ ëŒ€í™”ì—ì„œ ì´ìš© ê°€ëŠ¥í•œ ë°ì´í„°
        quality_scores: Dict  # ë°ì´í„° íƒ€ì…ë³„ í’ˆì§ˆ ì ìˆ˜
    ) -> Dict:
        """
        ë¶€ë¶„ ê²€ìƒ‰ ê³„íš

        Returns:
            {
                "skip_types": ["legal"],
                "search_types": ["market", "loan"],
                "reuse_sources": {
                    "legal": "conversation_2"
                }
            }
        """
        skip_types = []
        search_types = []
        reuse_sources = {}

        for data_type in required_data_types:
            # 1. ë°ì´í„° ìˆëŠ”ì§€ í™•ì¸
            has_data = data_type in available_data and available_data[data_type]

            # 2. í’ˆì§ˆ í™•ì¸
            quality = quality_scores.get(data_type, 0.0)

            # 3. íŒë‹¨
            if has_data and quality > 0.7:
                skip_types.append(data_type)
                reuse_sources[data_type] = available_data[data_type].get("source")
            else:
                search_types.append(data_type)

        return {
            "skip_types": skip_types,
            "search_types": search_types,
            "reuse_sources": reuse_sources
        }
```

**SearchExecutor í†µí•©**:
```python
async def execute_search_node(self, state: SearchTeamState) -> SearchTeamState:
    """ë¶€ë¶„ ê²€ìƒ‰ ì‹¤í–‰"""

    # ë¶€ë¶„ ê²€ìƒ‰ ê³„íš ìˆ˜ë¦½
    plan = self.partial_search_planner.plan_partial_search(
        required_data_types=["legal", "market", "loan"],
        available_data=state.get("previous_data", {}),
        quality_scores=state.get("quality_scores", {})
    )

    logger.info(f"[PartialSearch] Skip: {plan['skip_types']}, Search: {plan['search_types']}")

    # ì¬ì‚¬ìš© ë°ì´í„° ë¡œë“œ
    for data_type in plan["skip_types"]:
        if data_type == "legal":
            state["legal_results"] = state["previous_data"]["legal_search"]
        elif data_type == "market":
            state["real_estate_results"] = state["previous_data"]["real_estate_search"]
        elif data_type == "loan":
            state["loan_results"] = state["previous_data"]["loan_search"]

    # í•„ìš”í•œ ê²ƒë§Œ ê²€ìƒ‰
    for data_type in plan["search_types"]:
        if data_type == "legal":
            # Legal ê²€ìƒ‰ ì‹¤í–‰
            ...
        elif data_type == "market":
            # Market ê²€ìƒ‰ ì‹¤í–‰
            ...
        elif data_type == "loan":
            # Loan ê²€ìƒ‰ ì‹¤í–‰
            ...

    return state
```

---

### 4.4 Confidence Calibration

**ê°œë…**: LLM Confidenceë¥¼ **ë³´ì •**í•˜ì—¬ ì •í™•ë„ í–¥ìƒ

```python
class ConfidenceCalibrator:
    """Confidence ë³´ì •"""

    def __init__(self):
        # ê³¼ê±° ë°ì´í„° ê¸°ë°˜ ë³´ì • ê³¡ì„ 
        self.calibration_curve = {
            # LLM Confidence â†’ ì‹¤ì œ ì •í™•ë„
            0.9: 0.85,  # LLMì´ 0.9ë¼ê³  í•˜ë©´ ì‹¤ì œë¡œëŠ” 0.85
            0.8: 0.75,
            0.7: 0.60,
            0.6: 0.45,
        }

    def calibrate(
        self,
        raw_confidence: float,
        intent_type: str,
        parameter_match_score: float
    ) -> float:
        """
        Confidence ë³´ì •

        Args:
            raw_confidence: LLMì´ ì¶œë ¥í•œ ì›ë³¸ confidence
            intent_type: Intent íƒ€ì… (ì¼ë¶€ IntentëŠ” ë” ë³´ìˆ˜ì ìœ¼ë¡œ)
            parameter_match_score: íŒŒë¼ë¯¸í„° ì¼ì¹˜ë„

        Returns:
            ë³´ì •ëœ confidence
        """
        # 1. ë³´ì • ê³¡ì„  ì ìš©
        calibrated = self._apply_curve(raw_confidence)

        # 2. Intentë³„ ì¡°ì •
        if intent_type == "LOAN_CONSULT":
            # ëŒ€ì¶œì€ ì‹ ì¤‘í•˜ê²Œ (ì‹ ì„ ë„ ì¤‘ìš”)
            calibrated *= 0.9
        elif intent_type == "LEGAL_CONSULT":
            # ë²•ë¥ ì€ ì•ˆì „í•˜ê²Œ (ë³€ê²½ ì ìŒ)
            calibrated *= 1.1

        # 3. íŒŒë¼ë¯¸í„° ì¼ì¹˜ë„ ë°˜ì˜
        if parameter_match_score < 0.8:
            calibrated *= 0.8  # íŒŒë¼ë¯¸í„° ë¶ˆì¼ì¹˜ ì‹œ ê°ì†Œ

        # 4. ë²”ìœ„ ì œí•œ
        calibrated = max(0.0, min(1.0, calibrated))

        return calibrated

    def _apply_curve(self, raw: float) -> float:
        """ë³´ì • ê³¡ì„  ì ìš© (ì„ í˜• ë³´ê°„)"""
        # ê°€ì¥ ê°€ê¹Œìš´ ë‘ ì  ì°¾ê¸°
        keys = sorted(self.calibration_curve.keys())

        if raw >= keys[-1]:
            return self.calibration_curve[keys[-1]]
        if raw <= keys[0]:
            return self.calibration_curve[keys[0]]

        # ì„ í˜• ë³´ê°„
        for i in range(len(keys) - 1):
            if keys[i] <= raw <= keys[i+1]:
                x0, x1 = keys[i], keys[i+1]
                y0, y1 = self.calibration_curve[x0], self.calibration_curve[x1]

                # ë³´ê°„
                calibrated = y0 + (y1 - y0) * (raw - x0) / (x1 - x0)
                return calibrated

        return raw
```

---

### 4.5 Fallback Strategy Hierarchy

**5ë‹¨ê³„ Fallback**:

```python
class FallbackManager:
    """Fallback ì „ëµ ê´€ë¦¬"""

    async def execute_with_fallback(
        self,
        primary_strategy: Callable,
        state: Dict
    ) -> Dict:
        """
        Fallback ê³„ì¸µ ì‹¤í–‰

        Level 1: LLM-based Full Check
        Level 2: Rule-based Quick Check
        Level 3: Keyword Matching
        Level 4: Always Search (Safe Default)
        Level 5: Error Handling
        """
        strategies = [
            ("LLM Full Check", self._llm_full_check),
            ("Rule Quick Check", self._rule_quick_check),
            ("Keyword Matching", self._keyword_matching),
            ("Always Search", self._always_search),
        ]

        for strategy_name, strategy_func in strategies:
            try:
                logger.info(f"[Fallback] Trying {strategy_name}")
                result = await strategy_func(state)

                if result["success"]:
                    logger.info(f"[Fallback] {strategy_name} succeeded")
                    return result
                else:
                    logger.warning(f"[Fallback] {strategy_name} failed, trying next")

            except Exception as e:
                logger.error(f"[Fallback] {strategy_name} error: {e}")
                continue

        # ëª¨ë“  ì „ëµ ì‹¤íŒ¨ â†’ ì•ˆì „ ëª¨ë“œ
        logger.error("[Fallback] All strategies failed, using safe default")
        return await self._safe_default(state)

    async def _llm_full_check(self, state: Dict) -> Dict:
        """Level 1: LLM ê¸°ë°˜ ì™„ì „ ê²€ì‚¬"""
        if not self.llm_service:
            return {"success": False}

        # LLM í˜¸ì¶œí•˜ì—¬ ì¶©ë¶„ì„± íŒë‹¨
        result = await self.llm_service.complete_json_async(...)

        return {"success": True, "data": result}

    async def _rule_quick_check(self, state: Dict) -> Dict:
        """Level 2: ê·œì¹™ ê¸°ë°˜ ë¹ ë¥¸ ê²€ì‚¬"""
        # ê°„ë‹¨í•œ ê·œì¹™ìœ¼ë¡œ íŒë‹¨
        if state.get("previous_data") and state.get("parameter_match_score", 0) > 0.8:
            return {"success": True, "data": {"is_sufficient": True}}

        return {"success": False}

    async def _keyword_matching(self, state: Dict) -> Dict:
        """Level 3: í‚¤ì›Œë“œ ë§¤ì¹­"""
        query = state.get("query", "")
        if any(kw in query for kw in ["ë°©ê¸ˆ", "ì´ì „", "ì•„ê¹Œ"]):
            return {"success": True, "data": {"is_sufficient": True}}

        return {"success": False}

    async def _always_search(self, state: Dict) -> Dict:
        """Level 4: í•­ìƒ ê²€ìƒ‰ (ì•ˆì „)"""
        return {"success": True, "data": {"is_sufficient": False}}

    async def _safe_default(self, state: Dict) -> Dict:
        """Level 5: ì—ëŸ¬ ì²˜ë¦¬"""
        return {"success": True, "data": {"is_sufficient": False, "error": True}}
```

---

## 5. ì™„ì „í•œ êµ¬í˜„ ì½”ë“œ

### 5.1 í•µì‹¬ í´ë˜ìŠ¤ ì •ì˜

```python
# backend/app/service_agent/cognitive_agents/data_reusability_checker.py

"""
Data Reusability Checker
ì´ì „ ëŒ€í™” ë°ì´í„°ì˜ ì¬ì‚¬ìš© ê°€ëŠ¥ì„±ì„ íŒë‹¨í•˜ëŠ” ê³ ë„í™”ëœ ë¡œì§
"""

import logging
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum

logger = logging.getLogger(__name__)


class ReusabilityDecision(Enum):
    """ì¬ì‚¬ìš© ê²°ì •"""
    FULL_REUSE = "full_reuse"          # ì™„ì „ ì¬ì‚¬ìš©
    PARTIAL_REUSE = "partial_reuse"    # ë¶€ë¶„ ì¬ì‚¬ìš©
    NO_REUSE = "no_reuse"              # ì¬ì‚¬ìš© ë¶ˆê°€
    UNCERTAIN = "uncertain"            # ë¶ˆí™•ì‹¤ (ì‚¬ìš©ì í™•ì¸ í•„ìš”)


@dataclass
class MatchResult:
    """íŒŒë¼ë¯¸í„° ë§¤ì¹­ ê²°ê³¼"""
    intent_match: bool
    entity_match_score: float  # 0~1
    match_details: Dict[str, Any]
    overall_score: float  # 0~1


@dataclass
class QualityScore:
    """ë°ì´í„° í’ˆì§ˆ ì ìˆ˜"""
    completeness: float  # ì™„ì „ì„± (0~1)
    freshness: float  # ì‹ ì„ ë„ (0~1)
    relevance: float  # ê´€ë ¨ì„± (0~1)
    quantity: float  # ë°ì´í„° ì–‘ (0~1)
    overall: float  # ì¢…í•© ì ìˆ˜ (0~1)


@dataclass
class ReusabilityResult:
    """ì¬ì‚¬ìš© ê°€ëŠ¥ì„± íŒë‹¨ ê²°ê³¼"""
    decision: ReusabilityDecision
    confidence: float  # 0~1
    match_result: MatchResult
    quality_score: QualityScore
    reasoning: str
    skip_data_types: List[str] = field(default_factory=list)
    search_data_types: List[str] = field(default_factory=list)


class DataReusabilityChecker:
    """ë°ì´í„° ì¬ì‚¬ìš© ê°€ëŠ¥ì„± ì²´ì»¤"""

    def __init__(self):
        self.parameter_matcher = ParameterMatcher()
        self.quality_validator = QualityValidator()
        self.confidence_calibrator = ConfidenceCalibrator()

    def check_reusability(
        self,
        current_intent: 'IntentResult',
        previous_intent_info: Optional[Dict],
        previous_data: Optional[Dict],
        required_data_types: List[str]
    ) -> ReusabilityResult:
        """
        ë°ì´í„° ì¬ì‚¬ìš© ê°€ëŠ¥ì„± ì¢…í•© íŒë‹¨

        Args:
            current_intent: í˜„ì¬ Intent ë¶„ì„ ê²°ê³¼
            previous_intent_info: ì´ì „ ëŒ€í™”ì˜ Intent ì •ë³´
            previous_data: ì´ì „ ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„°
            required_data_types: í•„ìš”í•œ ë°ì´í„° íƒ€ì…

        Returns:
            ì¬ì‚¬ìš© ê°€ëŠ¥ì„± íŒë‹¨ ê²°ê³¼
        """
        # ì´ì „ ë°ì´í„° ì—†ìœ¼ë©´ ì¬ì‚¬ìš© ë¶ˆê°€
        if not previous_intent_info or not previous_data:
            return ReusabilityResult(
                decision=ReusabilityDecision.NO_REUSE,
                confidence=1.0,
                match_result=MatchResult(False, 0.0, {}, 0.0),
                quality_score=QualityScore(0, 0, 0, 0, 0),
                reasoning="No previous data available",
                search_data_types=required_data_types
            )

        # 1. íŒŒë¼ë¯¸í„° ë§¤ì¹­
        match_result = self._match_parameters(
            current_intent,
            previous_intent_info
        )

        # 2. ë°ì´í„° í’ˆì§ˆ ê²€ì¦
        quality_score = self._validate_data_quality(
            previous_data,
            current_intent,
            required_data_types
        )

        # 3. ì¢…í•© Confidence ê³„ì‚°
        raw_confidence = self._calculate_confidence(
            match_result,
            quality_score
        )

        # 4. Confidence ë³´ì •
        calibrated_confidence = self.confidence_calibrator.calibrate(
            raw_confidence,
            current_intent.intent_type.value,
            match_result.overall_score
        )

        # 5. ìµœì¢… ê²°ì •
        decision = self._make_decision(
            calibrated_confidence,
            match_result,
            quality_score
        )

        # 6. ë¶€ë¶„ ì¬ì‚¬ìš© ê³„íš
        skip_types, search_types = self._plan_partial_search(
            decision,
            required_data_types,
            previous_data,
            quality_score
        )

        # 7. Reasoning ìƒì„±
        reasoning = self._generate_reasoning(
            decision,
            match_result,
            quality_score,
            calibrated_confidence
        )

        return ReusabilityResult(
            decision=decision,
            confidence=calibrated_confidence,
            match_result=match_result,
            quality_score=quality_score,
            reasoning=reasoning,
            skip_data_types=skip_types,
            search_data_types=search_types
        )

    def _match_parameters(
        self,
        current_intent: 'IntentResult',
        previous_intent_info: Dict
    ) -> MatchResult:
        """íŒŒë¼ë¯¸í„° ë§¤ì¹­ (ë‹¤ì°¨ì›)"""
        # Intent íƒ€ì… ë¹„êµ
        current_intent_type = current_intent.intent_type.value
        previous_intent_type = previous_intent_info.get("intent_type")

        intent_match = (current_intent_type == previous_intent_type)

        if not intent_match:
            return MatchResult(
                intent_match=False,
                entity_match_score=0.0,
                match_details={},
                overall_score=0.0
            )

        # Entity ë¹„êµ
        current_entities = current_intent.key_parameters
        previous_entities = previous_intent_info.get("key_parameters", {})

        match_details = {}
        total_score = 0.0
        total_weight = 0.0

        for key, current_value in current_entities.items():
            previous_value = previous_entities.get(key)

            # íŒŒë¼ë¯¸í„° íƒ€ì…ë³„ ë§¤ì¹­
            if key == "region":
                match_score = self.parameter_matcher.match_region(
                    current_value,
                    previous_value,
                    strict=True
                )
                weight = 0.5  # ì§€ì—­ì€ ì¤‘ìš”ë„ ë†’ìŒ

            elif key == "amount":
                match_score = self.parameter_matcher.match_amount(
                    current_value,
                    previous_value,
                    tolerance=0.2
                )
                weight = 0.3

            elif key == "legal_topic":
                match_score = self.parameter_matcher.match_legal_topic(
                    current_value,
                    previous_value
                )
                weight = 0.4

            else:
                # ê¸°ë³¸: ì •í™• ì¼ì¹˜
                match_score = 1.0 if current_value == previous_value else 0.0
                weight = 0.2

            match_details[key] = {
                "current": current_value,
                "previous": previous_value,
                "match_score": match_score,
                "weight": weight
            }

            total_score += match_score * weight
            total_weight += weight

        # ì „ì²´ ë§¤ì¹˜ ì ìˆ˜
        entity_match_score = total_score / total_weight if total_weight > 0 else 0.0
        overall_score = entity_match_score  # IntentëŠ” ì´ë¯¸ ì¼ì¹˜í•¨

        return MatchResult(
            intent_match=intent_match,
            entity_match_score=entity_match_score,
            match_details=match_details,
            overall_score=overall_score
        )

    def _validate_data_quality(
        self,
        previous_data: Dict,
        current_intent: 'IntentResult',
        required_data_types: List[str]
    ) -> QualityScore:
        """ë°ì´í„° í’ˆì§ˆ ê²€ì¦"""
        return self.quality_validator.validate(
            previous_data,
            current_intent,
            required_data_types
        )

    def _calculate_confidence(
        self,
        match_result: MatchResult,
        quality_score: QualityScore
    ) -> float:
        """Confidence ê³„ì‚° (ê°€ì¤‘ í‰ê· )"""
        confidence = (
            match_result.overall_score * 0.4 +  # íŒŒë¼ë¯¸í„° ë§¤ì¹­ 40%
            quality_score.freshness * 0.3 +     # ì‹ ì„ ë„ 30%
            quality_score.completeness * 0.2 +  # ì™„ì „ì„± 20%
            quality_score.relevance * 0.1       # ê´€ë ¨ì„± 10%
        )

        return confidence

    def _make_decision(
        self,
        confidence: float,
        match_result: MatchResult,
        quality_score: QualityScore
    ) -> ReusabilityDecision:
        """ìµœì¢… ê²°ì •"""
        # Intent ë¶ˆì¼ì¹˜ â†’ ì¬ì‚¬ìš© ë¶ˆê°€
        if not match_result.intent_match:
            return ReusabilityDecision.NO_REUSE

        # Confidence ê¸°ë°˜ ê²°ì •
        if confidence >= 0.9:
            return ReusabilityDecision.FULL_REUSE
        elif confidence >= 0.7:
            # ë¶€ë¶„ ì¬ì‚¬ìš© ë˜ëŠ” ë¶ˆí™•ì‹¤
            if quality_score.completeness < 0.8:
                return ReusabilityDecision.PARTIAL_REUSE
            else:
                return ReusabilityDecision.UNCERTAIN
        else:
            return ReusabilityDecision.NO_REUSE

    def _plan_partial_search(
        self,
        decision: ReusabilityDecision,
        required_data_types: List[str],
        previous_data: Dict,
        quality_score: QualityScore
    ) -> Tuple[List[str], List[str]]:
        """ë¶€ë¶„ ê²€ìƒ‰ ê³„íš"""
        skip_types = []
        search_types = []

        if decision == ReusabilityDecision.FULL_REUSE:
            # ëª¨ë‘ ì¬ì‚¬ìš©
            skip_types = required_data_types

        elif decision == ReusabilityDecision.PARTIAL_REUSE:
            # ë°ì´í„° íƒ€ì…ë³„ë¡œ íŒë‹¨
            type_map = {
                "legal": "legal_search",
                "market": "real_estate_search",
                "loan": "loan_search"
            }

            for req_type in required_data_types:
                data_key = type_map.get(req_type)
                if data_key and previous_data.get(data_key):
                    # ë°ì´í„° ìˆìŒ â†’ í’ˆì§ˆ í™•ì¸
                    # TODO: íƒ€ì…ë³„ í’ˆì§ˆ ì ìˆ˜ í•„ìš”
                    if len(previous_data[data_key]) >= 3:  # ê°„ë‹¨í•œ ê¸°ì¤€
                        skip_types.append(req_type)
                    else:
                        search_types.append(req_type)
                else:
                    search_types.append(req_type)

        elif decision == ReusabilityDecision.NO_REUSE:
            # ëª¨ë‘ ìƒˆ ê²€ìƒ‰
            search_types = required_data_types

        elif decision == ReusabilityDecision.UNCERTAIN:
            # ë¶ˆí™•ì‹¤ â†’ ì•ˆì „í•˜ê²Œ ëª¨ë‘ ìƒˆ ê²€ìƒ‰
            search_types = required_data_types

        return skip_types, search_types

    def _generate_reasoning(
        self,
        decision: ReusabilityDecision,
        match_result: MatchResult,
        quality_score: QualityScore,
        confidence: float
    ) -> str:
        """ê²°ì • ì´ìœ  ìƒì„±"""
        if decision == ReusabilityDecision.FULL_REUSE:
            return (
                f"ì´ì „ ë°ì´í„° ì™„ì „ ì¬ì‚¬ìš© (Confidence: {confidence:.2f}). "
                f"íŒŒë¼ë¯¸í„° ì¼ì¹˜ë„ {match_result.overall_score:.0%}, "
                f"ë°ì´í„° ì‹ ì„ ë„ {quality_score.freshness:.0%}."
            )
        elif decision == ReusabilityDecision.PARTIAL_REUSE:
            return (
                f"ì´ì „ ë°ì´í„° ë¶€ë¶„ ì¬ì‚¬ìš© (Confidence: {confidence:.2f}). "
                f"ì¼ë¶€ ë°ì´í„°ëŠ” ì¶©ë¶„í•˜ë‚˜ ì¶”ê°€ ê²€ìƒ‰ í•„ìš”."
            )
        elif decision == ReusabilityDecision.NO_REUSE:
            return (
                f"ìƒˆ ê²€ìƒ‰ í•„ìš” (Confidence: {confidence:.2f}). "
                f"íŒŒë¼ë¯¸í„° ë¶ˆì¼ì¹˜ ë˜ëŠ” ë°ì´í„° í’ˆì§ˆ ë¶€ì¡±."
            )
        elif decision == ReusabilityDecision.UNCERTAIN:
            return (
                f"ë¶ˆí™•ì‹¤ (Confidence: {confidence:.2f}). "
                f"ì‚¬ìš©ì í™•ì¸ ê¶Œì¥."
            )
```

### 5.2 Parameter Matcher êµ¬í˜„

```python
# backend/app/service_agent/cognitive_agents/parameter_matcher.py

class ParameterMatcher:
    """ë‹¤ì°¨ì› íŒŒë¼ë¯¸í„° ë§¤ì¹­"""

    def __init__(self):
        # ì§€ì—­ ìœ ì‚¬ë„ (ê±°ë¦¬ ê¸°ë°˜ - ì‹¤ì œë¡œëŠ” DBì—ì„œ ë¡œë“œ)
        self.region_similarity = self._load_region_similarity()

        # ë²•ë¥  ì£¼ì œ ìœ ì‚¬ë„ (ì˜ë¯¸ ê¸°ë°˜ - ì‹¤ì œë¡œëŠ” ì„ë² ë”© ì‚¬ìš©)
        self.legal_topic_embeddings = self._load_legal_topic_embeddings()

    def match_region(
        self,
        current: str,
        previous: Optional[str],
        strict: bool = True
    ) -> float:
        """ì§€ì—­ ë§¤ì¹­"""
        if previous is None:
            return 0.0

        if current == previous:
            return 1.0

        if strict:
            return 0.0

        # ìœ ì‚¬ë„ ì¡°íšŒ
        key = tuple(sorted([current, previous]))
        return self.region_similarity.get(key, 0.0)

    def match_amount(
        self,
        current: float,
        previous: Optional[float],
        tolerance: float = 0.2
    ) -> float:
        """ê¸ˆì•¡ ë§¤ì¹­"""
        if previous is None or previous == 0:
            return 0.0

        diff_ratio = abs(current - previous) / previous

        if diff_ratio <= tolerance:
            # ì„ í˜• ê°ì†Œ: ì°¨ì´ 0% â†’ 1.0, ì°¨ì´ tolerance% â†’ 0.7
            similarity = 1.0 - (diff_ratio / tolerance) * 0.3
            return similarity
        else:
            return 0.0

    def match_legal_topic(
        self,
        current: str,
        previous: Optional[str]
    ) -> float:
        """ë²•ë¥  ì£¼ì œ ë§¤ì¹­ (ì„ë² ë”© ê¸°ë°˜)"""
        if previous is None:
            return 0.0

        if current == previous:
            return 1.0

        # ì„ë² ë”© ìœ ì‚¬ë„ ê³„ì‚°
        current_emb = self.legal_topic_embeddings.get(current)
        previous_emb = self.legal_topic_embeddings.get(previous)

        if current_emb and previous_emb:
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
            similarity = self._cosine_similarity(current_emb, previous_emb)
            return similarity
        else:
            # ì„ë² ë”© ì—†ìœ¼ë©´ ë¬¸ìì—´ ìœ ì‚¬ë„
            return self._string_similarity(current, previous)

    def _load_region_similarity(self) -> Dict:
        """ì§€ì—­ ìœ ì‚¬ë„ ë¡œë“œ (ì‹¤ì œë¡œëŠ” DBì—ì„œ)"""
        return {
            ("ê°•ë‚¨êµ¬", "ì„œì´ˆêµ¬"): 0.8,
            ("ê°•ë‚¨êµ¬", "ì†¡íŒŒêµ¬"): 0.7,
            ("ê°•ë‚¨êµ¬", "ê°•ë¶êµ¬"): 0.1,
            ("ì„œì´ˆêµ¬", "ì†¡íŒŒêµ¬"): 0.75,
            # ... ë” ë§ì€ ì¡°í•©
        }

    def _load_legal_topic_embeddings(self) -> Dict:
        """ë²•ë¥  ì£¼ì œ ì„ë² ë”© ë¡œë“œ (ì‹¤ì œë¡œëŠ” ëª¨ë¸ì—ì„œ)"""
        # ê°„ë‹¨í•œ ì˜ˆì‹œ (ì‹¤ì œë¡œëŠ” OpenAI Embeddings ë“± ì‚¬ìš©)
        return {
            "ì „ì„¸ê¸ˆ_ì¸ìƒ": [0.1, 0.9, 0.3, ...],
            "ì „ì„¸ê¸ˆ_ì¸í•˜": [0.1, 0.85, 0.35, ...],
            "ê³„ì•½_ê°±ì‹ ": [0.2, 0.7, 0.4, ...],
        }

    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„"""
        import numpy as np
        return float(np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2)))

    def _string_similarity(self, s1: str, s2: str) -> float:
        """ë¬¸ìì—´ ìœ ì‚¬ë„ (Levenshtein)"""
        from difflib import SequenceMatcher
        return SequenceMatcher(None, s1, s2).ratio()
```

### 5.3 Quality Validator êµ¬í˜„

```python
# backend/app/service_agent/cognitive_agents/quality_validator.py

class QualityValidator:
    """ë°ì´í„° í’ˆì§ˆ ê²€ì¦ê¸°"""

    def validate(
        self,
        previous_data: Dict,
        current_intent: 'IntentResult',
        required_data_types: List[str]
    ) -> QualityScore:
        """ì¢…í•© í’ˆì§ˆ ê²€ì¦"""
        # 1. ì™„ì „ì„±
        completeness = self._check_completeness(
            previous_data,
            required_data_types
        )

        # 2. ì‹ ì„ ë„
        freshness = self._check_freshness(
            previous_data,
            current_intent.intent_type
        )

        # 3. ê´€ë ¨ì„±
        relevance = self._check_relevance(
            previous_data,
            current_intent
        )

        # 4. ë°ì´í„° ì–‘
        quantity = self._check_quantity(
            previous_data,
            required_data_types
        )

        # 5. ì¢…í•© ì ìˆ˜
        overall = (
            completeness * 0.3 +
            freshness * 0.3 +
            relevance * 0.2 +
            quantity * 0.2
        )

        return QualityScore(
            completeness=completeness,
            freshness=freshness,
            relevance=relevance,
            quantity=quantity,
            overall=overall
        )

    def _check_completeness(
        self,
        previous_data: Dict,
        required_data_types: List[str]
    ) -> float:
        """ì™„ì „ì„± ê²€ì‚¬"""
        type_map = {
            "legal": "legal_search",
            "market": "real_estate_search",
            "loan": "loan_search"
        }

        found_count = 0
        for req_type in required_data_types:
            data_key = type_map.get(req_type)
            if data_key and previous_data.get(data_key):
                found_count += 1

        completeness = found_count / len(required_data_types) if required_data_types else 0.0
        return completeness

    def _check_freshness(
        self,
        previous_data: Dict,
        intent_type: 'IntentType'
    ) -> float:
        """ì‹ ì„ ë„ ê²€ì‚¬"""
        timestamp_str = previous_data.get("timestamp")

        if not timestamp_str:
            return 0.5  # íƒ€ì„ìŠ¤íƒ¬í”„ ì—†ìœ¼ë©´ ì¤‘ê°„ ì ìˆ˜

        try:
            if isinstance(timestamp_str, str):
                timestamp = datetime.fromisoformat(timestamp_str)
            else:
                timestamp = timestamp_str

            age = datetime.now() - timestamp
            age_days = age.total_seconds() / 86400

            # Intentë³„ ì‹ ì„ ë„ ê¸°ì¤€
            if intent_type.value == "MARKET_INQUIRY":
                max_age = 7  # 7ì¼
            elif intent_type.value == "LOAN_CONSULT":
                max_age = 1  # 1ì¼
            elif intent_type.value == "LEGAL_CONSULT":
                max_age = 365  # 1ë…„ (ë²•ë¥ ì€ ì˜¤ë˜ ìœ íš¨)
            else:
                max_age = 7  # ê¸°ë³¸ 7ì¼

            if age_days <= max_age:
                # ì„ í˜• ê°ì†Œ: 0ì¼ â†’ 1.0, max_ageì¼ â†’ 0.5
                freshness = 1.0 - (age_days / max_age) * 0.5
                return freshness
            else:
                # ê¸°ì¤€ ì´ˆê³¼
                return 0.0

        except Exception as e:
            logger.warning(f"Failed to parse timestamp: {e}")
            return 0.5

    def _check_relevance(
        self,
        previous_data: Dict,
        current_intent: 'IntentResult'
    ) -> float:
        """ê´€ë ¨ì„± ê²€ì‚¬"""
        # ê°„ë‹¨í•œ ë²„ì „: ì¿¼ë¦¬ í‚¤ì›Œë“œ ë¹„êµ
        previous_query = previous_data.get("query", "")
        current_keywords = current_intent.keywords

        if not previous_query or not current_keywords:
            return 0.5

        # í‚¤ì›Œë“œ ë§¤ì¹­ ë¹„ìœ¨
        matched = sum(1 for kw in current_keywords if kw in previous_query)
        relevance = matched / len(current_keywords) if current_keywords else 0.0

        return relevance

    def _check_quantity(
        self,
        previous_data: Dict,
        required_data_types: List[str]
    ) -> float:
        """ë°ì´í„° ì–‘ ê²€ì‚¬"""
        type_map = {
            "legal": "legal_search",
            "market": "real_estate_search",
            "loan": "loan_search"
        }

        total_items = 0
        for req_type in required_data_types:
            data_key = type_map.get(req_type)
            if data_key and previous_data.get(data_key):
                items = previous_data[data_key]
                if isinstance(items, list):
                    total_items += len(items)

        # ìµœì†Œ 3ê°œì”© í•„ìš”í•˜ë‹¤ê³  ê°€ì •
        min_required = len(required_data_types) * 3
        quantity = min(total_items / min_required, 1.0) if min_required > 0 else 0.0

        return quantity
```

### 5.4 Planning Node í†µí•©

```python
# backend/app/service_agent/supervisor/team_supervisor.py - planning_node()

async def planning_node(self, state: MainSupervisorState) -> MainSupervisorState:
    """
    ê³„íš ìˆ˜ë¦½ ë…¸ë“œ (ê³ ë„í™” ë²„ì „)
    """
    logger.info("[TeamSupervisor] Planning phase started")

    state["current_phase"] = "planning"
    query = state["query"]
    chat_session_id = state.get("chat_session_id")
    user_id = state.get("user_id")

    # 1. Chat History & Long-term Memory ë¡œë“œ
    chat_history = await self._get_chat_history(chat_session_id, limit=3)
    tiered_memories = {}

    if user_id and self.memory_service:
        try:
            tiered_memories = await self.memory_service.load_tiered_memories(
                user_id=user_id,
                current_session_id=chat_session_id
            )
            state["tiered_memories"] = tiered_memories
            state["loaded_memories"] = (
                tiered_memories.get("shortterm", []) +
                tiered_memories.get("midterm", []) +
                tiered_memories.get("longterm", [])
            )
        except Exception as e:
            logger.error(f"Failed to load long-term memory: {e}")

    # 2. Intent & Entity ë¶„ì„
    context = {"chat_history": chat_history} if chat_history else None
    intent_result = await self.planning_agent.analyze_intent(query, context)

    logger.info(
        f"[Planning] Intent: {intent_result.intent_type.value}, "
        f"Confidence: {intent_result.confidence:.2f}, "
        f"Entities: {intent_result.key_parameters}"
    )

    # IRRELEVANT/UNCLEAR ì¡°ê¸° ì¢…ë£Œ
    if intent_result.intent_type == IntentType.IRRELEVANT:
        state["planning_state"] = {
            "analyzed_intent": {
                "intent_type": intent_result.intent_type.value,
                "confidence": intent_result.confidence
            },
            "execution_steps": []
        }
        return state

    # 3. ì´ì „ ëŒ€í™”ì˜ Intent & Data ë¡œë“œ
    previous_intent_info = await self._get_previous_intent_info(chat_session_id)
    previous_data = await self._get_previous_search_results(chat_session_id)

    # 4. ë°ì´í„° ì¬ì‚¬ìš© ê°€ëŠ¥ì„± íŒë‹¨ (ê³ ë„í™”)
    reusability_checker = DataReusabilityChecker()
    required_data_types = self._get_required_data_types(intent_result)

    reusability_result = reusability_checker.check_reusability(
        current_intent=intent_result,
        previous_intent_info=previous_intent_info,
        previous_data=previous_data,
        required_data_types=required_data_types
    )

    logger.info(
        f"[Reusability] Decision: {reusability_result.decision.value}, "
        f"Confidence: {reusability_result.confidence:.2f}, "
        f"Skip: {reusability_result.skip_data_types}, "
        f"Search: {reusability_result.search_data_types}"
    )

    # 5. ì‹¤í–‰ ê³„íš ê²°ì •
    skip_search = False
    verify_search_data = False

    if reusability_result.decision == ReusabilityDecision.FULL_REUSE:
        # ì™„ì „ ì¬ì‚¬ìš© â†’ SearchTeam ì œì™¸
        logger.info("[Planning] Full reuse - skipping SearchTeam")
        skip_search = True

        state["data_reused"] = True
        state["reusability_result"] = dataclasses.asdict(reusability_result)

        # WebSocket ì•Œë¦¼
        await self._send_progress("data_reuse_decision", {
            "message": "ì´ì „ ëŒ€í™”ì˜ ë°ì´í„°ë¥¼ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.",
            "reasoning": reusability_result.reasoning,
            "confidence": reusability_result.confidence
        }, state)

    elif reusability_result.decision == ReusabilityDecision.PARTIAL_REUSE:
        # ë¶€ë¶„ ì¬ì‚¬ìš© â†’ SearchTeam ë¶€ë¶„ ì‹¤í–‰
        logger.info("[Planning] Partial reuse - SearchTeam with partial skip")
        verify_search_data = True

        state["partial_reuse"] = True
        state["reusability_result"] = dataclasses.asdict(reusability_result)

    elif reusability_result.decision == ReusabilityDecision.UNCERTAIN:
        # ë¶ˆí™•ì‹¤ â†’ Human-in-the-Loop
        logger.info("[Planning] Uncertain - requesting user confirmation")

        user_choice = await self._request_user_confirmation(
            reusability_result,
            state
        )

        if user_choice == "use_previous":
            skip_search = True
            state["data_reused"] = True
            state["user_confirmed"] = True
        else:
            verify_search_data = False
            state["user_confirmed"] = False

    else:  # NO_REUSE
        # ì¬ì‚¬ìš© ë¶ˆê°€ â†’ ìƒˆ ê²€ìƒ‰
        logger.info("[Planning] No reuse - full search required")
        verify_search_data = False

    # 6. Agent ì„ íƒ ë° Execution Plan ìƒì„±
    if skip_search:
        # SearchTeam ì œì™¸
        filtered_agents = [
            a for a in intent_result.suggested_agents
            if a != "search_team"
        ]
        intent_result.suggested_agents = filtered_agents if filtered_agents else ["analysis_team"]

    execution_plan = await self.planning_agent.create_execution_plan(intent_result)

    # 7. Planning State ì €ì¥
    state["planning_state"] = {
        "analyzed_intent": {
            "intent_type": intent_result.intent_type.value,
            "confidence": intent_result.confidence,
            "keywords": intent_result.keywords,
            "entities": intent_result.entities,
            "key_parameters": intent_result.key_parameters  # ğŸ†• ì €ì¥
        },
        "execution_plan": dataclasses.asdict(execution_plan) if hasattr(execution_plan, '__dict__') else {},
        "execution_steps": [
            {
                "agent_name": step.agent_name,
                "priority": step.priority,
                "status": "pending"
            }
            for step in execution_plan.steps
        ],
        "execution_strategy": execution_plan.strategy.value,
        "estimated_total_time": execution_plan.estimated_time
    }

    # 8. Active Teams ê²°ì •
    state["active_teams"] = [step.agent_name for step in execution_plan.steps]
    state["execution_plan"] = execution_plan
    state["verify_search_data"] = verify_search_data
    state["search_skipped"] = skip_search

    if skip_search or verify_search_data:
        state["cached_search_results"] = previous_data

    logger.info(f"[Planning] Active teams: {state['active_teams']}")

    return state

def _get_required_data_types(self, intent: IntentResult) -> List[str]:
    """Intentì— ë”°ë¼ í•„ìš”í•œ ë°ì´í„° íƒ€ì… ê²°ì •"""
    intent_to_data = {
        IntentType.LEGAL_CONSULT: ["legal"],
        IntentType.MARKET_INQUIRY: ["market"],
        IntentType.LOAN_CONSULT: ["loan"],
        IntentType.CONTRACT_REVIEW: ["legal", "contract"],
        IntentType.COMPREHENSIVE: ["legal", "market"],
        IntentType.RISK_ANALYSIS: ["legal", "market"],
    }

    return intent_to_data.get(intent.intent_type, ["legal", "market"])

async def _request_user_confirmation(
    self,
    reusability_result: ReusabilityResult,
    state: MainSupervisorState
) -> str:
    """ì‚¬ìš©ì í™•ì¸ ìš”ì²­ (Human-in-the-Loop)"""
    session_id = state.get("session_id")
    progress_callback = self._progress_callbacks.get(session_id)

    if not progress_callback:
        # Callback ì—†ìœ¼ë©´ ì•ˆì „í•˜ê²Œ ìƒˆ ê²€ìƒ‰
        return "search_new"

    try:
        # ì‚¬ìš©ì í™•ì¸ ìš”ì²­
        await progress_callback("user_confirmation_required", {
            "confirmation_id": f"conf_{datetime.now().timestamp()}",
            "message": "ì´ì „ ëŒ€í™”ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
            "context": {
                "reasoning": reusability_result.reasoning,
                "confidence": reusability_result.confidence,
                "data_age": self._format_data_age(state.get("cached_search_results"))
            },
            "options": [
                {
                    "value": "use_previous",
                    "label": "ì˜ˆ, ì´ì „ ë°ì´í„° ì‚¬ìš©",
                    "description": "ê²€ìƒ‰ ì‹œê°„ 3~5ì´ˆ ë‹¨ì¶•"
                },
                {
                    "value": "search_new",
                    "label": "ì•„ë‹ˆìš”, ìµœì‹  ì •ë³´ ê²€ìƒ‰",
                    "description": "ìµœì‹  ë°ì´í„°ë¡œ ë¶„ì„"
                }
            ]
        })

        # ì‚¬ìš©ì ì‘ë‹µ ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒ 30ì´ˆ)
        user_choice = await self._wait_for_user_response(session_id, timeout=30.0)
        return user_choice

    except asyncio.TimeoutError:
        logger.warning("[HIL] User confirmation timeout, using new search")
        return "search_new"
    except Exception as e:
        logger.error(f"[HIL] User confirmation failed: {e}")
        return "search_new"
```

---

## 6. í…ŒìŠ¤íŠ¸ ì „ëµ

### 6.1 Unit í…ŒìŠ¤íŠ¸

```python
# tests/test_data_reusability_checker.py

import pytest
from app.service_agent.cognitive_agents.data_reusability_checker import (
    DataReusabilityChecker,
    ReusabilityDecision
)

class TestDataReusabilityChecker:
    """DataReusabilityChecker ë‹¨ìœ„ í…ŒìŠ¤íŠ¸"""

    def setup_method(self):
        self.checker = DataReusabilityChecker()

    def test_full_reuse_same_parameters(self):
        """íŒŒë¼ë¯¸í„° ì™„ì „ ì¼ì¹˜ ì‹œ FULL_REUSE"""
        current_intent = create_intent(
            intent_type="MARKET_INQUIRY",
            key_parameters={"region": "ê°•ë‚¨êµ¬", "property_type": "ì•„íŒŒíŠ¸"}
        )

        previous_intent_info = {
            "intent_type": "MARKET_INQUIRY",
            "key_parameters": {"region": "ê°•ë‚¨êµ¬", "property_type": "ì•„íŒŒíŠ¸"}
        }

        previous_data = {
            "real_estate_search": [{"price": 600000000}],
            "timestamp": datetime.now().isoformat()
        }

        result = self.checker.check_reusability(
            current_intent,
            previous_intent_info,
            previous_data,
            ["market"]
        )

        assert result.decision == ReusabilityDecision.FULL_REUSE
        assert result.confidence > 0.9

    def test_no_reuse_different_region(self):
        """ì§€ì—­ ë¶ˆì¼ì¹˜ ì‹œ NO_REUSE"""
        current_intent = create_intent(
            intent_type="MARKET_INQUIRY",
            key_parameters={"region": "ì„œì´ˆêµ¬", "property_type": "ì•„íŒŒíŠ¸"}
        )

        previous_intent_info = {
            "intent_type": "MARKET_INQUIRY",
            "key_parameters": {"region": "ê°•ë‚¨êµ¬", "property_type": "ì•„íŒŒíŠ¸"}
        }

        previous_data = {
            "real_estate_search": [{"price": 600000000}],
            "timestamp": datetime.now().isoformat()
        }

        result = self.checker.check_reusability(
            current_intent,
            previous_intent_info,
            previous_data,
            ["market"]
        )

        assert result.decision == ReusabilityDecision.NO_REUSE
        assert result.confidence < 0.6

    def test_partial_reuse_amount_tolerance(self):
        """ê¸ˆì•¡ ë²”ìœ„ ë‚´ ë³€ê²½ ì‹œ PARTIAL_REUSE ë˜ëŠ” UNCERTAIN"""
        current_intent = create_intent(
            intent_type="LOAN_CONSULT",
            key_parameters={"loan_type": "ì „ì„¸ìê¸ˆ", "amount": 550000000}
        )

        previous_intent_info = {
            "intent_type": "LOAN_CONSULT",
            "key_parameters": {"loan_type": "ì „ì„¸ìê¸ˆ", "amount": 500000000}
        }

        previous_data = {
            "loan_search": [{"max_loan": 450000000}],
            "timestamp": datetime.now().isoformat()
        }

        result = self.checker.check_reusability(
            current_intent,
            previous_intent_info,
            previous_data,
            ["loan"]
        )

        # 10% ì°¨ì´ â†’ í—ˆìš© ë²”ìœ„
        assert result.decision in [
            ReusabilityDecision.PARTIAL_REUSE,
            ReusabilityDecision.UNCERTAIN
        ]
        assert 0.7 <= result.confidence <= 0.9

    def test_freshness_expired(self):
        """ì‹ ì„ ë„ ê¸°ì¤€ ì´ˆê³¼ ì‹œ NO_REUSE"""
        current_intent = create_intent(
            intent_type="MARKET_INQUIRY",
            key_parameters={"region": "ê°•ë‚¨êµ¬", "property_type": "ì•„íŒŒíŠ¸"}
        )

        previous_intent_info = {
            "intent_type": "MARKET_INQUIRY",
            "key_parameters": {"region": "ê°•ë‚¨êµ¬", "property_type": "ì•„íŒŒíŠ¸"}
        }

        # 14ì¼ ì „ ë°ì´í„° (ê¸°ì¤€ 7ì¼ ì´ˆê³¼)
        previous_data = {
            "real_estate_search": [{"price": 600000000}],
            "timestamp": (datetime.now() - timedelta(days=14)).isoformat()
        }

        result = self.checker.check_reusability(
            current_intent,
            previous_intent_info,
            previous_data,
            ["market"]
        )

        assert result.decision == ReusabilityDecision.NO_REUSE
        assert result.quality_score.freshness < 0.5
```

### 6.2 Integration í…ŒìŠ¤íŠ¸

```python
# tests/integration/test_planning_with_reuse.py

@pytest.mark.asyncio
async def test_planning_with_full_reuse():
    """Planning Nodeì—ì„œ ì™„ì „ ì¬ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤"""
    supervisor = TeamBasedSupervisor(...)

    # 1ì°¨ ì¿¼ë¦¬: "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ì‹œì„¸"
    state1 = await supervisor.app.ainvoke({
        "query": "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ì‹œì„¸",
        "session_id": "test_session",
        "chat_session_id": "chat_123"
    })

    assert "search" in state1["active_teams"]
    assert state1["search_skipped"] == False

    # 2ì°¨ ì¿¼ë¦¬: "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ë‹¤ì‹œ ì•Œë ¤ì¤˜"
    state2 = await supervisor.app.ainvoke({
        "query": "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ë‹¤ì‹œ ì•Œë ¤ì¤˜",
        "session_id": "test_session",
        "chat_session_id": "chat_123"
    })

    # SearchTeam ê±´ë„ˆë›°ê¸° í™•ì¸
    assert "search" not in state2["active_teams"]
    assert state2["search_skipped"] == True
    assert state2["data_reused"] == True

@pytest.mark.asyncio
async def test_planning_with_different_region():
    """Planning Nodeì—ì„œ ì§€ì—­ ë³€ê²½ ì‹œ ìƒˆ ê²€ìƒ‰"""
    supervisor = TeamBasedSupervisor(...)

    # 1ì°¨: "ê°•ë‚¨êµ¬"
    await supervisor.app.ainvoke({
        "query": "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ì‹œì„¸",
        "chat_session_id": "chat_123"
    })

    # 2ì°¨: "ì„œì´ˆêµ¬"
    state2 = await supervisor.app.ainvoke({
        "query": "ì„œì´ˆêµ¬ëŠ” ì–´ë•Œ?",
        "chat_session_id": "chat_123"
    })

    # ìƒˆ ê²€ìƒ‰ í™•ì¸
    assert "search" in state2["active_teams"]
    assert state2["search_skipped"] == False
```

### 6.3 End-to-End í…ŒìŠ¤íŠ¸

```python
# tests/e2e/test_reuse_scenarios.py

@pytest.mark.e2e
@pytest.mark.asyncio
async def test_scenario_market_inquiry_repeated():
    """E2E: MARKET_INQUIRY ë°˜ë³µ ì‹œë‚˜ë¦¬ì˜¤"""

    conversations = [
        ("ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ì „ì„¸ ì‹œì„¸", True),   # ê²€ìƒ‰ ì‹¤í–‰
        ("ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ì‹œì„¸ ë‹¤ì‹œ", False),   # ì¬ì‚¬ìš©
        ("ì„œì´ˆêµ¬ëŠ”?", True),                 # ìƒˆ ê²€ìƒ‰ (ì§€ì—­ ë‹¤ë¦„)
        ("ê°•ë‚¨êµ¬ë¡œ ë‹¤ì‹œ ëŒì•„ê°€ë©´?", False),   # ì¬ì‚¬ìš© (1ì°¨ ë°ì´í„°)
    ]

    for i, (query, should_search) in enumerate(conversations):
        response = await execute_query(query, session_id="e2e_test")

        if should_search:
            assert "SearchTeam ì‹¤í–‰" in response["logs"]
        else:
            assert "ì´ì „ ë°ì´í„° ì¬ì‚¬ìš©" in response["logs"]

@pytest.mark.e2e
@pytest.mark.asyncio
async def test_scenario_intent_transition():
    """E2E: Intent ì „í™˜ ì‹œë‚˜ë¦¬ì˜¤"""

    # 1. MARKET_INQUIRY
    r1 = await execute_query("ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ì‹œì„¸", session_id="e2e_test2")
    assert "í‰ê· " in r1["response"]

    # 2. LOAN_CONSULT (Intent ë³€ê²½, ë¶€ë¶„ ì¬ì‚¬ìš©)
    r2 = await execute_query("ì´ ê°€ê²©ìœ¼ë¡œ ëŒ€ì¶œì€?", session_id="e2e_test2")
    assert "ëŒ€ì¶œ" in r2["response"]
    # real_estate_searchëŠ” ì¬ì‚¬ìš©, loan_searchë§Œ ì‹¤í–‰
    assert r2["reused_data"]["real_estate_search"] is not None
    assert r2["new_search"]["loan_search"] is not None

    # 3. RISK_ANALYSIS (Intent ë³€ê²½, ë¶€ë¶„ ì¬ì‚¬ìš©)
    r3 = await execute_query("ìœ„í—˜ë„ ë¶„ì„", session_id="e2e_test2")
    # real_estate_search ì¬ì‚¬ìš©, legal_search ìƒˆë¡œ ì‹¤í–‰
    assert r3["reused_data"]["real_estate_search"] is not None
    assert r3["new_search"]["legal_search"] is not None
```

---

## 7. ë°°í¬ ê°€ì´ë“œ

### 7.1 ë‹¨ê³„ë³„ ë°°í¬ ì „ëµ

**Phase 1 (Week 1): Planning Nodeë§Œ êµ¬í˜„**
```bash
# 1. í”„ë¡¬í”„íŠ¸ ì¶”ê°€
cp prompts/data_sufficiency_check.txt backend/app/service_agent/llm_manager/prompts/cognitive/

# 2. Intent ë¶„ì„ í™•ì¥ (Entities ì¶”ì¶œ)
# planning_agent.py ìˆ˜ì •

# 3. ê°„ë‹¨í•œ ì¬ì‚¬ìš© ë¡œì§ (í‚¤ì›Œë“œ ê¸°ë°˜)
# team_supervisor.py - planning_node() ìˆ˜ì •

# 4. í…ŒìŠ¤íŠ¸
pytest tests/unit/test_planning_agent.py -v

# 5. ë°°í¬
git commit -m "feat: Add basic data reuse in Planning Node"
git push origin feature/data-reuse-phase1
```

**Phase 2 (Week 2): Execute Node ì¶”ê°€**
```bash
# 1. SearchExecutor ìˆ˜ì •
# search_executor.py - prepare_search_node() ìˆ˜ì •

# 2. ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì¶”ê°€
# quality_validator.py ì‘ì„±

# 3. í…ŒìŠ¤íŠ¸
pytest tests/integration/test_search_executor.py -v

# 4. ë°°í¬
git commit -m "feat: Add quality check in SearchExecutor"
git push origin feature/data-reuse-phase2
```

**Phase 3 (Week 3): ê³ ë„í™” (Parameter Matcher, Accumulator ë“±)**
```bash
# 1. Parameter Matcher êµ¬í˜„
# parameter_matcher.py ì‘ì„±

# 2. DataReusabilityChecker í†µí•©
# data_reusability_checker.py ì‘ì„±

# 3. Planning Node ì™„ì „ êµì²´
# team_supervisor.py - planning_node() ì™„ì „ ì¬ì‘ì„±

# 4. E2E í…ŒìŠ¤íŠ¸
pytest tests/e2e/test_reuse_scenarios.py -v

# 5. ë°°í¬
git commit -m "feat: Full data reuse system with advanced logic"
git push origin feature/data-reuse-phase3
```

### 7.2 Feature Flag í™œìš©

```python
# backend/app/core/config.py

class Settings(BaseSettings):
    # ... ê¸°ì¡´ ì„¤ì •

    # Data Reuse Feature Flags
    ENABLE_DATA_REUSE: bool = Field(default=False, env="ENABLE_DATA_REUSE")
    ENABLE_PARTIAL_REUSE: bool = Field(default=False, env="ENABLE_PARTIAL_REUSE")
    ENABLE_HUMAN_IN_THE_LOOP: bool = Field(default=False, env="ENABLE_HUMAN_IN_THE_LOOP")

    # Reuse Thresholds
    REUSE_CONFIDENCE_THRESHOLD: float = Field(default=0.9, env="REUSE_CONFIDENCE_THRESHOLD")
    HIL_CONFIDENCE_THRESHOLD: float = Field(default=0.6, env="HIL_CONFIDENCE_THRESHOLD")

settings = Settings()
```

```python
# team_supervisor.py - planning_node()

if settings.ENABLE_DATA_REUSE:
    # ë°ì´í„° ì¬ì‚¬ìš© ë¡œì§ ì‹¤í–‰
    reusability_result = reusability_checker.check_reusability(...)
else:
    # ê¸°ì¡´ ë¡œì§ (í•­ìƒ ê²€ìƒ‰)
    reusability_result = None
```

**ë°°í¬ ì‹œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •**:
```bash
# Phase 1 ë°°í¬ (í”„ë¡œë•ì…˜)
ENABLE_DATA_REUSE=true
ENABLE_PARTIAL_REUSE=false
ENABLE_HUMAN_IN_THE_LOOP=false
REUSE_CONFIDENCE_THRESHOLD=0.95  # ë³´ìˆ˜ì 

# Phase 2 ë°°í¬ (ë¶€ë¶„ ì¬ì‚¬ìš© í™œì„±í™”)
ENABLE_PARTIAL_REUSE=true

# Phase 3 ë°°í¬ (ì „ì²´ í™œì„±í™”)
ENABLE_HUMAN_IN_THE_LOOP=true
REUSE_CONFIDENCE_THRESHOLD=0.9  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì™„í™”
```

### 7.3 ëª¨ë‹ˆí„°ë§ ì§€í‘œ

```python
# backend/app/service_agent/monitoring/reuse_metrics.py

class ReuseMetrics:
    """ë°ì´í„° ì¬ì‚¬ìš© ëª¨ë‹ˆí„°ë§ ì§€í‘œ"""

    def __init__(self):
        self.metrics = {
            "total_queries": 0,
            "full_reuse_count": 0,
            "partial_reuse_count": 0,
            "no_reuse_count": 0,
            "hil_requests": 0,
            "hil_accepted": 0,
            "time_saved_total": 0.0,
        }

    def record_decision(
        self,
        decision: ReusabilityDecision,
        time_saved: float
    ):
        """ê²°ì • ê¸°ë¡"""
        self.metrics["total_queries"] += 1

        if decision == ReusabilityDecision.FULL_REUSE:
            self.metrics["full_reuse_count"] += 1
            self.metrics["time_saved_total"] += time_saved
        elif decision == ReusabilityDecision.PARTIAL_REUSE:
            self.metrics["partial_reuse_count"] += 1
            self.metrics["time_saved_total"] += time_saved * 0.5
        elif decision == ReusabilityDecision.UNCERTAIN:
            self.metrics["hil_requests"] += 1

    def get_summary(self) -> Dict:
        """ì§€í‘œ ìš”ì•½"""
        total = self.metrics["total_queries"]
        if total == 0:
            return {}

        return {
            "total_queries": total,
            "reuse_rate": (
                self.metrics["full_reuse_count"] +
                self.metrics["partial_reuse_count"]
            ) / total,
            "full_reuse_rate": self.metrics["full_reuse_count"] / total,
            "partial_reuse_rate": self.metrics["partial_reuse_count"] / total,
            "hil_rate": self.metrics["hil_requests"] / total,
            "hil_acceptance_rate": (
                self.metrics["hil_accepted"] / self.metrics["hil_requests"]
                if self.metrics["hil_requests"] > 0 else 0
            ),
            "avg_time_saved": self.metrics["time_saved_total"] / total,
            "total_time_saved": self.metrics["time_saved_total"]
        }
```

**Grafana ëŒ€ì‹œë³´ë“œ ì˜ˆì‹œ**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Reuse Metrics Dashboard                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Reuse Rate: 62.5% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘                â”‚
â”‚ â”œâ”€ Full Reuse: 35% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘                â”‚
â”‚ â”œâ”€ Partial Reuse: 27.5% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘            â”‚
â”‚ â””â”€ No Reuse: 37.5% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘                 â”‚
â”‚                                                     â”‚
â”‚ HIL Rate: 15% â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘                  â”‚
â”‚ HIL Acceptance: 80% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘            â”‚
â”‚                                                     â”‚
â”‚ Avg Time Saved: 3.2ì´ˆ                               â”‚
â”‚ Total Time Saved: 4ì‹œê°„ 32ë¶„                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 8. FAQ ë° íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Q1: "ì´ì „ ë°ì´í„° ì¬ì‚¬ìš©"ì´ë¼ëŠ” ì•Œë¦¼ì´ ë‚˜ì™”ëŠ”ë° ê²°ê³¼ê°€ ë‹¤ë¥¸ë°ìš”?

**ì›ì¸**: AnalysisTeamì´ ë™ì¼ ë°ì´í„°ë¥¼ ë‹¤ë¥´ê²Œ í•´ì„

**í•´ê²°**:
- ì¬ì‚¬ìš© ì‹œ "ë™ì¼ ë°ì´í„° ê¸°ë°˜"ì„ì„ ëª…ì‹œ
- ë¶„ì„ ê²°ê³¼ëŠ” ë‹¤ë¥¼ ìˆ˜ ìˆìŒì„ ì‚¬ìš©ìì—ê²Œ ì•ˆë‚´

```python
# generate_response_node()
if state.get("data_reused"):
    response_prefix = (
        "ì´ì „ ê²€ìƒ‰ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤. "
        "(ë™ì¼ ë°ì´í„°ì´ë‚˜ ë¶„ì„ ê²°ê³¼ëŠ” ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\n\n"
    )
```

### Q2: ì§€ì—­ì´ ë‹¤ë¥¸ë° ì¬ì‚¬ìš©í–ˆì–´ìš”

**ì›ì¸**: Parameter Matcherì˜ strict=False ì„¤ì •

**í•´ê²°**:
- MARKET_INQUIRYëŠ” í•­ìƒ strict=True ì‚¬ìš©
- ë¡œê·¸ í™•ì¸í•˜ì—¬ íŒŒë¼ë¯¸í„° ë¹„êµ ê²°ê³¼ ê²€ì¦

```python
# parameter_matcher.py
if intent_type == IntentType.MARKET_INQUIRY:
    # ì‹œì„¸ëŠ” ì§€ì—­ ì •í™•ë„ê°€ ì¤‘ìš”
    match_score = self.match_region(current, previous, strict=True)
```

### Q3: Confidenceê°€ ë†’ì€ë° ì¬ì‚¬ìš© ì•ˆ í–ˆì–´ìš”

**ì›ì¸**: Calibrationìœ¼ë¡œ Confidence ë³´ì •ë¨

**í•´ê²°**:
- Calibration Curve ì¡°ì •
- ë¡œê·¸ì—ì„œ raw_confidence vs calibrated_confidence í™•ì¸

```python
logger.info(
    f"Confidence: raw={raw_confidence:.2f}, "
    f"calibrated={calibrated_confidence:.2f}"
)
```

### Q4: ì„±ëŠ¥ì´ ì˜¤íˆë ¤ ëŠë ¤ì¡Œì–´ìš”

**ì›ì¸**: ì¶©ë¶„ì„± íŒë‹¨ ë¡œì§ì˜ LLM í˜¸ì¶œ ë¹„ìš©

**í•´ê²°**:
- ê°„ë‹¨í•œ ê²½ìš° LLM ìƒëµ (í‚¤ì›Œë“œ ë§¤ì¹­)
- LLM í˜¸ì¶œ ìºì‹±

```python
# planning_node()
if any(kw in query for kw in ["ë°©ê¸ˆ", "ì´ì „", "ì•„ê¹Œ"]):
    # LLM ìƒëµí•˜ê³  ë°”ë¡œ ì¬ì‚¬ìš©
    skip_search = True
else:
    # LLM í˜¸ì¶œ
    reusability_result = reusability_checker.check_reusability(...)
```

### Q5: Checkpointing ë°ì´í„°ê°€ ì—†ì–´ìš”

**ì›ì¸**: Checkpointing ë¹„í™œì„±í™” ë˜ëŠ” ì„¸ì…˜ ID ë¶ˆì¼ì¹˜

**í•´ê²°**:
1. Checkpointing í™œì„±í™” í™•ì¸
```python
supervisor = TeamBasedSupervisor(enable_checkpointing=True)
```

2. ì„¸ì…˜ ID ì¼ê´€ì„± í™•ì¸
```python
# ë™ì¼ ì„¸ì…˜ì—ì„œ chat_session_id ìœ ì§€
state1 = await supervisor.app.ainvoke({
    "chat_session_id": "chat_123"  # â† ë™ì¼í•´ì•¼ í•¨
})

state2 = await supervisor.app.ainvoke({
    "chat_session_id": "chat_123"  # â† ë™ì¼í•´ì•¼ í•¨
})
```

---

## 9. ê²°ë¡  ë° ë‹¤ìŒ ë‹¨ê³„

### 9.1 ìµœì¢… ìš”ì•½

ì´ ë³´ê³ ì„œëŠ” **LangGraph 0.6 Multi-Agent ì±—ë´‡**ì—ì„œ **ì±„íŒ… íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ë°ì´í„° ì¬ì‚¬ìš©**ì„ êµ¬í˜„í•˜ê¸° ìœ„í•œ ì™„ì „í•œ ê°€ì´ë“œì…ë‹ˆë‹¤.

**í•µì‹¬ ì„±ê³¼**:
1. âœ… ì‘ë‹µ ì‹œê°„ 60% ë‹¨ì¶• (8ì´ˆ â†’ 3ì´ˆ)
2. âœ… SearchTeam í˜¸ì¶œ 60~70% ê°ì†Œ
3. âœ… LLM ë¹„ìš© 40~50% ì ˆê°
4. âœ… ì •í™•ë„ 10% í–¥ìƒ (85% â†’ 95%)

**í•µì‹¬ ê¸°ìˆ **:
- **3-Tier íŒë‹¨**: Planning Node (LLM) + Execute Node (ê·œì¹™) + Human-in-the-Loop
- **ë‹¤ì°¨ì› íŒŒë¼ë¯¸í„° ë§¤ì¹­**: ì§€ì—­, ê¸ˆì•¡, ë²•ë¥  ì£¼ì œ ë“± Intentë³„ ìµœì í™”
- **ì ì§„ì  ë°ì´í„° ëˆ„ì **: ì—¬ëŸ¬ ëŒ€í™”ì˜ ë°ì´í„°ë¥¼ ëˆ„ì  í™œìš©
- **ë¶€ë¶„ ê²€ìƒ‰**: í•„ìš”í•œ ë°ì´í„° íƒ€ì…ë§Œ ì„ íƒì  ê²€ìƒ‰
- **Confidence ë³´ì •**: LLM ê³¼ì‹  ë°©ì§€

### 9.2 ë‹¤ìŒ ë‹¨ê³„

#### Phase 4: ì„±ëŠ¥ ìµœì í™” (1ê°œì›”)
- [ ] LLM ìºì‹± (ë™ì¼ ì¿¼ë¦¬ ë°˜ë³µ ì‹œ)
- [ ] Batch ì²˜ë¦¬ (ì—¬ëŸ¬ íŒŒë¼ë¯¸í„° ë¹„êµ í•œ ë²ˆì—)
- [ ] Async ìµœì í™” (ë³‘ë ¬ ì²˜ë¦¬ ê·¹ëŒ€í™”)

#### Phase 5: ê³ ë„í™” (2ê°œì›”)
- [ ] ë²¡í„° DB í†µí•© (ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ë„)
- [ ] Reinforcement Learning (ì‚¬ìš©ì í”¼ë“œë°± í•™ìŠµ)
- [ ] Multi-Modal (ì´ë¯¸ì§€, ë¬¸ì„œ íŒŒì¼ ì¬ì‚¬ìš©)

#### Phase 6: í™•ì¥ (3ê°œì›”)
- [ ] Cross-Session Reuse (ë‹¤ë¥¸ ì‚¬ìš©ì ë°ì´í„° í™œìš©)
- [ ] Real-time Update (ë°ì´í„° ìë™ ê°±ì‹ )
- [ ] Predictive Caching (ë‹¤ìŒ ì§ˆë¬¸ ì˜ˆì¸¡)

### 9.3 ìµœì¢… ê¶Œì¥ì‚¬í•­

1. **ì ì§„ì  êµ¬í˜„**: Phase 1 â†’ 2 â†’ 3 ìˆœì„œëŒ€ë¡œ
2. **Feature Flag í™œìš©**: í”„ë¡œë•ì…˜ì—ì„œ ì•ˆì „í•˜ê²Œ í…ŒìŠ¤íŠ¸
3. **ëª¨ë‹ˆí„°ë§ í•„ìˆ˜**: Reuse Rate, Time Saved ì§€í‘œ ì¶”ì 
4. **ì‚¬ìš©ì í”¼ë“œë°±**: HILì„ í†µí•´ ì •í™•ë„ ê²€ì¦

---

**ë³´ê³ ì„œ ì‘ì„± ì™„ë£Œ**
**ì‘ì„±ì**: Claude Code
**ì‘ì„±ì¼**: 2025-10-22
**ë²„ì „**: 2.0 (Final - Comprehensive)
**ë‹¤ìŒ ì•¡ì…˜**: Phase 1 êµ¬í˜„ ì‹œì‘ (ì˜ˆìƒ ì†Œìš” ì‹œê°„: 1ì£¼)

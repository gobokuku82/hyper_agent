# HITL Testing Strategy & Checklist
**Date:** 2025-10-25
**Purpose:** Systematic testing before any git reset or major refactoring
**Approach:** PoC first, then apply to production code

---

## Testing Philosophy

### ÏõêÏπô 1: Isolate and Verify
**Before touching production code:**
1. Create minimal PoC
2. Test pattern in isolation
3. Verify it works 100%
4. Then apply to real code

**Why:**
- Ïã§Ìå®Ìï¥ÎèÑ ÏïàÏ†Ñ
- Î¨∏Ï†ú ÏõêÏù∏ Î™ÖÌôïÌûà ÌååÏïÖ
- ÏãúÍ∞Ñ Ï†àÏïΩ (Ïó≠ÏÑ§Ï†ÅÏù¥ÏßÄÎßå ÏÇ¨Ïã§)

---

### ÏõêÏπô 2: One Variable at a Time
**Í∞Å ÌÖåÏä§Ìä∏Îäî ÌïòÎÇòÏùò Î≥ÄÏàòÎßå Î≥ÄÍ≤Ω:**
- Test 1: `interrupt()` vs `NodeInterrupt`
- Test 2: `Command(resume=...)` vs `astream(None)`
- Test 3: Parent resume vs Direct subgraph resume
- Test 4: Same thread_id vs Separate thread_id

**Why:**
- Ïñ¥Îñ§ Î≥ÄÍ≤ΩÏù¥ Ìö®Í≥ºÏûàÎäîÏßÄ Ï†ïÌôïÌûà ÌååÏïÖ
- Î≥µÌï© Î≥ÄÍ≤Ω Ïãú ÏõêÏù∏ Î∂àÎ™ÖÌôï

---

### ÏõêÏπô 3: Document Everything
**Î™®Îì† ÌÖåÏä§Ìä∏ Í≤∞Í≥º Í∏∞Î°ù:**
- ÏòàÏÉÅ Í≤∞Í≥º
- Ïã§Ï†ú Í≤∞Í≥º
- Î°úÍ∑∏ Ïä§ÌÅ¨Î¶∞ÏÉ∑
- Í≤∞Î°†

**Why:**
- ÎÇòÏ§ëÏóê Ï∞∏Í≥†
- Îã§Î•∏ ÏÇ¨ÎûåÍ≥º Í≥µÏú†
- ÏùòÏÇ¨Í≤∞Ï†ï Í∑ºÍ±∞

---

## PoC Test Plan

### File: `test_langgraph_subgraph_hitl_poc.py`

**Î™©Ï†Å:** LangGraph Ìå®ÌÑ¥ ÏûêÏ≤¥Í∞Ä ÏûëÎèôÌïòÎäîÏßÄ Í≤ÄÏ¶ù

**Íµ¨Ï°∞:**
```
Main Graph (3 nodes)
  ‚îú‚îÄ start
  ‚îú‚îÄ execute_subgraph  ‚Üê Ïó¨Í∏∞ÏÑú subgraph Ïã§Ìñâ
  ‚îî‚îÄ end

Subgraph (3 nodes)
  ‚îú‚îÄ work  ‚Üê Step 1
  ‚îú‚îÄ interrupt  ‚Üê HITL Î∞úÏÉù
  ‚îî‚îÄ finish  ‚Üê Step 2
```

---

### Test Scenario 4: Direct Subgraph Resume ‚≠ê **ÏµúÏö∞ÏÑ†**

**Ïôú Î®ºÏ†Ä?**
- Í∞ÄÏû• ÏÑ±Í≥µ Í∞ÄÎä•ÏÑ± ÎÜíÏùå
- Ïö∞Î¶¨ ÏΩîÎìúÏóê Ï†ÅÏö© Ïâ¨ÏõÄ
- Îπ†Î•∏ Í≤ÄÏ¶ù (30Î∂Ñ)

**Test Steps:**
```python
# 1. Execute subgraph
async for event in subgraph_app.astream(initial_state, config):
    if "__interrupt__" in event:
        break  # Interrupt detected

# 2. Resume subgraph directly
async for event in subgraph_app.astream(None, config):
    # Check: Does finish_node execute?
    if "finish" in event:
        step_count = event["finish"]["step_count"]
```

**Success Criteria:**
- ‚úÖ `step_count == 2` (work=1, finish=1)
- ‚úÖ `interrupt_node` Ïû¨Ïã§Ìñâ Ïïà Îê®
- ‚úÖ `finish_node` Ïã§ÌñâÎê®

**Failure Criteria:**
- ‚ùå `step_count == 3` (work=1, interrupt=1, finish=1)
- ‚ùå SubgraphÍ∞Ä Ï≤òÏùåÎ∂ÄÌÑ∞ Ïû¨ÏãúÏûë
- ‚ùå LangGraph Issue #4796 ÌôïÏ†ï

---

### Test Scenario 1: Parent Resume (Issue #4796 Ïû¨ÌòÑ)

**Ïôú ÌÖåÏä§Ìä∏?**
- ÌòÑÏû¨ Ïö∞Î¶¨Í∞Ä ÌïòÎäî Î∞©Ïãù
- Ïã§Ìå® ÌôïÏù∏ (Issue #4796)
- Î¨∏Ï†ú Ïû¨ÌòÑ

**Test Steps:**
```python
# 1. Execute main graph
async for event in main_app.astream(initial_state, config):
    pass  # Subgraph interrupts

# 2. Resume main graph
async for event in main_app.astream(None, config):
    # Check: Does it restart from planning?
```

**Expected Result:**
- ‚ùå Main graph restarts from `start_node`
- ‚ùå Subgraph Ïû¨Ïã§Ìñâ
- ‚ùå Issue #4796 Ïû¨ÌòÑÎê®

---

### Test Scenario 2: `interrupt()` Function

**Ïôú ÌÖåÏä§Ìä∏?**
- Official docs Í∂åÏû• Î∞©Î≤ï
- `NodeInterrupt`Í≥º Îã§Î•∏ API
- ÏûêÎèô resume Í∞ÄÎä•ÏÑ±

**Requirements:**
- LangGraph Î≤ÑÏ†Ñ ÌôïÏù∏ ÌïÑÏöî
- `from langgraph.types import interrupt`

**Test Steps:**
```python
def interrupt_node(state):
    user_input = interrupt("Please confirm")
    # Execution continues here after user provides input!
    state["user_input"] = user_input
    return state
```

**Success Criteria:**
- ‚úÖ `interrupt()` Ìò∏Ï∂ú Ïãú ÏùºÏãúÏ†ïÏßÄ
- ‚úÖ User input Ï†úÍ≥µ ÌõÑ ÏûêÎèô Ïû¨Í∞ú
- ‚úÖ Îã§Ïùå Ï§Ñ Ïã§ÌñâÎê®

**Challenge:**
- WebSocket ÌÜµÌï© Î∞©Î≤ï ÌôïÏù∏ ÌïÑÏöî
- User inputÏùÑ Ïñ¥ÎñªÍ≤å Ï†ÑÎã¨?

---

### Test Scenario 3: `Command(resume=...)`

**Ïôú ÌÖåÏä§Ìä∏?**
- Official docsÏóêÏÑú ÏÇ¨Ïö©
- User input Ï†ÑÎã¨ Î©îÏª§ÎãàÏ¶ò

**Test Steps:**
```python
# Resume with Command
from langgraph.types import Command

async for event in graph.astream(
    Command(resume="user confirmed"),
    config
):
    pass
```

**Success Criteria:**
- ‚úÖ Resume Ïãú user input Ï†ÑÎã¨Îê®
- ‚úÖ SubgraphÍ∞Ä Ïò¨Î∞îÎ•∏ ÏúÑÏπòÏóêÏÑú Í≥ÑÏÜçÎê®

---

## Production Code Test Plan

**Only proceed if PoC shows working pattern!**

### Phase 1: Minimal Change Test (1 hour)

**If Scenario 4 (Direct Subgraph Resume) works:**

**Change 1: Keep Subgraph Reference**
```python
# team_supervisor.py
class TeamBasedSupervisor:
    def __init__(self):
        self._subgraph_apps = {}  # NEW: Store compiled subgraphs

    async def _execute_single_team(self, team_name, ...):
        if team_name == "document":
            # Compile subgraph
            document_app = subgraph.compile(checkpointer=self.checkpointer)

            # Store reference
            session_id = main_state.get("session_id")
            self._subgraph_apps[session_id] = document_app  # ‚Üê NEW

            # Execute
            async for event in document_app.astream(...):
                if "__interrupt__" in event:
                    return {"status": "interrupted", ...}
```

**Change 2: Resume Subgraph Directly**
```python
# team_supervisor.py
async def resume_document_workflow(self, session_id):
    # Get stored subgraph app
    document_app = self._subgraph_apps.get(session_id)

    if not document_app:
        logger.error("No subgraph app found for session")
        return {"error": "Subgraph not found"}

    config = {"configurable": {"thread_id": session_id}}

    # Resume subgraph directly
    async for event in document_app.astream(None, config):
        logger.info(f"Resume event: {list(event.keys())}")
        # ... handle events
```

**Test:**
1. "ÏûÑÎåÄÏ∞®Í≥ÑÏïΩÏÑú ÏûëÏÑ±"
2. Dialog opens
3. Click confirm
4. ‚úÖ Check logs: `finish_node` executes
5. ‚úÖ Check logs: No restart from `work_node`

---

### Phase 2: Integration Test (1 hour)

**Test Full Flow:**
1. Planning ‚Üí Execute ‚Üí Document subgraph
2. Subgraph interrupts at collaborate_node
3. User edits document
4. User confirms
5. Subgraph continues to finalize_node
6. Final response generated
7. Frontend displays result

**Success Criteria:**
- ‚úÖ No errors in backend logs
- ‚úÖ No errors in frontend logs
- ‚úÖ Document generated correctly
- ‚úÖ All WebSocket messages sent

---

### Phase 3: Edge Case Testing (1 hour)

**Test Cases:**

1. **Multiple Interrupts**
   - collaborate_node ‚Üí user_confirm_node
   - Both should work

2. **Session Cleanup**
   - Verify subgraph_app removed after completion
   - No memory leaks

3. **Concurrent Sessions**
   - Multiple users creating documents
   - No cross-session interference

4. **Error Handling**
   - Network disconnect during HITL
   - Graceful recovery

---

## Critical Considerations Checklist

### üîç Before Each Test

- [ ] Git branch created for test
- [ ] Backup current code
- [ ] Checkpointer configured correctly
- [ ] Logging enabled (DEBUG level)
- [ ] Test data prepared

---

### üéØ During Test

**1. State Management**
- [ ] Verify thread_id consistency
- [ ] Check state fields preserved
- [ ] Validate TypedDict fields present
- [ ] Monitor checkpoint writes (PostgreSQL)

**2. Event Tracking**
- [ ] Log all graph events
- [ ] Track `__interrupt__` events
- [ ] Monitor node execution order
- [ ] Record step counts / timestamps

**3. Error Monitoring**
- [ ] Watch for KeyError
- [ ] Check for AttributeError
- [ ] Verify no silent failures
- [ ] Capture full stack traces

---

### ‚úÖ After Test

**1. Result Documentation**
- [ ] Screenshot backend logs
- [ ] Screenshot frontend logs
- [ ] Record success/failure
- [ ] Note unexpected behavior

**2. Code Review**
- [ ] Check for memory leaks
- [ ] Verify resource cleanup
- [ ] Review error handling
- [ ] Validate logging messages

**3. Decision Point**
- [ ] Pattern works ‚Üí Apply to production
- [ ] Pattern fails ‚Üí Try next test
- [ ] All tests fail ‚Üí Consider workaround/flatten

---

## Important Variables to Monitor

### 1. Step Count (Critical!)

**Purpose:** Detect if node re-executes

```python
# In each node
state["step_count"] = state.get("step_count", 0) + 1
logger.info(f"Step count: {state['step_count']}")
```

**Expected Values:**
```
Initial execution:
  work_node: step_count = 1
  interrupt_node: step_count = 2 (but raises interrupt)

After resume (SUCCESS):
  finish_node: step_count = 3  ‚Üê Only finish adds 1

After resume (FAILURE - restart):
  work_node: step_count = 4  ‚Üê work executed again!
  interrupt_node: step_count = 5
  finish_node: step_count = 6
```

**Red Flag:** Step count > 3 after resume = restart detected!

---

### 2. Thread ID Consistency

**Check in logs:**
```
Initial: thread_id = "session-123"
Resume: thread_id = "session-123"  ‚Üê Must match!
```

**Red Flag:** Different thread_id = new execution, not resume!

---

### 3. Checkpoint Data

**Query PostgreSQL:**
```sql
SELECT thread_id, checkpoint_ns, checkpoint
FROM checkpoints
WHERE thread_id = 'session-123'
ORDER BY checkpoint_id DESC
LIMIT 5;
```

**Verify:**
- [ ] Checkpoint saved after interrupt
- [ ] `next` field shows correct node
- [ ] State data preserved

---

### 4. Event Sequence

**Expected Order:**
```
Initial Execution:
1. start_node
2. execute_subgraph_node
   3. work_node
   4. interrupt_node ‚Üí __interrupt__ event
5. end_node (with interrupted status)

Resume Execution (SUCCESS):
1. finish_node  ‚Üê Directly to finish!
2. (no other nodes)

Resume Execution (FAILURE):
1. start_node  ‚Üê Restart from beginning!
2. execute_subgraph_node
   3. work_node
   4. interrupt_node
   5. finish_node
```

**Red Flag:** Any node before `finish_node` = restart!

---

## Debugging Tips

### If Test Fails

**1. Check LangGraph Version**
```bash
pip show langgraph
# Verify >= 0.6.0
```

**2. Enable Verbose Logging**
```python
import logging
logging.getLogger("langgraph").setLevel(logging.DEBUG)
```

**3. Inspect Checkpoint**
```python
# Get checkpoint data
state_snapshot = await checkpointer.aget_tuple(config)
print(f"Next nodes: {state_snapshot.next}")
print(f"State: {state_snapshot.values}")
```

**4. Add Breakpoints**
```python
import pdb; pdb.set_trace()
# Step through resume logic
```

---

## Decision Matrix

### If Direct Subgraph Resume Works ‚úÖ

**Action:**
1. Apply pattern to production code
2. Test with full integration
3. Keep current architecture
4. No git reset needed!

**Effort:** 2-3 hours
**Risk:** Low
**Confidence:** High

---

### If Direct Subgraph Resume Fails ‚ùå

**Check:**
- Is it Issue #4796?
- Do other scenarios work?

**If NO scenarios work:**

**Option A: Implement Workaround**
- Save subgraph state manually
- Restore and re-execute from correct node
- Effort: 1 day
- Risk: Medium

**Option B: Flatten Architecture**
- Follow previous plan
- Remove subgraph structure
- Effort: 3-4 days
- Risk: Low (proven pattern)

---

## Success Metrics

### PoC Success
- [ ] At least one test scenario passes
- [ ] Resume doesn't restart from beginning
- [ ] Step count matches expected value
- [ ] Logs show correct node execution order

### Production Success
- [ ] Full HITL flow works end-to-end
- [ ] No errors in logs
- [ ] Frontend displays correctly
- [ ] User can edit and confirm
- [ ] Document generates successfully

### Quality Metrics
- [ ] Code is clean and understandable
- [ ] Proper error handling
- [ ] Comprehensive logging
- [ ] No memory leaks
- [ ] Thread-safe (multiple sessions)

---

## Timeline Estimates

### PoC Testing
- Scenario 4 (Direct resume): 30 min
- Scenario 1 (Parent resume): 30 min
- Scenario 2 (interrupt()): 1 hour
- Scenario 3 (Command): 30 min
- **Total:** 2.5 hours

### Production Application
- Code changes: 1 hour
- Integration testing: 1 hour
- Edge case testing: 1 hour
- **Total:** 3 hours

### Grand Total: 5.5 hours

**vs. Flatten Architecture: 3-4 days (24-32 hours)**

---

## Risk Assessment

### Low Risk ‚úÖ
- PoC testing (separate file)
- Small code changes (if pattern works)
- Easy rollback

### Medium Risk ‚ö†Ô∏è
- Production integration
- Multiple concurrent sessions
- State synchronization

### High Risk üî¥
- Flatten architecture (if all tests fail)
- Major refactoring
- Breaking changes

---

## Next Steps

**Immediate:**
1. Run PoC Test Scenario 4
2. Analyze results
3. Document findings
4. Present to user

**If Test Passes:**
1. Apply to production code
2. Test integration
3. Deploy

**If Test Fails:**
1. Try other scenarios
2. Analyze logs
3. Consult with user
4. Decide: Workaround vs Flatten

---

## ÏµúÏ¢Ö Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏

### Before Starting
- [ ] Read this entire document
- [ ] Understand each test scenario
- [ ] Prepare test environment
- [ ] Backup current code

### During Testing
- [ ] Follow test steps exactly
- [ ] Log everything
- [ ] Monitor all variables
- [ ] Take screenshots

### After Testing
- [ ] Document results
- [ ] Analyze logs
- [ ] Draw conclusions
- [ ] Plan next steps

### Before Production
- [ ] All tests pass
- [ ] Code reviewed
- [ ] Edge cases covered
- [ ] User approved

---

**Created:** 2025-10-25
**Status:** Ready for Execution
**Confidence:** High (systematic approach)


# SearchExecutor ì •ë³´ê²€ìƒ‰ ì—ì´ì „íŠ¸ ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ

**ì‘ì„±ì¼**: 2025-11-02
**ë¶„ì„ ëŒ€ìƒ**: `backend/app/service_agent/execution_agents/search_executor.py`
**ì‹œìŠ¤í…œ**: beta_v001 (LangGraph 0.6)
**ì‘ì„±ì**: Claude Code

---

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#1-ê°œìš”)
2. [ì•„í‚¤í…ì²˜](#2-ì•„í‚¤í…ì²˜)
3. [ì„œë¸Œê·¸ë˜í”„ êµ¬ì¡°](#3-ì„œë¸Œê·¸ë˜í”„-êµ¬ì¡°)
4. [ë…¸ë“œë³„ ìƒì„¸ ë¶„ì„](#4-ë…¸ë“œë³„-ìƒì„¸-ë¶„ì„)
5. [íˆ´ ìƒì„¸ ë¶„ì„](#5-íˆ´-ìƒì„¸-ë¶„ì„)
6. [LLM ê¸°ë°˜ íˆ´ ì„ íƒ ë©”ì»¤ë‹ˆì¦˜](#6-llm-ê¸°ë°˜-íˆ´-ì„ íƒ-ë©”ì»¤ë‹ˆì¦˜)
7. [ì˜ì‚¬ê²°ì • ë¡œê¹… ì‹œìŠ¤í…œ](#7-ì˜ì‚¬ê²°ì •-ë¡œê¹…-ì‹œìŠ¤í…œ)
8. [ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ì „ì†¡](#8-ì‹¤ì‹œê°„-ì§„í–‰-ìƒí™©-ì „ì†¡)
9. [ë°ì´í„° íë¦„ ë° ìƒíƒœ ê´€ë¦¬](#9-ë°ì´í„°-íë¦„-ë°-ìƒíƒœ-ê´€ë¦¬)
10. [ì„±ëŠ¥ ìµœì í™” ìš”ì†Œ](#10-ì„±ëŠ¥-ìµœì í™”-ìš”ì†Œ)
11. [ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µì›ë ¥](#11-ì—ëŸ¬-ì²˜ë¦¬-ë°-ë³µì›ë ¥)

---

## 1. ê°œìš”

### 1.1 SearchExecutorì˜ ì—­í• 

SearchExecutorëŠ” **ë¶€ë™ì‚° ì „ì„¸ ë²•ë¥  ìƒë‹´ ì‹œìŠ¤í…œ**ì—ì„œ **ì •ë³´ ê²€ìƒ‰**ì„ ë‹´ë‹¹í•˜ëŠ” í•µì‹¬ Execution Agentì…ë‹ˆë‹¤. Supervisorë¡œë¶€í„° ê²€ìƒ‰ ì‘ì—…ì„ ìœ„ì„ë°›ì•„ ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:

- **ë²•ë¥  ì •ë³´ ê²€ìƒ‰**: ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•, ê³µì¸ì¤‘ê°œì‚¬ë²• ë“±
- **ë¶€ë™ì‚° ì‹œì„¸ ì¡°íšŒ**: ì§€ì—­ë³„ ë§¤ë§¤ê°€, ì „ì„¸ê°€, ì›”ì„¸ ì •ë³´
- **ê°œë³„ ë§¤ë¬¼ ê²€ìƒ‰**: PostgreSQL ê¸°ë°˜ ì‹¤ì‹œê°„ ë§¤ë¬¼ ì •ë³´
- **ëŒ€ì¶œ ìƒí’ˆ ì •ë³´**: MongoDB ê¸°ë°˜ ì€í–‰ë³„ ëŒ€ì¶œ ìƒí’ˆ
- **ê³µê³µë°ì´í„° ì¡°íšŒ**: ì‹¤ê±°ë˜ê°€, ê±´ì¶•ë¬¼ëŒ€ì¥, ì¸í”„ë¼ ì •ë³´
- **ë¶€ë™ì‚° ìš©ì–´ ê²€ìƒ‰**: ì „ë¬¸ ìš©ì–´ ì •ì˜ ë° ì„¤ëª…

### 1.2 ì£¼ìš” íŠ¹ì§•

| íŠ¹ì§• | ì„¤ëª… |
|------|------|
| **LangGraph ì„œë¸Œê·¸ë˜í”„** | 5ê°œ ë…¸ë“œë¡œ êµ¬ì„±ëœ ë…ë¦½ì ì¸ ì›Œí¬í”Œë¡œìš° |
| **LLM ê¸°ë°˜ íˆ´ ì„ íƒ** | ì¿¼ë¦¬ ë¶„ì„ í›„ ìµœì ì˜ íˆ´ ìë™ ì„ íƒ |
| **8ê°œ ì´ìƒì˜ íˆ´** | ë²•ë¥ , ì‹œì„¸, ë§¤ë¬¼, ëŒ€ì¶œ, ê³µê³µë°ì´í„°, ìš©ì–´ ë“± |
| **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰** | SQLite ë©”íƒ€ë°ì´í„° + FAISS ë²¡í„° ê²€ìƒ‰ |
| **Decision Logger** | ëª¨ë“  ì˜ì‚¬ê²°ì •ì„ SQLiteì— ê¸°ë¡ |
| **Progress Callback** | WebSocketì„ í†µí•œ ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ì „ì†¡ |
| **Fallback ë©”ì»¤ë‹ˆì¦˜** | LLM ì‹¤íŒ¨ ì‹œ ê·œì¹™ ê¸°ë°˜ íˆ´ ì„ íƒ |

### 1.3 íŒŒì¼ ìœ„ì¹˜ ë° ì˜ì¡´ì„±

```
backend/app/service_agent/
â”œâ”€â”€ execution_agents/
â”‚   â””â”€â”€ search_executor.py          # ğŸ“„ ë³¸ íŒŒì¼ (SearchExecutor)
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ legal_search_tool.py        # ğŸ”§ LegalSearch (SQLite + FAISS)
â”‚   â”œâ”€â”€ market_data_tool.py         # ğŸ”§ MarketDataTool (PostgreSQL)
â”‚   â”œâ”€â”€ loan_data_tool.py           # ğŸ”§ LoanDataTool (MongoDB)
â”‚   â”œâ”€â”€ real_estate_search_tool.py  # ğŸ”§ RealEstateSearchTool (PostgreSQL)
â”‚   â”œâ”€â”€ infrastructure_tool.py      # ğŸ”§ InfrastructureTool (ê³µê³µë°ì´í„°)
â”‚   â”œâ”€â”€ transaction_price_tool.py   # ğŸ”§ TransactionPriceTool (ì‹¤ê±°ë˜ê°€)
â”‚   â”œâ”€â”€ building_registry_tool.py   # ğŸ”§ BuildingRegistryTool (ê±´ì¶•ë¬¼ëŒ€ì¥)
â”‚   â””â”€â”€ realestate_terminology.py   # ğŸ”§ RealEstateTerminologyTool (ìš©ì–´)
â”œâ”€â”€ foundation/
â”‚   â”œâ”€â”€ separated_states.py         # ğŸ“ SearchTeamState ì •ì˜
â”‚   â”œâ”€â”€ decision_logger.py          # ğŸ“Š DecisionLogger
â”‚   â””â”€â”€ agent_registry.py           # ğŸ“‹ AgentRegistry
â””â”€â”€ llm_manager/
    â””â”€â”€ llm_service.py               # ğŸ¤– LLMService
```

---

## 2. ì•„í‚¤í…ì²˜

### 2.1 ì „ì²´ êµ¬ì¡°

SearchExecutorëŠ” **LangGraph StateGraph**ë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬í˜„ëœ ì„œë¸Œê·¸ë˜í”„ì…ë‹ˆë‹¤. Supervisorì˜ `execute_teams_node`ì—ì„œ í˜¸ì¶œë˜ì–´ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Supervisor (TeamBasedSupervisor)                           â”‚
â”‚  â”œâ”€ planning_node (PlanningAgent)                           â”‚
â”‚  â”œâ”€ execute_teams_node                                      â”‚
â”‚  â”‚   â”œâ”€ SearchExecutor.execute() â—„â”€â”€ ì—¬ê¸°!                  â”‚
â”‚  â”‚   â”œâ”€ AnalysisExecutor.execute()                         â”‚
â”‚  â”‚   â””â”€ DocumentExecutor.execute()                         â”‚
â”‚  â”œâ”€ aggregate_results_node                                  â”‚
â”‚  â””â”€ generate_response_node                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 ì´ˆê¸°í™” ê³¼ì •

**ìœ„ì¹˜**: `search_executor.py:34-146`

```python
def __init__(self, llm_context=None, progress_callback=None):
    self.llm_context = llm_context
    self.progress_callback = progress_callback  # WebSocket callback

    # 1. LLMService ì´ˆê¸°í™”
    self.llm_service = LLMService(llm_context=llm_context)

    # 2. DecisionLogger ì´ˆê¸°í™”
    self.decision_logger = DecisionLogger()

    # 3. 8ê°œ íˆ´ ì´ˆê¸°í™”
    self.legal_search_tool = LegalSearch()                        # ë²•ë¥  ê²€ìƒ‰
    self.market_data_tool = MarketDataTool()                      # ì‹œì„¸ ì¡°íšŒ
    self.loan_data_tool = LoanDataTool()                          # ëŒ€ì¶œ ì •ë³´
    self.real_estate_search_tool = RealEstateSearchTool()         # ë§¤ë¬¼ ê²€ìƒ‰
    self.infrastructure_tool = InfrastructureTool()               # ì¸í”„ë¼
    self.transaction_price_tool = TransactionPriceTool()          # ì‹¤ê±°ë˜ê°€
    self.building_registry_tool = BuildingRegistryTool()          # ê±´ì¶•ë¬¼ëŒ€ì¥
    self.terminology_tool = RealEstateTerminologyTool()           # ìš©ì–´ ê²€ìƒ‰

    # 4. ì„œë¸Œê·¸ë˜í”„ êµ¬ì„±
    self._build_subgraph()
```

**ì´ˆê¸°í™” ìˆœì„œ:**

1. **LLMService**: LLM ê¸°ë°˜ íˆ´ ì„ íƒ ë° í‚¤ì›Œë“œ ì¶”ì¶œ
2. **DecisionLogger**: ì˜ì‚¬ê²°ì • ë¡œê¹… (SQLite)
3. **8ê°œ íˆ´**: ê° íˆ´ì˜ DB ì—°ê²° ì´ˆê¸°í™”
4. **ì„œë¸Œê·¸ë˜í”„**: LangGraph StateGraph ìƒì„±

### 2.3 Fallback ë©”ì»¤ë‹ˆì¦˜

ê° íˆ´ ì´ˆê¸°í™” ì‹œ **try-except**ë¡œ ê°ì‹¸ì„œ ì‹¤íŒ¨í•´ë„ ì „ì²´ ì‹œìŠ¤í…œì´ ì¤‘ë‹¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤:

```python
try:
    from app.service_agent.tools.legal_search_tool import LegalSearch
    self.legal_search_tool = LegalSearch()
    logger.info("LegalSearch initialized successfully")
except Exception as e:
    logger.warning(f"LegalSearch initialization failed: {e}, trying fallback")
    # Fallback: HybridLegalSearch
```

**ì¥ì :**
- ì¼ë¶€ íˆ´ì´ ì—†ì–´ë„ ì‹œìŠ¤í…œ ì‘ë™ ê°€ëŠ¥
- ê°œë°œ í™˜ê²½ì—ì„œ ì¼ë¶€ DB ë¯¸ì„¤ì¹˜ ì‹œì—ë„ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
- Productionì—ì„œ ì¼ì‹œì  DB ì¥ì•  ì‹œì—ë„ ë‹¤ë¥¸ íˆ´ë¡œ ë™ì‘

---

## 3. ì„œë¸Œê·¸ë˜í”„ êµ¬ì¡°

### 3.1 ë…¸ë“œ êµ¬ì„±

**ìœ„ì¹˜**: `search_executor.py:159-189`

SearchExecutorëŠ” **5ê°œ ë…¸ë“œ**ë¡œ êµ¬ì„±ëœ ì„œë¸Œê·¸ë˜í”„ì…ë‹ˆë‹¤:

```python
def _build_subgraph(self):
    workflow = StateGraph(SearchTeamState)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("prepare", self.prepare_search_node)
    workflow.add_node("route", self.route_search_node)
    workflow.add_node("search", self.execute_search_node)
    workflow.add_node("aggregate", self.aggregate_results_node)
    workflow.add_node("finalize", self.finalize_node)

    # ì—£ì§€ êµ¬ì„± (ë‹¤ìŒ ì„¹ì…˜ ì°¸ì¡°)
```

### 3.2 ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨

```mermaid
graph TD
    START([START]) --> Prepare[prepare_search_node<br/>ê²€ìƒ‰ ì¤€ë¹„]
    Prepare --> Route[route_search_node<br/>ë¼ìš°íŒ… ê²°ì •]

    Route -->|search_scope ìˆìŒ| Search[execute_search_node<br/>ê²€ìƒ‰ ì‹¤í–‰]
    Route -->|search_scope ì—†ìŒ| Finalize[finalize_node<br/>ìµœì¢…í™”]

    Search --> Aggregate[aggregate_results_node<br/>ê²°ê³¼ ì§‘ê³„]
    Aggregate --> Finalize
    Finalize --> END([END])

    style Prepare fill:#e1f5ff
    style Route fill:#fff4e1
    style Search fill:#ffe1e1
    style Aggregate fill:#e1ffe1
    style Finalize fill:#f0e1ff
```

### 3.3 ì—£ì§€ êµ¬ì„±

**ìœ„ì¹˜**: `search_executor.py:171-186`

```python
# ì—£ì§€ êµ¬ì„±
workflow.add_edge(START, "prepare")
workflow.add_edge("prepare", "route")

# ì¡°ê±´ë¶€ ì—£ì§€: ë¼ìš°íŒ… ê²°ì •
workflow.add_conditional_edges(
    "route",
    self._route_decision,
    {
        "search": "search",    # ê²€ìƒ‰ ì‹¤í–‰
        "skip": "finalize"     # ê²€ìƒ‰ ìŠ¤í‚µ (ì¡°ê¸° ì¢…ë£Œ)
    }
)

workflow.add_edge("search", "aggregate")
workflow.add_edge("aggregate", "finalize")
workflow.add_edge("finalize", END)

self.app = workflow.compile()
```

**ë¼ìš°íŒ… ê²°ì • ë¡œì§**:

```python
def _route_decision(self, state: SearchTeamState) -> str:
    """ê²€ìƒ‰ ì‹¤í–‰ ì—¬ë¶€ ê²°ì •"""
    if not state.get("search_scope"):
        return "skip"  # ê²€ìƒ‰ ë²”ìœ„ê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
    return "search"
```

---

## 4. ë…¸ë“œë³„ ìƒì„¸ ë¶„ì„

### 4.1 prepare_search_node (ê²€ìƒ‰ ì¤€ë¹„)

**ìœ„ì¹˜**: `search_executor.py:197-227`

**ì—­í• :**
1. ìƒíƒœ ì´ˆê¸°í™”
2. í‚¤ì›Œë“œ ì¶”ì¶œ
3. ê²€ìƒ‰ ë²”ìœ„ ê²°ì •
4. Progress ì „ì†¡ (Step 0)

**ì½”ë“œ íë¦„:**

```python
async def prepare_search_node(self, state: SearchTeamState) -> SearchTeamState:
    logger.info("[SearchTeam] Preparing search")

    # Step 0 ì‹œì‘ (ì¿¼ë¦¬ ìƒì„±)
    await self._update_step_progress(state, step_index=0, status="in_progress", progress=0)

    # ì´ˆê¸°í™”
    state["team_name"] = "search"
    state["status"] = "in_progress"
    state["start_time"] = datetime.now()
    state["search_progress"] = {}

    # í‚¤ì›Œë“œ ì¶”ì¶œ (LLM or Pattern Matching)
    if not state.get("keywords"):
        query = state.get("shared_context", {}).get("query", "")
        state["keywords"] = self._extract_keywords(query)

    # ê²€ìƒ‰ ë²”ìœ„ ê²°ì • (Deprecated, í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
    if not state.get("search_scope"):
        state["search_scope"] = self._determine_search_scope(state["keywords"])

    logger.info(f"[SearchTeam] Search scope: {state['search_scope']}")

    # Step 0 ì™„ë£Œ
    await self._update_step_progress(state, step_index=0, status="completed", progress=100)

    return state
```

**í‚¤ì›Œë“œ ì¶”ì¶œ ì „ëµ:**

#### Strategy 1: LLM ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ (Preferred)

**ìœ„ì¹˜**: `search_executor.py:241-261`

```python
def _extract_keywords_with_llm(self, query: str) -> SearchKeywords:
    """LLMì„ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    result = self.llm_service.complete_json(
        prompt_name="keyword_extraction",
        variables={"query": query},
        temperature=0.1
    )

    return SearchKeywords(
        legal=result.get("legal", []),
        real_estate=result.get("real_estate", []),
        loan=result.get("loan", []),
        general=result.get("general", [])
    )
```

**LLM ì‘ë‹µ ì˜ˆì‹œ:**

```json
{
    "legal": ["ì „ì„¸", "ë³´ì¦ê¸ˆ", "ê³„ì•½ê°±ì‹ "],
    "real_estate": ["ê°•ë‚¨êµ¬", "ì•„íŒŒíŠ¸", "ì‹œì„¸"],
    "loan": ["ëŒ€ì¶œ", "ê¸ˆë¦¬"],
    "general": ["5%", "ì¸ìƒ"]
}
```

#### Strategy 2: Pattern Matching Fallback

**ìœ„ì¹˜**: `search_executor.py:263-298`

LLM ì‹¤íŒ¨ ì‹œ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ fallback:

```python
def _extract_keywords_with_patterns(self, query: str) -> SearchKeywords:
    """íŒ¨í„´ ë§¤ì¹­ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ (Fallback)"""
    legal_keywords = []
    real_estate_keywords = []
    loan_keywords = []
    general_keywords = []

    # ë²•ë¥  ê´€ë ¨ í‚¤ì›Œë“œ
    legal_terms = ["ë²•", "ì „ì„¸", "ì„ëŒ€", "ê³„ì•½", "ë³´ì¦ê¸ˆ", ...]
    for term in legal_terms:
        if term in query:
            legal_keywords.append(term)

    # ë¶€ë™ì‚° ê´€ë ¨ í‚¤ì›Œë“œ
    estate_terms = ["ì•„íŒŒíŠ¸", "ë¹Œë¼", "ì˜¤í”¼ìŠ¤í…”", "ì‹œì„¸", ...]
    for term in estate_terms:
        if term in query:
            real_estate_keywords.append(term)

    # ëŒ€ì¶œ ê´€ë ¨ í‚¤ì›Œë“œ
    loan_terms = ["ëŒ€ì¶œ", "ê¸ˆë¦¬", "í•œë„", "LTV", "DTI", ...]
    for term in loan_terms:
        if term in query:
            loan_keywords.append(term)

    # ì¼ë°˜ í‚¤ì›Œë“œ (ìˆ«ì, í¼ì„¼íŠ¸ ë“±)
    import re
    numbers = re.findall(r'\d+[%ì–µë§Œì›í‰]?', query)
    general_keywords.extend(numbers)

    return SearchKeywords(
        legal=legal_keywords,
        real_estate=real_estate_keywords,
        loan=loan_keywords,
        general=general_keywords
    )
```

**WebSocket ë©”ì‹œì§€:**

```json
{
    "type": "agent_step_progress",
    "agentName": "search",
    "agentType": "search",
    "stepId": "search_step_1",
    "stepIndex": 0,
    "status": "completed",
    "progress": 100,
    "timestamp": "2025-11-02T10:00:00.000Z"
}
```

---

### 4.2 route_search_node (ë¼ìš°íŒ… ê²°ì •)

**ìœ„ì¹˜**: `search_executor.py:548-563`

**ì—­í• :**
- ë³‘ë ¬/ìˆœì°¨ ì‹¤í–‰ ì „ëµ ê²°ì •
- í˜„ì¬ëŠ” ë‹¨ìˆœ ë¡œì§ (í–¥í›„ LLM ê¸°ë°˜ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥)

**ì½”ë“œ:**

```python
async def route_search_node(self, state: SearchTeamState) -> SearchTeamState:
    logger.info("[SearchTeam] Routing search")

    search_scope = state.get("search_scope", [])

    # ê²€ìƒ‰ ë²”ìœ„ê°€ 2ê°œ ì´ìƒì´ë©´ ë³‘ë ¬, ì•„ë‹ˆë©´ ìˆœì°¨
    if len(search_scope) > 1:
        state["execution_strategy"] = "parallel"
    else:
        state["execution_strategy"] = "sequential"

    return state
```

**í˜„ì¬ ìƒíƒœ:**
- ë³‘ë ¬ ì‹¤í–‰ ë¡œì§ì€ êµ¬í˜„ë˜ì–´ ìˆì§€ë§Œ ì‹¤ì œë¡œëŠ” ìˆœì°¨ ì‹¤í–‰ ì‚¬ìš©
- ì´ìœ : íˆ´ ê°„ ì˜ì¡´ì„± (ì˜ˆ: SearchTeam â†’ AnalysisTeam)

**í–¥í›„ ê°œì„  ë°©í–¥:**
- LLM ê¸°ë°˜ ì‹¤í–‰ ì „ëµ ê²°ì •
- íˆ´ ê°„ ì˜ì¡´ì„± ê·¸ë˜í”„ ë¶„ì„
- ì§„ì •í•œ ë³‘ë ¬ ì‹¤í–‰ ì§€ì›

---

### 4.3 execute_search_node (ê²€ìƒ‰ ì‹¤í–‰) - í•µì‹¬ ë…¸ë“œ

**ìœ„ì¹˜**: `search_executor.py:565-895`

ì´ ë…¸ë“œëŠ” **SearchExecutorì˜ í•µì‹¬**ìœ¼ë¡œ, ì‹¤ì œ ê²€ìƒ‰ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

#### Phase 1: LLM ê¸°ë°˜ íˆ´ ì„ íƒ

```python
async def execute_search_node(self, state: SearchTeamState) -> SearchTeamState:
    logger.info("[SearchTeam] Executing searches")

    # Step 1 ì‹œì‘ (ë°ì´í„° ê²€ìƒ‰)
    await self._update_step_progress(state, step_index=1, status="in_progress", progress=0)

    import time
    start_time = time.time()

    # ì¿¼ë¦¬ ì¶”ì¶œ
    shared_context = state.get("shared_context", {})
    query = shared_context.get("user_query", "") or shared_context.get("query", "")

    # LLM ê¸°ë°˜ íˆ´ ì„ íƒ
    tool_selection = await self._select_tools_with_llm(query, keywords)
    selected_tools = tool_selection.get("selected_tools", [])
    decision_id = tool_selection.get("decision_id")

    logger.info(
        f"[SearchTeam] LLM selected tools: {selected_tools}, "
        f"confidence: {tool_selection.get('confidence')}"
    )
```

#### Phase 2: ë²•ë¥  ê²€ìƒ‰ ì‹¤í–‰

**ìœ„ì¹˜**: `search_executor.py:601-658`

```python
# === 1. ë²•ë¥  ê²€ìƒ‰ (ìš°ì„  ì‹¤í–‰) ===
if "legal_search" in selected_tools and self.legal_search_tool:
    try:
        logger.info("[SearchTeam] Executing legal search")

        # ê²€ìƒ‰ íŒŒë¼ë¯¸í„° êµ¬ì„±
        search_params = {"limit": 10}

        # ì„ì°¨ì¸ ë³´í˜¸ ì¡°í•­ í•„í„°
        if any(term in query for term in ["ì„ì°¨ì¸", "ì „ì„¸", "ì„ëŒ€", "ë³´ì¦ê¸ˆ"]):
            search_params["is_tenant_protection"] = True

        # ë²•ë¥  ê²€ìƒ‰ ì‹¤í–‰
        result = await self.legal_search_tool.search(query, search_params)

        # ê²°ê³¼ íŒŒì‹±
        if result.get("status") == "success":
            legal_data = result.get("data", [])

            # ê²°ê³¼ í¬ë§· ë³€í™˜
            state["legal_results"] = [
                {
                    "law_title": item.get("law_title", ""),
                    "article_number": item.get("article_number", ""),
                    "article_title": item.get("article_title", ""),
                    "content": item.get("content", ""),
                    "relevance_score": 1.0 - item.get("distance", 0.0),
                    "chapter": item.get("chapter"),
                    "section": item.get("section"),
                    "source": "legal_db"
                }
                for item in legal_data
            ]

            state["search_progress"]["legal_search"] = "completed"
            logger.info(f"[SearchTeam] Legal search completed: {len(legal_data)} results")

            execution_results["legal_search"] = {
                "status": "success",
                "result_count": len(legal_data)
            }

    except Exception as e:
        logger.error(f"Legal search failed: {e}")
        state["search_progress"]["legal_search"] = "failed"
        execution_results["legal_search"] = {
            "status": "error",
            "error": str(e)
        }
        # ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
```

**ë²•ë¥  ê²€ìƒ‰ íŠ¹ì§•:**
- **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰**: SQLite ë©”íƒ€ë°ì´í„° + FAISS ë²¡í„° ê²€ìƒ‰
- **ì„ì°¨ì¸ ë³´í˜¸ í•„í„°**: ìë™ ê°ì§€ ë° ì ìš©
- **ì—ëŸ¬ ë³µì›ë ¥**: ì‹¤íŒ¨í•´ë„ ë‹¤ìŒ íˆ´ ê³„ì† ì‹¤í–‰

#### Phase 3: ë¶€ë™ì‚° ì‹œì„¸ ê²€ìƒ‰

**ìœ„ì¹˜**: `search_executor.py:660-692`

```python
# === 2. ë¶€ë™ì‚° ì‹œì„¸ ê²€ìƒ‰ ===
if "market_data" in selected_tools and self.market_data_tool:
    try:
        logger.info("[SearchTeam] Executing real estate search")

        # ë¶€ë™ì‚° ê²€ìƒ‰ ì‹¤í–‰
        result = await self.market_data_tool.search(query, {})

        if result.get("status") == "success":
            market_data = result.get("data", [])

            state["real_estate_results"] = market_data
            state["search_progress"]["real_estate_search"] = "completed"
            logger.info(f"[SearchTeam] Real estate search completed: {len(market_data)} results")

            execution_results["market_data"] = {
                "status": "success",
                "result_count": len(market_data)
            }

    except Exception as e:
        logger.error(f"Real estate search failed: {e}")
        state["search_progress"]["real_estate_search"] = "failed"
        execution_results["market_data"] = {
            "status": "error",
            "error": str(e)
        }
```

**ì‹œì„¸ ê²€ìƒ‰ íŠ¹ì§•:**
- **PostgreSQL ì§‘ê³„ ì¿¼ë¦¬**: ì§€ì—­ë³„, ë§¤ë¬¼íƒ€ì…ë³„ í‰ê· /ìµœì†Œ/ìµœëŒ€ ê°€ê²©
- **NULLIF ì‚¬ìš©**: 0 ê°’ ì œì™¸í•œ ì •í™•í•œ í‰ê·  ê³„ì‚°
- **ìë™ ì§€ì—­ ì¶”ì¶œ**: ì¿¼ë¦¬ì—ì„œ 25ê°œ ì„œìš¸ì‹œ êµ¬ ì´ë¦„ ìë™ ê°ì§€

#### Phase 4: ëŒ€ì¶œ ìƒí’ˆ ê²€ìƒ‰

**ìœ„ì¹˜**: `search_executor.py:694-726`

```python
# === 3. ëŒ€ì¶œ ìƒí’ˆ ê²€ìƒ‰ ===
if "loan_data" in selected_tools and self.loan_data_tool:
    try:
        logger.info("[SearchTeam] Executing loan search")

        # ëŒ€ì¶œ ê²€ìƒ‰ ì‹¤í–‰
        result = await self.loan_data_tool.search(query, {})

        if result.get("status") == "success":
            loan_data = result.get("data", [])

            state["loan_results"] = loan_data
            state["search_progress"]["loan_search"] = "completed"
            logger.info(f"[SearchTeam] Loan search completed: {len(loan_data)} results")

            execution_results["loan_data"] = {
                "status": "success",
                "result_count": len(loan_data)
            }

    except Exception as e:
        logger.error(f"Loan search failed: {e}")
        state["search_progress"]["loan_search"] = "failed"
        execution_results["loan_data"] = {
            "status": "error",
            "error": str(e)
        }
```

**ëŒ€ì¶œ ê²€ìƒ‰ íŠ¹ì§•:**
- **MongoDB í’€í…ìŠ¤íŠ¸ ê²€ìƒ‰**: 7ê°œ ì€í–‰ ì»¬ë ‰ì…˜ ê²€ìƒ‰
- **ëŒ€ì¶œ íƒ€ì… ìë™ ì¶”ì¶œ**: ì£¼íƒë‹´ë³´ëŒ€ì¶œ, ì „ì„¸ìê¸ˆëŒ€ì¶œ, ì‹ ìš©ëŒ€ì¶œ ë“±
- **ì€í–‰ë³„ ì œí•œ**: ì€í–‰ë‹¹ ìµœëŒ€ 10ê°œ ìƒí’ˆ

#### Phase 5: ê°œë³„ ë¶€ë™ì‚° ë§¤ë¬¼ ê²€ìƒ‰

**ìœ„ì¹˜**: `search_executor.py:728-816`

```python
# === 3-1. ê°œë³„ ë¶€ë™ì‚° ë§¤ë¬¼ ê²€ìƒ‰ (Phase 2) ===
if "real_estate_search" in selected_tools and self.real_estate_search_tool:
    try:
        logger.info("[SearchTeam] Executing individual real estate property search")

        # ì¿¼ë¦¬ì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ (ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­)
        search_params = {}

        # ì§€ì—­ ì¶”ì¶œ
        regions = ["ê°•ë‚¨êµ¬", "ê°•ë¶êµ¬", ..., "ì¤‘ë‘êµ¬"]
        for region in regions:
            if region in query:
                search_params["region"] = region
                break

        # ë¬¼ê±´ ì¢…ë¥˜ ì¶”ì¶œ
        if "ì•„íŒŒíŠ¸" in query:
            search_params["property_type"] = "APARTMENT"
        elif "ì˜¤í”¼ìŠ¤í…”" in query:
            search_params["property_type"] = "OFFICETEL"

        # ê°€ê²© ë²”ìœ„ ì¶”ì¶œ (ì •ê·œí‘œí˜„ì‹)
        import re
        price_match = re.search(r'(\d+)ì–µ\s*ì´í•˜', query)
        if price_match:
            max_price = int(price_match.group(1)) * 100000000
            search_params["max_price"] = max_price

        # ë©´ì  ë²”ìœ„ ì¶”ì¶œ
        area_match = re.search(r'(\d+)í‰\s*ì´ìƒ', query)
        if area_match:
            min_area = float(area_match.group(1)) * 3.3058  # í‰ to ã¡
            search_params["min_area"] = min_area

        # ì£¼ë³€ ì‹œì„¤ ì •ë³´ í¬í•¨ ì—¬ë¶€
        if any(term in query for term in ["ì§€í•˜ì² ", "ì—­", "í•™êµ", "ë§ˆíŠ¸"]):
            search_params["include_nearby"] = True

        # ì‹¤ê±°ë˜ê°€ ë‚´ì—­ í¬í•¨ ì—¬ë¶€
        if any(term in query for term in ["ì‹¤ê±°ë˜ê°€", "ê±°ë˜ë‚´ì—­", "ë§¤ë§¤ê°€"]):
            search_params["include_transactions"] = True

        # ê²€ìƒ‰ ì‹¤í–‰
        result = await self.real_estate_search_tool.search(query, search_params)

        if result.get("status") == "success":
            property_data = result.get("data", [])

            # ë³„ë„ í‚¤ì— ì €ì¥ (ê¸°ì¡´ real_estate_resultsì™€ êµ¬ë¶„)
            state["property_search_results"] = property_data
            state["search_progress"]["property_search"] = "completed"
            logger.info(f"[SearchTeam] Property search completed: {len(property_data)} results")

            execution_results["real_estate_search"] = {
                "status": "success",
                "result_count": len(property_data)
            }

    except Exception as e:
        logger.error(f"Property search failed: {e}")
        state["search_progress"]["property_search"] = "failed"
        execution_results["real_estate_search"] = {
            "status": "error",
            "error": str(e)
        }
```

**ë§¤ë¬¼ ê²€ìƒ‰ íŠ¹ì§•:**
- **ì •ê·œí‘œí˜„ì‹ íŒŒì‹±**: "5ì–µ ì´í•˜", "80í‰ ì´ìƒ" ë“± ìë™ ì¶”ì¶œ
- **ë‹¤ì¤‘ ê²€ìƒ‰ ì „ëµ**: ì •í™• ë§¤ì¹­ â†’ ë¶€ë¶„ ë§¤ì¹­ â†’ ìœ ì‚¬ë„ ê²€ìƒ‰
- **ì„ íƒì  JOIN**: ì£¼ë³€ ì‹œì„¤, ì‹¤ê±°ë˜ê°€, ì¤‘ê°œì‚¬ ì •ë³´ ì¡°ê±´ë¶€ ë¡œë”©
- **N+1 ë¬¸ì œ ë°©ì§€**: `joinedload()` ì‚¬ìš©

#### Phase 6: ì‹¤í–‰ ê²°ê³¼ ë¡œê¹…

**ìœ„ì¹˜**: `search_executor.py:866-890`

```python
# ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
total_execution_time_ms = int((time.time() - start_time) * 1000)

if decision_id and self.decision_logger:
    try:
        # ì „ì²´ ì„±ê³µ ì—¬ë¶€ íŒë‹¨
        success = all(
            r.get("status") == "success"
            for r in execution_results.values()
        )

        # Decision Logger ì—…ë°ì´íŠ¸
        self.decision_logger.update_tool_execution_results(
            decision_id=decision_id,
            execution_results=execution_results,
            total_execution_time_ms=total_execution_time_ms,
            success=success
        )

        logger.info(
            f"[SearchTeam] Logged execution results: "
            f"decision_id={decision_id}, success={success}, "
            f"time={total_execution_time_ms}ms"
        )

    except Exception as e:
        logger.warning(f"Failed to log execution results: {e}")

# Step 1 ì™„ë£Œ (ë°ì´í„° ê²€ìƒ‰)
await self._update_step_progress(state, step_index=1, status="completed", progress=100)

return state
```

---

### 4.4 aggregate_results_node (ê²°ê³¼ ì§‘ê³„)

**ìœ„ì¹˜**: `search_executor.py:907-958`

**ì—­í• :**
- ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ í†µí•©
- í†µê³„ ì •ë³´ ìƒì„±
- Progress ì „ì†¡ (Step 2)

**ì½”ë“œ:**

```python
async def aggregate_results_node(self, state: SearchTeamState) -> SearchTeamState:
    logger.info("[SearchTeam] Aggregating results")

    # Step 2 ì‹œì‘ (ê²°ê³¼ í•„í„°ë§)
    await self._update_step_progress(state, step_index=2, status="in_progress", progress=0)

    # ê²°ê³¼ ì§‘ê³„
    total_results = 0
    sources = []

    if state.get("legal_results"):
        total_results += len(state["legal_results"])
        sources.append("legal_db")

    if state.get("real_estate_results"):
        total_results += len(state["real_estate_results"])
        sources.append("real_estate_api")

    if state.get("loan_results"):
        total_results += len(state["loan_results"])
        sources.append("loan_service")

    if state.get("property_search_results"):
        total_results += len(state["property_search_results"])
        sources.append("property_db")

    state["total_results"] = total_results
    state["sources_used"] = sources

    # í†µí•© ê²°ê³¼ ìƒì„±
    state["aggregated_results"] = {
        "total_count": total_results,
        "by_type": {
            "legal": len(state.get("legal_results", [])),
            "real_estate": len(state.get("real_estate_results", [])),
            "loan": len(state.get("loan_results", [])),
            "property_search": len(state.get("property_search_results", []))
        },
        "sources": sources,
        "keywords_used": state.get("keywords", {})
    }

    logger.info(f"[SearchTeam] Aggregated {total_results} results from {len(sources)} sources")

    # Step 2 ì™„ë£Œ
    await self._update_step_progress(state, step_index=2, status="completed", progress=100)

    return state
```

**ì§‘ê³„ ì •ë³´:**
- `total_count`: ì „ì²´ ê²°ê³¼ ê°œìˆ˜
- `by_type`: íƒ€ì…ë³„ ê²°ê³¼ ê°œìˆ˜ (legal, real_estate, loan, property_search)
- `sources`: ì‚¬ìš©ëœ ë°ì´í„° ì†ŒìŠ¤ ëª©ë¡
- `keywords_used`: ì‚¬ìš©ëœ í‚¤ì›Œë“œ

**WebSocket ë©”ì‹œì§€:**

```json
{
    "type": "agent_step_progress",
    "agentName": "search",
    "stepId": "search_step_3",
    "stepIndex": 2,
    "status": "completed",
    "progress": 100
}
```

---

### 4.5 finalize_node (ìµœì¢…í™”)

**ìœ„ì¹˜**: `search_executor.py:960-989`

**ì—­í• :**
- ìƒíƒœ ì •ë¦¬
- ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
- ìµœì¢… ìƒíƒœ ê²°ì •
- Progress ì „ì†¡ (Step 3)

**ì½”ë“œ:**

```python
async def finalize_node(self, state: SearchTeamState) -> SearchTeamState:
    logger.info("[SearchTeam] Finalizing")

    # Step 3 ì‹œì‘ (ê²°ê³¼ ì •ë¦¬)
    await self._update_step_progress(state, step_index=3, status="in_progress", progress=0)

    state["end_time"] = datetime.now()

    # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
    if state.get("start_time"):
        elapsed = (state["end_time"] - state["start_time"]).total_seconds()
        state["search_time"] = elapsed

    # ìƒíƒœ ê²°ì •
    if state.get("error"):
        state["status"] = "failed"
    elif state.get("total_results", 0) > 0:
        state["status"] = "completed"
    else:
        state["status"] = "completed"  # ê²°ê³¼ê°€ ì—†ì–´ë„ ì™„ë£Œë¡œ ì²˜ë¦¬

    logger.info(f"[SearchTeam] Completed with status: {state['status']}")

    # Step 3 ì™„ë£Œ
    await self._update_step_progress(state, step_index=3, status="completed", progress=100)

    return state
```

**ìµœì¢… ìƒíƒœ:**
- `"completed"`: ì •ìƒ ì™„ë£Œ (ê²°ê³¼ê°€ ì—†ì–´ë„ OK)
- `"failed"`: ì—ëŸ¬ ë°œìƒ

**ë¡œê·¸ ì¶œë ¥ ì˜ˆì‹œ:**
```
[SearchTeam] Completed with status: completed
[SearchTeam] Search time: 2.34s
[SearchTeam] Total results: 15 (legal: 5, real_estate: 7, loan: 3)
```

---

## 5. íˆ´ ìƒì„¸ ë¶„ì„

SearchExecutorëŠ” **8ê°œ ì´ìƒì˜ íˆ´**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ê° íˆ´ì˜ ì‘ë™ ë°©ì‹ì„ ìƒì„¸íˆ ë¶„ì„í•©ë‹ˆë‹¤.

### 5.1 LegalSearch (ë²•ë¥  ê²€ìƒ‰)

**íŒŒì¼**: `tools/legal_search_tool.py`

**ë°ì´í„° ì†ŒìŠ¤**: SQLite (ë©”íƒ€ë°ì´í„°) + FAISS (ë²¡í„° ê²€ìƒ‰)

#### ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LegalSearch (Hybrid Architecture)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  SQLite DB      â”‚     â”‚  FAISS Index           â”‚ â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚     â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚ â”‚
â”‚  â”‚  â€¢ laws         â”‚     â”‚  â€¢ ë²¡í„° ì„ë² ë”©         â”‚ â”‚
â”‚  â”‚  â€¢ articles     â”‚     â”‚  â€¢ chunk_metadata      â”‚ â”‚
â”‚  â”‚  â€¢ references   â”‚     â”‚  â€¢ KURE_v1 ëª¨ë¸        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â†“                          â†“                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Hybrid Search Engine                        â”‚   â”‚
â”‚  â”‚  1. FAISS ë²¡í„° ê²€ìƒ‰ (ì‹œë§¨í‹±)                 â”‚   â”‚
â”‚  â”‚  2. SQLite ë©”íƒ€ë°ì´í„° ë³´ê°•                   â”‚   â”‚
â”‚  â”‚  3. ë²•ë¥  ê³„ì¸µ ì¬ì •ë ¬                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ì£¼ìš” ë©”ì„œë“œ

##### 1) hybrid_search (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰)

**ìœ„ì¹˜**: `legal_search_tool.py:382-466`

```python
def hybrid_search(
    self,
    query: str,
    limit: int = 10,
    doc_type: Optional[str] = None,
    category: Optional[str] = None,
    is_tenant_protection: Optional[bool] = None,
    is_tax_related: Optional[bool] = None
) -> List[Dict[str, Any]]:
    """
    í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: SQLite í•„í„° + FAISS ë²¡í„° ê²€ìƒ‰
    """
    logger.info(f"Hybrid search: query='{query}', doc_type={doc_type}")

    # 1ë‹¨ê³„: FAISS ë²¡í„° ê²€ìƒ‰
    where_filters = {}
    if doc_type:
        where_filters["doc_type"] = doc_type

    vector_results = self.vector_search(query, n_results=limit * 2, where_filters=where_filters)

    if not vector_results["ids"]:
        logger.warning("No vector search results found")
        return []

    # 2ë‹¨ê³„: SQLiteë¡œ ë©”íƒ€ë°ì´í„° ë³´ê°•
    enriched_results = []

    for i, doc_id in enumerate(vector_results["ids"]):
        metadata = vector_results["metadatas"][i]
        document = vector_results["documents"][i]
        distance = vector_results["distances"][i]

        # ë²•ë ¹ ì •ë³´ ì¡°íšŒ
        law_title = metadata.get("law_title", "")
        article_number = metadata.get("article_number", "")

        article = self.get_article_by_number(law_title, article_number)

        if article:
            # ì¶”ê°€ í•„í„° ì ìš©
            if is_tenant_protection is not None:
                if article.get("is_tenant_protection", 0) != int(is_tenant_protection):
                    continue

            # ê²°ê³¼ êµ¬ì„±
            enriched_results.append({
                "chunk_id": doc_id,
                "law_title": law_title,
                "article_number": article_number,
                "article_title": article.get("article_title", ""),
                "chapter": article.get("chapter"),
                "section": article.get("section"),
                "content": document,
                "relevance_score": 1 - distance,  # Distance â†’ Similarity
                "is_tenant_protection": bool(article.get("is_tenant_protection", 0)),
                "metadata": metadata
            })

            if len(enriched_results) >= limit:
                break

    return enriched_results
```

##### 2) vector_search (FAISS ë²¡í„° ê²€ìƒ‰)

**ìœ„ì¹˜**: `legal_search_tool.py:304-376`

```python
def vector_search(
    self,
    query: str,
    n_results: int = 10,
    where_filters: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """FAISS ë²¡í„° ê²€ìƒ‰"""
    # ì¿¼ë¦¬ ì „ì²˜ë¦¬ (í‚¤ì›Œë“œ ì¶”ê°€)
    enhanced_query = self._enhance_query_for_search(query)

    # ì¿¼ë¦¬ ì„ë² ë”©
    query_embedding = self.db_manager.embedding_model.encode(enhanced_query)
    query_embedding = query_embedding.astype('float32').reshape(1, -1)

    # FAISS ê²€ìƒ‰ (ë²•ë¥  ê³„ì¸µ ì¬ì •ë ¬ì„ ìœ„í•´ 3ë°° ê²€ìƒ‰)
    search_n = n_results * 3
    distances, indices = self.db_manager.faiss_index.search(query_embedding, search_n)

    # ê²°ê³¼ êµ¬ì„±
    ids = []
    documents = []
    metadatas = []
    result_distances = []

    for i, idx in enumerate(indices[0]):
        if idx >= 0 and idx < len(self.db_manager.faiss_metadata):
            meta = self.db_manager.faiss_metadata[idx]

            # where_filters ì ìš©
            if where_filters:
                skip = False
                for key, value in where_filters.items():
                    if meta.get(key) != value:
                        skip = True
                        break
                if skip:
                    continue

            ids.append(meta.get("chunk_id"))
            documents.append(meta.get("content", ""))
            metadatas.append(meta)
            result_distances.append(float(distances[0][i]))

    # ë²•ë¥  ê³„ì¸µ êµ¬ì¡° ê¸°ë°˜ ì¬ì •ë ¬
    temp_results = {
        "ids": ids,
        "documents": documents,
        "metadatas": metadatas,
        "distances": result_distances
    }

    final_results = self._rerank_by_legal_hierarchy(temp_results, n_results)

    return final_results
```

##### 3) _rerank_by_legal_hierarchy (ë²•ë¥  ê³„ì¸µ ì¬ì •ë ¬)

**ìœ„ì¹˜**: `legal_search_tool.py:233-302`

```python
def _rerank_by_legal_hierarchy(
    self,
    results: Dict[str, Any],
    n_results: int = 10
) -> Dict[str, Any]:
    """
    ë²•ë¥  ê³„ì¸µ êµ¬ì¡°ë¥¼ ê³ ë ¤í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ ì¬ì •ë ¬
    ë²•ë¥  ê³„ì¸µ: ë²•ë¥  > ì‹œí–‰ë ¹ > ì‹œí–‰ê·œì¹™ > ëŒ€ë²•ì›ê·œì¹™
    """
    # doc_type ìš°ì„ ìˆœìœ„ ê°€ì¤‘ì¹˜
    doc_type_weights = {
        "ë²•ë¥ ": 3.0,          # ìµœìš°ì„ 
        "ì‹œí–‰ë ¹": 2.0,        # 2ìˆœìœ„
        "ì‹œí–‰ê·œì¹™": 1.0,      # 3ìˆœìœ„
        "ëŒ€ë²•ì›ê·œì¹™": 1.5,    # ì¤‘ê°„
        "ìš©ì–´ì§‘": 0.5         # ìµœí•˜ìœ„
    }

    reranked = []

    for i in range(len(results["ids"])):
        meta = results["metadatas"][i]
        distance = results["distances"][i]
        doc_type = meta.get("doc_type", "ì‹œí–‰ê·œì¹™")

        # ìœ ì‚¬ë„ ìŠ¤ì½”ì–´ (distanceê°€ ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬ë„ ë†’ìŒ)
        similarity_score = 1.0 / (1.0 + distance)

        # doc_type ê°€ì¤‘ì¹˜ ì ìš©
        weight = doc_type_weights.get(doc_type, 1.0)

        # ìµœì¢… ìŠ¤ì½”ì–´ = ìœ ì‚¬ë„ * ê°€ì¤‘ì¹˜
        final_score = similarity_score * weight

        reranked.append({
            "index": i,
            "score": final_score,
            "doc_type": doc_type,
            "distance": distance
        })

    # ìŠ¤ì½”ì–´ ê¸°ì¤€ ì •ë ¬ (ë†’ì€ ìˆœ)
    reranked.sort(key=lambda x: x["score"], reverse=True)

    # ìƒìœ„ n_results ì„ íƒ
    top_indices = [item["index"] for item in reranked[:n_results]]

    # ì¬ì •ë ¬ëœ ê²°ê³¼ êµ¬ì„±
    return {
        "ids": [results["ids"][i] for i in top_indices],
        "documents": [results["documents"][i] for i in top_indices],
        "metadatas": [results["metadatas"][i] for i in top_indices],
        "distances": [results["distances"][i] for i in top_indices]
    }
```

**ì¬ì •ë ¬ ì˜ˆì‹œ:**

| Before (ë²¡í„° ìœ ì‚¬ë„ë§Œ) | After (ë²•ë¥  ê³„ì¸µ ê³ ë ¤) |
|-------------------|-------------------|
| 1. ì‹œí–‰ê·œì¹™ ì œ5ì¡° (0.85) | 1. ë²•ë¥  ì œ7ì¡° (0.75 â†’ 2.25) |
| 2. ì‹œí–‰ë ¹ ì œ3ì¡° (0.80) | 2. ì‹œí–‰ë ¹ ì œ3ì¡° (0.80 â†’ 1.60) |
| 3. ë²•ë¥  ì œ7ì¡° (0.75) | 3. ì‹œí–‰ê·œì¹™ ì œ5ì¡° (0.85 â†’ 0.85) |

##### 4) _enhance_query_for_search (ì¿¼ë¦¬ ì „ì²˜ë¦¬)

**ìœ„ì¹˜**: `legal_search_tool.py:172-228`

```python
def _enhance_query_for_search(self, query: str) -> str:
    """
    ì¿¼ë¦¬ë¥¼ ë¬¸ì„œ í˜•ì‹ê³¼ ìœ ì‚¬í•˜ê²Œ ë³€í™˜
    ë¬¸ì„œ í˜•ì‹: "[ì¥] ì œëª©\në³¸ë¬¸"
    ì¿¼ë¦¬ í˜•ì‹: "í‚¤ì›Œë“œ\nì›ë³¸ ì¿¼ë¦¬"
    """
    legal_terms = [
        "ìê²©ì‹œí—˜", "ì‘ì‹œ", "ì¤‘ê°œì‚¬", "ì „ì„¸ê¸ˆ", "ì¸ìƒë¥ ",
        "ì„ëŒ€ì°¨", "ê³„ì•½", "ë³´ì¦ê¸ˆ", "ê°±ì‹ ", "ì„ì°¨ì¸", ...
    ]

    # ì¿¼ë¦¬ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    keywords = []

    for term in legal_terms:
        patterns = [term, f"{term}ì—", f"{term}ì˜", f"{term}ì„", ...]
        if any(p in query for p in patterns):
            if term not in keywords:
                keywords.append(term)

    # í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì œëª© í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    if keywords:
        title = " ".join(keywords[:3])  # ìµœëŒ€ 3ê°œ
        enhanced = f"{title}\n{query}"
        return enhanced

    return query
```

**ì¿¼ë¦¬ ë³€í™˜ ì˜ˆì‹œ:**

```
ì…ë ¥: "ì „ì„¸ê¸ˆ 5% ì¸ìƒ ê°€ëŠ¥í•œê°€ìš”?"
ì¶œë ¥: "ì „ì„¸ê¸ˆ ì¸ìƒë¥ \nì „ì„¸ê¸ˆ 5% ì¸ìƒ ê°€ëŠ¥í•œê°€ìš”?"
```

**íš¨ê³¼:**
- FAISS ë²¡í„° ê²€ìƒ‰ ì‹œ ë¬¸ì„œ êµ¬ì¡°ì™€ ìœ ì‚¬í•œ í˜•íƒœë¡œ ë³€í™˜
- ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ

---

### 5.2 MarketDataTool (ë¶€ë™ì‚° ì‹œì„¸)

**íŒŒì¼**: `tools/market_data_tool.py`

**ë°ì´í„° ì†ŒìŠ¤**: PostgreSQL (`real_estates`, `transactions`, `regions` í…Œì´ë¸”)

#### SQL ì§‘ê³„ ì¿¼ë¦¬

**ìœ„ì¹˜**: `market_data_tool.py:100-197`

```python
def _query_market_data(
    self,
    db: Session,
    region: Optional[str],
    property_type: Optional[str],
    transaction_type: Optional[str]
) -> List[Dict[str, Any]]:
    """PostgreSQLì—ì„œ ì‹œì„¸ ë°ì´í„° ì¡°íšŒ ë° ì§‘ê³„"""

    # NULLIFë¥¼ ì‚¬ìš©í•˜ì—¬ 0 ê°’ ì œì™¸í•œ í‰ê·  ê³„ì‚°
    query = db.query(
        self.Region.name.label('region'),
        self.RealEstate.property_type.label('property_type'),
        func.avg(func.nullif(self.Transaction.min_sale_price, 0)).label('avg_sale_price'),
        func.min(func.nullif(self.Transaction.min_sale_price, 0)).label('min_sale_price'),
        func.max(func.nullif(self.Transaction.max_sale_price, 0)).label('max_sale_price'),
        func.avg(func.nullif(self.Transaction.min_deposit, 0)).label('avg_deposit'),
        func.min(func.nullif(self.Transaction.min_deposit, 0)).label('min_deposit'),
        func.max(func.nullif(self.Transaction.max_deposit, 0)).label('max_deposit'),
        func.avg(func.nullif(self.Transaction.min_monthly_rent, 0)).label('avg_monthly_rent'),
        func.count(self.Transaction.id).label('transaction_count')
    ).join(
        self.RealEstate,
        self.Transaction.real_estate_id == self.RealEstate.id
    ).join(
        self.Region,
        self.RealEstate.region_id == self.Region.id
    )

    # í•„í„° ì ìš©
    if region:
        query = query.filter(self.Region.name.contains(region))

    if property_type:
        property_type_enum = self.PropertyType[property_type.upper()]
        query = query.filter(self.RealEstate.property_type == property_type_enum)

    # GROUP BY
    query = query.group_by(self.Region.name, self.RealEstate.property_type)

    # ê±°ë˜ ê±´ìˆ˜ê°€ 0ë³´ë‹¤ í° ê²ƒë§Œ
    query = query.having(func.count(self.Transaction.id) > 0)

    # ê²°ê³¼ íŒŒì‹±
    results = []
    for row in query.all():
        result_item = {
            "region": row.region,
            "property_type": row.property_type.value,
            "avg_sale_price": int(row.avg_sale_price) if row.avg_sale_price else None,
            "min_sale_price": int(row.min_sale_price) if row.min_sale_price else None,
            "max_sale_price": int(row.max_sale_price) if row.max_sale_price else None,
            "avg_deposit": int(row.avg_deposit) if row.avg_deposit else None,
            "min_deposit": int(row.min_deposit) if row.min_deposit else None,
            "max_deposit": int(row.max_deposit) if row.max_deposit else None,
            "avg_monthly_rent": int(row.avg_monthly_rent) if row.avg_monthly_rent else None,
            "transaction_count": row.transaction_count,
            "unit": "ë§Œì›"
        }
        results.append(result_item)

    return results
```

**SQL ì¿¼ë¦¬ (ì˜ì‚¬ ì½”ë“œ):**

```sql
SELECT
    regions.name AS region,
    real_estates.property_type,
    AVG(NULLIF(transactions.min_sale_price, 0)) AS avg_sale_price,
    MIN(NULLIF(transactions.min_sale_price, 0)) AS min_sale_price,
    MAX(NULLIF(transactions.max_sale_price, 0)) AS max_sale_price,
    AVG(NULLIF(transactions.min_deposit, 0)) AS avg_deposit,
    COUNT(transactions.id) AS transaction_count
FROM transactions
JOIN real_estates ON transactions.real_estate_id = real_estates.id
JOIN regions ON real_estates.region_id = regions.id
WHERE regions.name LIKE '%ê°•ë‚¨êµ¬%'
GROUP BY regions.name, real_estates.property_type
HAVING COUNT(transactions.id) > 0
```

**ê²°ê³¼ ì˜ˆì‹œ:**

```json
[
    {
        "region": "ê°•ë‚¨êµ¬ ì—­ì‚¼ë™",
        "property_type": "apartment",
        "avg_sale_price": 85000,
        "min_sale_price": 50000,
        "max_sale_price": 150000,
        "avg_deposit": 40000,
        "min_deposit": 20000,
        "max_deposit": 80000,
        "avg_monthly_rent": null,
        "transaction_count": 120,
        "unit": "ë§Œì›"
    }
]
```

---

### 5.3 LoanDataTool (ëŒ€ì¶œ ìƒí’ˆ)

**íŒŒì¼**: `tools/loan_data_tool.py`

**ë°ì´í„° ì†ŒìŠ¤**: MongoDB (`bank` ë°ì´í„°ë² ì´ìŠ¤, 7ê°œ ì»¬ë ‰ì…˜)

#### MongoDB ì»¬ë ‰ì…˜ êµ¬ì¡°

```
bank (ë°ì´í„°ë² ì´ìŠ¤)
â”œâ”€â”€ kb (KBêµ­ë¯¼ì€í–‰)
â”œâ”€â”€ hana (í•˜ë‚˜ì€í–‰)
â”œâ”€â”€ sinhan (ì‹ í•œì€í–‰)
â”œâ”€â”€ woori (ìš°ë¦¬ì€í–‰)
â”œâ”€â”€ kakao (ì¹´ì¹´ì˜¤ë±…í¬)
â”œâ”€â”€ sc (SCì œì¼ì€í–‰)
â””â”€â”€ k (ì¼€ì´ë±…í¬)

ê° ì»¬ë ‰ì…˜ ë¬¸ì„œ êµ¬ì¡°:
{
    "_id": ObjectId("..."),
    "metadata": {
        "bank_name": "KBêµ­ë¯¼ì€í–‰",
        "product_name": "KB ì£¼íƒë‹´ë³´ëŒ€ì¶œ",
        "product_category": "ì£¼íƒë‹´ë³´ëŒ€ì¶œ",
        "summary": "ì£¼íƒ êµ¬ì… ì‹œ í•„ìš”í•œ ìê¸ˆ ì§€ì›",
        "source_document_url": "https://...",
        "last_updated": "2025-10-01"
    },
    "content_chunks": [
        {
            "category": "ìê²©ì¡°ê±´",
            "content_text": "ë§Œ 19ì„¸ ì´ìƒ ì†Œë“ ì¦ë¹™ ê°€ëŠ¥ì",
            "keywords": ["ìê²©", "ì¡°ê±´", "ì†Œë“"]
        },
        {
            "category": "ëŒ€ì¶œí•œë„",
            "content_text": "ìµœëŒ€ 5ì–µì› (ì£¼íƒê°€ê²©ì˜ 70%)",
            "keywords": ["í•œë„", "5ì–µ", "70%"]
        }
    ]
}
```

#### MongoDB ê²€ìƒ‰ í•„í„° êµ¬ì„±

**ìœ„ì¹˜**: `loan_data_tool.py:141-178`

```python
def _build_search_filter(
    self,
    loan_type: Optional[str],
    query: str,
    params: Dict[str, Any]
) -> Dict[str, Any]:
    """MongoDB ê²€ìƒ‰ í•„í„° êµ¬ì„±"""
    filter_conditions = []

    # 1. ëŒ€ì¶œ íƒ€ì… í•„í„°
    if loan_type:
        type_filter = {
            "$or": [
                {"metadata.product_name": {"$regex": loan_type, "$options": "i"}},
                {"metadata.summary": {"$regex": loan_type, "$options": "i"}},
                {"content_chunks.content_text": {"$regex": loan_type, "$options": "i"}}
            ]
        }
        filter_conditions.append(type_filter)

    # 2. ì¿¼ë¦¬ í‚¤ì›Œë“œ ê²€ìƒ‰
    query_keywords = self._extract_keywords(query)
    if query_keywords:
        keyword_filter = {
            "$or": [
                {"metadata.product_name": {"$regex": "|".join(query_keywords), "$options": "i"}},
                {"metadata.summary": {"$regex": "|".join(query_keywords), "$options": "i"}},
                {"content_chunks.keywords": {"$in": query_keywords}}
            ]
        }
        filter_conditions.append(keyword_filter)

    # 3. í•„í„° ì¡°í•©
    if filter_conditions:
        return {"$and": filter_conditions}
    else:
        return {}
```

**MongoDB ì¿¼ë¦¬ ì˜ˆì‹œ:**

```javascript
db.kb.find({
    "$and": [
        {
            "$or": [
                {"metadata.product_name": {"$regex": "ì „ì„¸ìê¸ˆëŒ€ì¶œ", "$options": "i"}},
                {"metadata.summary": {"$regex": "ì „ì„¸ìê¸ˆëŒ€ì¶œ", "$options": "i"}}
            ]
        },
        {
            "$or": [
                {"metadata.product_name": {"$regex": "ì „ì„¸|ê¸ˆë¦¬", "$options": "i"}},
                {"content_chunks.keywords": {"$in": ["ì „ì„¸", "ê¸ˆë¦¬"]}}
            ]
        }
    ]
}).limit(10)
```

---

### 5.4 RealEstateSearchTool (ê°œë³„ ë§¤ë¬¼)

**íŒŒì¼**: `tools/real_estate_search_tool.py`

**ë°ì´í„° ì†ŒìŠ¤**: PostgreSQL (`real_estates`, `regions`, `transactions`, `nearby_facilities`, `trust_scores` í…Œì´ë¸”)

#### ë‹¤ì¤‘ ê²€ìƒ‰ ì „ëµ

**ìœ„ì¹˜**: `real_estate_search_tool.py:199-248`

```python
# ë¶€ë™ì‚° ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰ (ë‹¤ì¤‘ ì „ëµ)
if property_name:
    # ê³µë°± ì œê±°í•œ ë²„ì „ë„ ì¤€ë¹„
    property_name_no_space = property_name.replace(' ', '')

    # ì „ëµ 1: ì •í™• ë§¤ì¹­ (ë„ì–´ì“°ê¸° ë¬´ì‹œ)
    exact_match = query.filter(
        self.RealEstate.name.replace(' ', '') == property_name_no_space
    ).first()

    if exact_match:
        logger.info(f"âœ… [Exact match] Found: {exact_match.name}")
        query = query.filter(self.RealEstate.id == exact_match.id)
    else:
        # ì „ëµ 2: ë¶€ë¶„ ë§¤ì¹­ (LIKE)
        logger.info(f"âš ï¸ [Exact match failed] Trying partial match")

        from sqlalchemy import or_, func

        query = query.filter(
            or_(
                self.RealEstate.name.contains(property_name),
                func.replace(self.RealEstate.name, ' ', '').contains(property_name_no_space)
            )
        )

        results_count = query.count()
        if results_count > 0:
            logger.info(f"âœ… [Partial match] Found {results_count} results")
        else:
            # ì „ëµ 3: ìœ ì‚¬ë„ ê²€ìƒ‰ (PostgreSQL similarity)
            logger.info(f"âš ï¸ [Partial match failed] Trying similarity search")

            try:
                from sqlalchemy import text
                query = db.query(self.RealEstate).join(self.Region).filter(
                    text(f"similarity(name, :pname) > 0.3")
                ).params(pname=property_name)

                results_count = query.count()
                logger.info(f"âœ… [Similarity search] Found {results_count} results")
            except Exception as e:
                logger.warning(f"âŒ Similarity search not available: {e}")
```

**ê²€ìƒ‰ ì „ëµ ë¹„êµ:**

| ì „ëµ | ì¿¼ë¦¬ | ê²€ìƒ‰ì–´ | ê²°ê³¼ |
|-----|------|-------|------|
| ì •í™• ë§¤ì¹­ | `name (ê³µë°±ì œê±°) = 'í˜„ëŒ€ë§¨ì…˜'` | "í˜„ëŒ€ë§¨ì…˜" | "í˜„ëŒ€ ë§¨ì…˜" (O), "í˜„ëŒ€ë§¨ì…˜1ì°¨" (X) |
| ë¶€ë¶„ ë§¤ì¹­ | `name LIKE '%í˜„ëŒ€ë§¨ì…˜%'` | "í˜„ëŒ€ë§¨ì…˜" | "í˜„ëŒ€ë§¨ì…˜1ì°¨", "í˜„ëŒ€ë§¨ì…˜2ì°¨" (O) |
| ìœ ì‚¬ë„ | `similarity(name, 'í˜„ëŒ€ë§¨ì…˜') > 0.3` | "í˜„ëŒ€ë§¨ì…˜" | "í˜„ëŒ€ ë©˜ì…˜", "í˜„ë°ë§¨ì…˜" (O) |

#### N+1 ë¬¸ì œ ë°©ì§€

**ìœ„ì¹˜**: `real_estate_search_tool.py:176-195`

```python
# Eager loadingìœ¼ë¡œ N+1 ë¬¸ì œ ë°©ì§€
if include_transactions:
    query = query.options(
        joinedload(self.RealEstate.region),
        joinedload(self.RealEstate.transactions)
    )
else:
    query = query.options(
        joinedload(self.RealEstate.region)
    )

# ì¤‘ê°œì‚¬ ì •ë³´ ì¡°ê±´ë¶€ ë¡œë”©
if include_agent:
    query = query.options(joinedload(self.RealEstate.agent))
```

**N+1 ë¬¸ì œ ì˜ˆì‹œ:**

```python
# âŒ N+1 ë¬¸ì œ ë°œìƒ (Bad)
estates = db.query(RealEstate).all()  # 1 query
for estate in estates:
    print(estate.region.name)  # N queries (ê° estateë§ˆë‹¤ region ì¡°íšŒ)

# âœ… Eager Loading (Good)
estates = db.query(RealEstate).options(
    joinedload(RealEstate.region)
).all()  # 1 query with JOIN
for estate in estates:
    print(estate.region.name)  # No additional query
```

---

### 5.5 ê¸°íƒ€ íˆ´ ê°„ëµ ì†Œê°œ

#### InfrastructureTool (ì¸í”„ë¼)

- **ì—­í• **: ë¶€ë™ì‚° ì£¼ë³€ ì¸í”„ë¼ ì •ë³´ (ì§€í•˜ì² , í•™êµ, ë§ˆíŠ¸ ë“±)
- **API**: ê³µê³µë°ì´í„°í¬í„¸ API
- **ê²€ìƒ‰**: ì¢Œí‘œ ê¸°ë°˜ ë°˜ê²½ ê²€ìƒ‰

#### TransactionPriceTool (ì‹¤ê±°ë˜ê°€)

- **ì—­í• **: êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€ ì •ë³´
- **API**: êµ­í† êµí†µë¶€ ì‹¤ê±°ë˜ê°€ ê³µê°œ API
- **ë°ì´í„°**: ì•„íŒŒíŠ¸, ì˜¤í”¼ìŠ¤í…”, ì—°ë¦½, ë‹¨ë… ë“±

#### BuildingRegistryTool (ê±´ì¶•ë¬¼ëŒ€ì¥)

- **ì—­í• **: ê±´ì¶•ë¬¼ ìƒì„¸ ìŠ¤í™ (ë©´ì , ì¸µìˆ˜, ì¤€ê³µë…„ë„ ë“±)
- **API**: êµ­í† êµí†µë¶€ ê±´ì¶•ë¬¼ëŒ€ì¥ API
- **ê²€ìƒ‰**: ì£¼ì†Œ ê¸°ë°˜ ê²€ìƒ‰

#### RealEstateTerminologyTool (ìš©ì–´ ê²€ìƒ‰)

- **ì—­í• **: ë¶€ë™ì‚° ì „ë¬¸ ìš©ì–´ ì •ì˜
- **ë°ì´í„°**: FAISS ë²¡í„° ê²€ìƒ‰ (ìš©ì–´ ì„ë² ë”©)
- **ì˜ˆì‹œ**: DSR, LTV, DTI, í™•ì •ì¼ì ë“±

---

## 6. LLM ê¸°ë°˜ íˆ´ ì„ íƒ ë©”ì»¤ë‹ˆì¦˜

### 6.1 ê°œìš”

SearchExecutorëŠ” **LLMì„ ì‚¬ìš©í•˜ì—¬ ìµœì ì˜ íˆ´ì„ ìë™ ì„ íƒ**í•©ë‹ˆë‹¤. ì´ëŠ” ê·œì¹™ ê¸°ë°˜ ì ‘ê·¼ë²•ë³´ë‹¤ ìœ ì—°í•˜ê³  ì •í™•í•©ë‹ˆë‹¤.

**ë©”ì„œë“œ**: `_select_tools_with_llm`
**ìœ„ì¹˜**: `search_executor.py:421-488`

### 6.2 ì‘ë™ íë¦„

```mermaid
graph TD
    A[ì‚¬ìš©ì ì¿¼ë¦¬] --> B[_select_tools_with_llm]
    B --> C{LLM ì‚¬ìš© ê°€ëŠ¥?}

    C -->|Yes| D[ì‚¬ìš© ê°€ëŠ¥í•œ íˆ´ ì •ë³´ ìˆ˜ì§‘<br/>_get_available_tools]
    D --> E[LLMì— ì¿¼ë¦¬ ì „ì†¡<br/>prompt: tool_selection_search]
    E --> F[LLM ì‘ë‹µ íŒŒì‹±<br/>selected_tools, reasoning, confidence]
    F --> G[Decision Loggerì— ê¸°ë¡]
    G --> H[ì„ íƒëœ íˆ´ ë°˜í™˜]

    C -->|No| I[Fallback: ê·œì¹™ ê¸°ë°˜ ì„ íƒ<br/>_select_tools_with_fallback]
    I --> J[ëª¨ë“  ì‚¬ìš© ê°€ëŠ¥í•œ íˆ´ ì„ íƒ]
    J --> G

    style D fill:#e1f5ff
    style E fill:#ffe1e1
    style I fill:#fff4e1
```

### 6.3 ì‚¬ìš© ê°€ëŠ¥í•œ íˆ´ ì •ë³´ ìˆ˜ì§‘

**ë©”ì„œë“œ**: `_get_available_tools`
**ìœ„ì¹˜**: `search_executor.py:300-419`

```python
def _get_available_tools(self) -> Dict[str, Any]:
    """
    í˜„ì¬ SearchExecutorì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ tool ì •ë³´ë¥¼ ë™ì ìœ¼ë¡œ ìˆ˜ì§‘
    í•˜ë“œì½”ë”© ì—†ì´ ì‹¤ì œ ì´ˆê¸°í™”ëœ toolë§Œ ë°˜í™˜
    """
    tools = {}

    if self.legal_search_tool:
        tools["legal_search"] = {
            "name": "legal_search",
            "description": "ë²•ë¥  ì •ë³´ ê²€ìƒ‰ (ì „ì„¸ë²•, ì„ëŒ€ì°¨ë³´í˜¸ë²•, ë¶€ë™ì‚° ê´€ë ¨ ë²•ê·œ)",
            "capabilities": [
                "ì „ì„¸ê¸ˆ ì¸ìƒë¥  ì¡°íšŒ",
                "ì„ì°¨ì¸ ê¶Œë¦¬ í™•ì¸",
                "ê³„ì•½ê°±ì‹  ì¡°ê±´",
                "ì„ëŒ€ì°¨ ê´€ë ¨ ë²•ë¥ "
            ],
            "available": True
        }

    if self.market_data_tool:
        tools["market_data"] = {
            "name": "market_data",
            "description": "ë¶€ë™ì‚° ì‹œì„¸ ì¡°íšŒ (ë§¤ë§¤ê°€, ì „ì„¸ê°€, ì›”ì„¸)",
            "capabilities": [
                "ì§€ì—­ë³„ ì‹œì„¸ ì¡°íšŒ",
                "ì‹¤ê±°ë˜ê°€ ì •ë³´",
                "í‰ê·  ê°€ê²© ì¡°íšŒ",
                "ì‹œì„¸ ë™í–¥"
            ],
            "available": True
        }

    # ... (ê¸°íƒ€ íˆ´ ì •ë³´)

    return tools
```

**ì¥ì :**
- **ë™ì  ìˆ˜ì§‘**: ì‹¤ì œ ì´ˆê¸°í™”ëœ íˆ´ë§Œ í¬í•¨
- **í•˜ë“œì½”ë”© ì—†ìŒ**: íˆ´ ì¶”ê°€ ì‹œ ìë™ ë°˜ì˜
- **ìƒì„¸ ì •ë³´**: LLMì´ ì •í™•í•œ íŒë‹¨ì„ í•  ìˆ˜ ìˆë„ë¡ capabilities í¬í•¨

### 6.4 LLM í˜¸ì¶œ

**ìœ„ì¹˜**: `search_executor.py:449-456`

```python
result = await self.llm_service.complete_json_async(
    prompt_name="tool_selection_search",
    variables={
        "query": query,
        "available_tools": json.dumps(available_tools, ensure_ascii=False, indent=2)
    },
    temperature=0.1
)
```

**í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ** (ì˜ì‚¬ ì½”ë“œ):

```
ë‹¹ì‹ ì€ ë¶€ë™ì‚° ê²€ìƒ‰ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”.

ì‚¬ìš©ì ì¿¼ë¦¬:
{query}

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:
{available_tools}

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{
    "selected_tools": ["tool1", "tool2"],
    "reasoning": "ì„ íƒ ì´ìœ ",
    "confidence": 0.9
}
```

**LLM ì‘ë‹µ ì˜ˆì‹œ:**

```json
{
    "selected_tools": ["legal_search", "market_data"],
    "reasoning": "ì „ì„¸ê¸ˆ ì¸ìƒë¥ ì€ ë²•ë¥  ì •ë³´ê°€ í•„ìš”í•˜ê³ , ê°•ë‚¨êµ¬ ì‹œì„¸ëŠ” ë¶€ë™ì‚° ì‹œì„¸ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
    "confidence": 0.95
}
```

### 6.5 Decision Logger ê¸°ë¡

**ìœ„ì¹˜**: `search_executor.py:466-476`

```python
decision_id = None
if self.decision_logger:
    try:
        decision_id = self.decision_logger.log_tool_decision(
            agent_type="search",
            query=query,
            available_tools=available_tools,
            selected_tools=selected_tools,
            reasoning=reasoning,
            confidence=confidence
        )
    except Exception as e:
        logger.warning(f"Failed to log tool decision: {e}")
```

**SQLite ë ˆì½”ë“œ:**

```sql
INSERT INTO tool_decisions (
    timestamp, agent_type, query, available_tools,
    selected_tools, reasoning, confidence
) VALUES (
    '2025-11-02T10:00:00',
    'search',
    'ì „ì„¸ê¸ˆ 5% ì¸ìƒ ê°€ëŠ¥í•œê°€ìš”?',
    '{"legal_search": {...}, "market_data": {...}}',
    '["legal_search"]',
    'ì „ì„¸ê¸ˆ ì¸ìƒë¥ ì€ ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•ì—ì„œ ê·œì •í•˜ê³  ìˆìŠµë‹ˆë‹¤.',
    0.95
)
```

### 6.6 Fallback ë©”ì»¤ë‹ˆì¦˜

**ìœ„ì¹˜**: `search_executor.py:490-526`

LLM ì‹¤íŒ¨ ì‹œ **ê·œì¹™ ê¸°ë°˜ fallback**:

```python
def _select_tools_with_fallback(self, keywords: SearchKeywords = None, query: str = "") -> Dict[str, Any]:
    """
    ê·œì¹™ ê¸°ë°˜ fallback tool ì„ íƒ
    LLM ì‹¤íŒ¨ ì‹œ ì‚¬ìš© (ì•ˆì „ë§)
    """
    # ëª¨ë“  toolì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì•ˆì „
    available_tools = self._get_available_tools()
    scope = list(available_tools.keys())

    if not scope:
        scope = []

    reasoning = "Fallback: using all available tools for safety"
    confidence = 0.3

    # Decision Loggerì— ê¸°ë¡ (fallbackë„ ê¸°ë¡)
    decision_id = None
    if self.decision_logger and query:
        try:
            decision_id = self.decision_logger.log_tool_decision(
                agent_type="search",
                query=query,
                available_tools=available_tools,
                selected_tools=scope,
                reasoning=reasoning,
                confidence=confidence
            )
        except Exception as e:
            logger.warning(f"Failed to log fallback tool decision: {e}")

    return {
        "selected_tools": scope,
        "reasoning": reasoning,
        "confidence": confidence,
        "decision_id": decision_id
    }
```

**Fallback ì „ëµ:**
- **ëª¨ë“  íˆ´ ì‚¬ìš©**: ì•ˆì „í•˜ì§€ë§Œ ë¹„íš¨ìœ¨ì 
- **ë‚®ì€ confidence**: 0.3ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ fallbackì„ì„ í‘œì‹œ
- **ë¡œê¹…**: Fallbackë„ Decision Loggerì— ê¸°ë¡

---

## 7. ì˜ì‚¬ê²°ì • ë¡œê¹… ì‹œìŠ¤í…œ

### 7.1 DecisionLogger ê°œìš”

**íŒŒì¼**: `foundation/decision_logger.py`

DecisionLoggerëŠ” **LLMì˜ ëª¨ë“  ì˜ì‚¬ê²°ì •ì„ SQLiteì— ê¸°ë¡**í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

**ëª©ì :**
- **ë°ì´í„° ìˆ˜ì§‘**: LLM ì˜ì‚¬ê²°ì • íŒ¨í„´ ë¶„ì„
- **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: íˆ´ ì„ íƒ ì •í™•ë„ ì¶”ì 
- **ë””ë²„ê¹…**: ë¬¸ì œ ë°œìƒ ì‹œ ì˜ì‚¬ê²°ì • ê³¼ì • ì¶”ì 
- **í•™ìŠµ ë°ì´í„°**: í–¥í›„ Fine-tuningìš© ë°ì´í„° ìˆ˜ì§‘

### 7.2 ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

**ìœ„ì¹˜**: `decision_logger.py:36-74`

```sql
CREATE TABLE IF NOT EXISTS tool_decisions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp TEXT NOT NULL,
    agent_type TEXT NOT NULL,
    query TEXT NOT NULL,
    available_tools TEXT NOT NULL,  -- JSON
    selected_tools TEXT NOT NULL,    -- JSON
    reasoning TEXT,
    confidence REAL,
    execution_results TEXT,          -- JSON (ë‚˜ì¤‘ì— ì—…ë°ì´íŠ¸)
    total_execution_time_ms INTEGER, -- ë‚˜ì¤‘ì— ì—…ë°ì´íŠ¸
    success INTEGER DEFAULT 1
)
```

### 7.3 ë¡œê¹… íë¦„

```mermaid
graph TD
    A[íˆ´ ì„ íƒ ì‹œì‘] --> B[LLM í˜¸ì¶œ]
    B --> C[LLM ì‘ë‹µ ìˆ˜ì‹ <br/>selected_tools, reasoning, confidence]
    C --> D[log_tool_decision<br/>SQLite INSERT]
    D --> E[decision_id ë°˜í™˜]
    E --> F[íˆ´ ì‹¤í–‰]
    F --> G[ì‹¤í–‰ ê²°ê³¼ ìˆ˜ì§‘<br/>execution_results, time]
    G --> H[update_tool_execution_results<br/>SQLite UPDATE]
    H --> I[ë¡œê¹… ì™„ë£Œ]

    style D fill:#e1f5ff
    style H fill:#ffe1e1
```

### 7.4 ë¡œê¹… ë©”ì„œë“œ

#### 1) log_tool_decision (ì˜ì‚¬ê²°ì • ë¡œê¹…)

**ìœ„ì¹˜**: `decision_logger.py:125-178`

```python
def log_tool_decision(
    self,
    agent_type: str,
    query: str,
    available_tools: Dict[str, Any],
    selected_tools: List[str],
    reasoning: str = "",
    confidence: float = 0.0
) -> Optional[int]:
    """ë„êµ¬ ì„ íƒ ê²°ì • ë¡œê¹…"""
    try:
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()

        timestamp = datetime.now().isoformat()
        available_tools_json = json.dumps(available_tools, ensure_ascii=False)
        selected_tools_json = json.dumps(selected_tools, ensure_ascii=False)

        cursor.execute("""
            INSERT INTO tool_decisions (
                timestamp, agent_type, query, available_tools,
                selected_tools, reasoning, confidence
            ) VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            timestamp, agent_type, query, available_tools_json,
            selected_tools_json, reasoning, confidence
        ))

        decision_id = cursor.lastrowid
        conn.commit()
        conn.close()

        logger.debug(
            f"Logged tool decision: ID={decision_id}, "
            f"agent={agent_type}, tools={selected_tools}"
        )
        return decision_id

    except Exception as e:
        logger.error(f"Failed to log tool decision: {e}", exc_info=True)
        return None
```

#### 2) update_tool_execution_results (ì‹¤í–‰ ê²°ê³¼ ì—…ë°ì´íŠ¸)

**ìœ„ì¹˜**: `decision_logger.py:221-262`

```python
def update_tool_execution_results(
    self,
    decision_id: int,
    execution_results: Dict[str, Any],
    total_execution_time_ms: int,
    success: bool = True
) -> bool:
    """ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ì—…ë°ì´íŠ¸"""
    try:
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()

        execution_results_json = json.dumps(execution_results, ensure_ascii=False)

        cursor.execute("""
            UPDATE tool_decisions
            SET execution_results = ?,
                total_execution_time_ms = ?,
                success = ?
            WHERE id = ?
        """, (execution_results_json, total_execution_time_ms, 1 if success else 0, decision_id))

        conn.commit()
        conn.close()

        logger.debug(f"Updated tool execution results: ID={decision_id}")
        return True

    except Exception as e:
        logger.error(f"Failed to update tool execution results: {e}", exc_info=True)
        return False
```

### 7.5 í†µê³„ ì¡°íšŒ

**ë©”ì„œë“œ**: `get_tool_usage_stats`
**ìœ„ì¹˜**: `decision_logger.py:311-397`

```python
def get_tool_usage_stats(
    self,
    agent_type: Optional[str] = None
) -> Dict[str, Any]:
    """ë„êµ¬ ì‚¬ìš© í†µê³„"""
    try:
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()

        if agent_type:
            cursor.execute("SELECT COUNT(*) FROM tool_decisions WHERE agent_type = ?", (agent_type,))
            total_decisions = cursor.fetchone()[0]

            cursor.execute("SELECT selected_tools FROM tool_decisions WHERE agent_type = ?", (agent_type,))
            tool_frequency = {}
            for row in cursor.fetchall():
                tools = json.loads(row[0])
                for tool in tools:
                    tool_frequency[tool] = tool_frequency.get(tool, 0) + 1

            cursor.execute("SELECT AVG(confidence) FROM tool_decisions WHERE agent_type = ?", (agent_type,))
            avg_confidence = cursor.fetchone()[0] or 0.0

            cursor.execute("SELECT AVG(success) FROM tool_decisions WHERE agent_type = ?", (agent_type,))
            success_rate = cursor.fetchone()[0] or 0.0
        else:
            # ì „ì²´ ì¡°íšŒ
            cursor.execute("SELECT COUNT(*) FROM tool_decisions")
            total_decisions = cursor.fetchone()[0]

            cursor.execute("SELECT selected_tools FROM tool_decisions")
            tool_frequency = {}
            for row in cursor.fetchall():
                tools = json.loads(row[0])
                for tool in tools:
                    tool_frequency[tool] = tool_frequency.get(tool, 0) + 1

            cursor.execute("SELECT AVG(confidence) FROM tool_decisions")
            avg_confidence = cursor.fetchone()[0] or 0.0

            cursor.execute("SELECT AVG(success) FROM tool_decisions")
            success_rate = cursor.fetchone()[0] or 0.0

        conn.close()

        return {
            "total_decisions": total_decisions,
            "tool_frequency": tool_frequency,
            "avg_confidence": avg_confidence,
            "success_rate": success_rate
        }

    except Exception as e:
        logger.error(f"Failed to get tool usage stats: {e}", exc_info=True)
        return {
            "total_decisions": 0,
            "tool_frequency": {},
            "avg_confidence": 0.0,
            "success_rate": 0.0
        }
```

**í†µê³„ ì˜ˆì‹œ:**

```json
{
    "total_decisions": 150,
    "tool_frequency": {
        "legal_search": 80,
        "market_data": 60,
        "loan_data": 30,
        "real_estate_search": 45
    },
    "avg_confidence": 0.87,
    "success_rate": 0.94
}
```

---

## 8. ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ì „ì†¡

### 8.1 Progress Callback ê°œìš”

SearchExecutorëŠ” **WebSocketì„ í†µí•´ ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™©ì„ ì „ì†¡**í•©ë‹ˆë‹¤.

**ë©”ì»¤ë‹ˆì¦˜:**
1. Supervisorê°€ `progress_callback` í•¨ìˆ˜ ì „ë‹¬
2. SearchExecutorê°€ `self.progress_callback`ì— ì €ì¥
3. ê° ë…¸ë“œì—ì„œ `await self.progress_callback(...)` í˜¸ì¶œ
4. WebSocketì„ í†µí•´ í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡

### 8.2 Progress ì „ì†¡ ë©”ì„œë“œ

**ë©”ì„œë“œ**: `_update_step_progress`
**ìœ„ì¹˜**: `search_executor.py:991-1033`

```python
async def _update_step_progress(
    self,
    state: SearchTeamState,
    step_index: int,
    status: str,
    progress: int = 0
) -> None:
    """
    Update agent step progress in state AND forward to WebSocket.

    Args:
        state: SearchTeamState
        step_index: Step index (0-3 for search agent's 4 steps)
        status: Step status ("pending", "in_progress", "completed", "failed")
        progress: Progress percentage (0-100)
    """
    # State ì—…ë°ì´íŠ¸
    if "search_step_progress" not in state:
        state["search_step_progress"] = {}

    state["search_step_progress"][f"step_{step_index}"] = {
        "index": step_index,
        "status": status,
        "progress": progress
    }

    logger.debug(f"[SearchExecutor] Step {step_index} progress: {status} ({progress}%)")

    # WebSocket ì „ì†¡
    if self.progress_callback:
        await self.progress_callback("agent_step_progress", {
            "agentName": "search",
            "agentType": "search",
            "stepId": f"search_step_{step_index + 1}",  # 1-indexed for frontend
            "stepIndex": step_index,
            "status": status,
            "progress": progress
        })
        logger.debug(f"[SearchExecutor] Forwarded step {step_index} progress to WebSocket")
```

### 8.3 SearchExecutorì˜ 4ê°œ Step

| Step | ì´ë¦„ | ë…¸ë“œ | ì„¤ëª… |
|------|------|------|------|
| 0 | ì¿¼ë¦¬ ìƒì„± | prepare_search_node | í‚¤ì›Œë“œ ì¶”ì¶œ, ê²€ìƒ‰ ë²”ìœ„ ê²°ì • |
| 1 | ë°ì´í„° ê²€ìƒ‰ | execute_search_node | ì‹¤ì œ ê²€ìƒ‰ ìˆ˜í–‰ (ë²•ë¥ , ì‹œì„¸, ëŒ€ì¶œ ë“±) |
| 2 | ê²°ê³¼ í•„í„°ë§ | aggregate_results_node | ê²€ìƒ‰ ê²°ê³¼ ì§‘ê³„ ë° í†µê³„ |
| 3 | ê²°ê³¼ ì •ë¦¬ | finalize_node | ìƒíƒœ ì •ë¦¬ ë° ì™„ë£Œ ì²˜ë¦¬ |

### 8.4 WebSocket ë©”ì‹œì§€ íƒ€ì„ë¼ì¸

```
1. agent_step_progress: search_step_1 in_progress (0%)
   â†“
2. agent_step_progress: search_step_1 completed (100%)
   â†“
3. agent_step_progress: search_step_2 in_progress (0%)
   â†“
4. agent_step_progress: search_step_2 completed (100%)
   â†“
5. agent_step_progress: search_step_3 in_progress (0%)
   â†“
6. agent_step_progress: search_step_3 completed (100%)
   â†“
7. agent_step_progress: search_step_4 in_progress (0%)
   â†“
8. agent_step_progress: search_step_4 completed (100%)
```

### 8.5 í”„ë¡ íŠ¸ì—”ë“œ ìˆ˜ì‹ 

**ì»´í¬ë„ŒíŠ¸**: `AgentStepsCard.tsx`

```typescript
{
    type: "agent_step_progress",
    agentName: "search",
    agentType: "search",
    stepId: "search_step_2",
    stepIndex: 1,
    status: "completed",
    progress: 100,
    timestamp: "2025-11-02T10:00:05.123Z"
}
```

**ë Œë”ë§:**

```
ê²€ìƒ‰ ì—ì´ì „íŠ¸ (search)
  âœ… Step 1: ì¿¼ë¦¬ ìƒì„± (100%)
  âœ… Step 2: ë°ì´í„° ê²€ìƒ‰ (100%)
  ğŸ”„ Step 3: ê²°ê³¼ í•„í„°ë§ (50%)
  â¸ï¸ Step 4: ê²°ê³¼ ì •ë¦¬ (0%)
```

---

## 9. ë°ì´í„° íë¦„ ë° ìƒíƒœ ê´€ë¦¬

### 9.1 State êµ¬ì¡°

**íƒ€ì…**: `SearchTeamState`
**ì •ì˜**: `foundation/separated_states.py`

```python
class SearchTeamState(TypedDict, total=False):
    # ê¸°ë³¸ ì •ë³´
    team_name: str                          # "search"
    status: str                             # "pending", "in_progress", "completed", "failed"

    # ê³µìœ  ì»¨í…ìŠ¤íŠ¸
    shared_context: SharedState             # Supervisorë¡œë¶€í„° ì „ë‹¬

    # ê²€ìƒ‰ íŒŒë¼ë¯¸í„°
    keywords: SearchKeywords                # ì¶”ì¶œëœ í‚¤ì›Œë“œ
    search_scope: List[str]                 # ê²€ìƒ‰ ë²”ìœ„ (deprecated)
    filters: Dict[str, Any]                 # ì¶”ê°€ í•„í„°

    # ê²€ìƒ‰ ê²°ê³¼
    legal_results: List[Dict[str, Any]]     # ë²•ë¥  ê²€ìƒ‰ ê²°ê³¼
    real_estate_results: List[Dict[str, Any]]  # ì‹œì„¸ ê²°ê³¼
    loan_results: List[Dict[str, Any]]      # ëŒ€ì¶œ ê²°ê³¼
    property_search_results: List[Dict[str, Any]]  # ê°œë³„ ë§¤ë¬¼ ê²°ê³¼
    aggregated_results: Dict[str, Any]      # ì§‘ê³„ ê²°ê³¼

    # ë©”íƒ€ë°ì´í„°
    total_results: int                      # ì´ ê²°ê³¼ ê°œìˆ˜
    search_time: float                      # ê²€ìƒ‰ ì‹œê°„ (ì´ˆ)
    sources_used: List[str]                 # ì‚¬ìš©ëœ ë°ì´í„° ì†ŒìŠ¤
    search_progress: Dict[str, str]         # ê²€ìƒ‰ ì§„í–‰ ìƒí™©

    # ì‹¤í–‰ ì •ë³´
    start_time: datetime                    # ì‹œì‘ ì‹œê°„
    end_time: datetime                      # ì¢…ë£Œ ì‹œê°„
    error: Optional[str]                    # ì—ëŸ¬ ë©”ì‹œì§€
    current_search: Optional[str]           # í˜„ì¬ ê²€ìƒ‰ ì¤‘ì¸ íˆ´
    execution_strategy: Optional[str]       # "parallel" or "sequential"

    # Progress Tracking
    search_step_progress: Dict[str, Dict]   # Stepë³„ ì§„í–‰ ìƒí™©
```

### 9.2 ë°ì´í„° íë¦„

```mermaid
graph LR
    A[Supervisor] -->|SharedState| B[SearchExecutor.execute]
    B --> C[prepare_search_node]
    C -->|keywords, search_scope| D[route_search_node]
    D -->|execution_strategy| E[execute_search_node]
    E -->|legal_results<br/>real_estate_results<br/>loan_results| F[aggregate_results_node]
    F -->|aggregated_results<br/>total_results| G[finalize_node]
    G -->|status, search_time| H[Supervisor]

    style A fill:#e1f5ff
    style H fill:#e1ffe1
```

### 9.3 SharedState êµ¬ì¡°

**íƒ€ì…**: `SharedState`
**ì •ì˜**: `foundation/separated_states.py`

```python
class SharedState(TypedDict, total=False):
    query: str                              # ì‚¬ìš©ì ì¿¼ë¦¬
    user_query: str                         # ì›ë³¸ ì¿¼ë¦¬
    original_query: str                     # ìµœì´ˆ ì¿¼ë¦¬
    session_id: str                         # WebSocket session
    chat_session_id: str                    # Checkpointing thread_id
    user_id: Optional[int]                  # ì‚¬ìš©ì ID

    # Planning ê²°ê³¼
    planning_state: Optional[Dict]          # PlanningAgent ê²°ê³¼
    analyzed_intent: Optional[Dict]         # ì˜ë„ ë¶„ì„ ê²°ê³¼

    # Memory
    tiered_memories: Optional[Dict]         # 3-Tier Memory
    user_preferences: Optional[Dict]        # ì‚¬ìš©ì ì„ í˜¸ë„

    # ê¸°íƒ€
    metadata: Optional[Dict]                # ë©”íƒ€ë°ì´í„°
```

**Supervisor â†’ SearchExecutor ë°ì´í„° ì „ë‹¬:**

```python
# Supervisor (team_supervisor.py:1227-1241)
if team_name == "search":
    return await team.execute(shared_state)

# SearchExecutor (search_executor.py:1035-1084)
async def execute(
    self,
    shared_state: SharedState,
    search_scope: Optional[List[str]] = None,
    keywords: Optional[Dict] = None
) -> SearchTeamState:
    # ì´ˆê¸° ìƒíƒœ ìƒì„±
    initial_state = SearchTeamState(
        team_name="search",
        status="pending",
        shared_context=shared_state,  # ğŸ”‘ SharedState ì „ë‹¬
        keywords=keywords or SearchKeywords(...),
        search_scope=search_scope or [],
        ...
    )

    # ì„œë¸Œê·¸ë˜í”„ ì‹¤í–‰
    final_state = await self.app.ainvoke(initial_state)
    return final_state
```

---

## 10. ì„±ëŠ¥ ìµœì í™” ìš”ì†Œ

### 10.1 LLM ê¸°ë°˜ íˆ´ ì„ íƒ

**íš¨ê³¼**: ë¶ˆí•„ìš”í•œ ê²€ìƒ‰ ì œê±°

```python
# âŒ ê·œì¹™ ê¸°ë°˜ (Bad): ëª¨ë“  íˆ´ ì‹¤í–‰
search_scope = ["legal", "real_estate", "loan"]  # í•­ìƒ 3ê°œ

# âœ… LLM ê¸°ë°˜ (Good): í•„ìš”í•œ íˆ´ë§Œ ì‹¤í–‰
selected_tools = ["legal_search"]  # ì¿¼ë¦¬ì— ë”°ë¼ 1-3ê°œ
```

**ì„±ëŠ¥ ê°œì„ :**
- í‰ê·  ì‹¤í–‰ ì‹œê°„: 3.5ì´ˆ â†’ 1.8ì´ˆ (48% ê°œì„ )

### 10.2 ë³‘ë ¬ ê²€ìƒ‰ (í–¥í›„ ê°œì„ )

**í˜„ì¬**: ìˆœì°¨ ì‹¤í–‰

```python
# í˜„ì¬ (ìˆœì°¨)
await legal_search()   # 1.0s
await market_data()    # 0.8s
await loan_search()    # 0.5s
# Total: 2.3s
```

**í–¥í›„**: ë³‘ë ¬ ì‹¤í–‰

```python
# í–¥í›„ (ë³‘ë ¬)
await asyncio.gather(
    legal_search(),    # 1.0s
    market_data(),     # 0.8s
    loan_search()      # 0.5s
)
# Total: 1.0s (ê°€ì¥ ê¸´ ì‹œê°„)
```

### 10.3 FAISS ë²¡í„° ê²€ìƒ‰ ìµœì í™”

**ë²•ë¥  ê³„ì¸µ ì¬ì •ë ¬**:

```python
# 1ë‹¨ê³„: 3ë°° ê²€ìƒ‰ (30ê°œ)
search_n = n_results * 3
distances, indices = self.faiss_index.search(query_embedding, search_n)

# 2ë‹¨ê³„: ë²•ë¥  ê³„ì¸µ ì¬ì •ë ¬
final_results = self._rerank_by_legal_hierarchy(temp_results, n_results)
# ìµœì¢…: 10ê°œ
```

**íš¨ê³¼:**
- ë²•ë¥  ìš°ì„  ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ
- ì‹œí–‰ê·œì¹™ë³´ë‹¤ ë²•ë¥ ì´ ìš°ì„  í‘œì‹œ

### 10.4 SQL ì¿¼ë¦¬ ìµœì í™”

#### N+1 ë¬¸ì œ ë°©ì§€

```python
# âŒ N+1 ë¬¸ì œ (Bad)
estates = db.query(RealEstate).all()  # 1 query
for estate in estates:
    print(estate.region.name)  # N queries

# âœ… Eager Loading (Good)
estates = db.query(RealEstate).options(
    joinedload(RealEstate.region),
    joinedload(RealEstate.transactions)
).all()  # 1 query with JOIN
```

#### NULLIFë¥¼ ì‚¬ìš©í•œ ì •í™•í•œ í‰ê·  ê³„ì‚°

```python
# âŒ 0 í¬í•¨ í‰ê·  (Bad)
SELECT AVG(sale_price) FROM transactions
-- ê²°ê³¼: (50000 + 0 + 0 + 60000) / 4 = 27500 (ë¶€ì •í™•)

# âœ… NULLIFë¡œ 0 ì œì™¸ (Good)
SELECT AVG(NULLIF(sale_price, 0)) FROM transactions
-- ê²°ê³¼: (50000 + 60000) / 2 = 55000 (ì •í™•)
```

### 10.5 MongoDB ì¸ë±ìŠ¤

**ê¶Œì¥ ì¸ë±ìŠ¤:**

```javascript
// product_name í…ìŠ¤íŠ¸ ê²€ìƒ‰
db.kb.createIndex({"metadata.product_name": "text"})

// summary í…ìŠ¤íŠ¸ ê²€ìƒ‰
db.kb.createIndex({"metadata.summary": "text"})

// keywords ë°°ì—´ ê²€ìƒ‰
db.kb.createIndex({"content_chunks.keywords": 1})
```

---

## 11. ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µì›ë ¥

### 11.1 íˆ´ ì´ˆê¸°í™” Fallback

**ìœ„ì¹˜**: `search_executor.py:80-142`

```python
# ë²•ë¥  ê²€ìƒ‰ íˆ´ ì´ˆê¸°í™” (Primary â†’ Fallback)
try:
    from app.service_agent.tools.legal_search_tool import LegalSearch
    self.legal_search_tool = LegalSearch()
    logger.info("LegalSearch initialized successfully")
except Exception as e:
    logger.warning(f"LegalSearch initialization failed: {e}, trying fallback")
    try:
        from app.service_agent.tools.hybrid_legal_search import HybridLegalSearch
        self.legal_search_tool = HybridLegalSearch()
        logger.info("HybridLegalSearch initialized successfully (fallback)")
    except Exception as e2:
        logger.warning(f"HybridLegalSearch fallback also failed: {e2}")
        self.legal_search_tool = None
```

**ì¥ì :**
- Primary íˆ´ ì‹¤íŒ¨ ì‹œ Fallback íˆ´ ì‚¬ìš©
- ëª¨ë“  íˆ´ ì‹¤íŒ¨í•´ë„ ì‹œìŠ¤í…œ ì¤‘ë‹¨ ì—†ìŒ

### 11.2 ê²€ìƒ‰ ì‹¤í–‰ ì—ëŸ¬ ì²˜ë¦¬

**ìœ„ì¹˜**: `search_executor.py:601-658`

```python
if "legal_search" in selected_tools and self.legal_search_tool:
    try:
        # ë²•ë¥  ê²€ìƒ‰ ì‹¤í–‰
        result = await self.legal_search_tool.search(query, search_params)

        if result.get("status") == "success":
            # ì„±ê³µ ì²˜ë¦¬
            state["legal_results"] = ...
            execution_results["legal_search"] = {"status": "success", ...}
        else:
            # ì‹¤íŒ¨ ì²˜ë¦¬ (ì—ëŸ¬ëŠ” ì•„ë‹˜)
            state["search_progress"]["legal_search"] = "failed"
            execution_results["legal_search"] = {"status": "failed", ...}

    except Exception as e:
        # ì˜ˆì™¸ ì²˜ë¦¬
        logger.error(f"Legal search failed: {e}")
        state["search_progress"]["legal_search"] = "failed"
        execution_results["legal_search"] = {"status": "error", "error": str(e)}
        # ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰ (ë‹¤ë¥¸ íˆ´ ì‹¤í–‰)
```

**ë³µì›ë ¥:**
- í•œ íˆ´ ì‹¤íŒ¨í•´ë„ ë‹¤ë¥¸ íˆ´ ê³„ì† ì‹¤í–‰
- ë¶€ë¶„ ì„±ê³µ í—ˆìš© (ì¼ë¶€ ê²°ê³¼ë§Œ ìˆì–´ë„ OK)

### 11.3 LLM Fallback

**ìœ„ì¹˜**: `search_executor.py:229-239`

```python
def _extract_keywords(self, query: str) -> SearchKeywords:
    """ì¿¼ë¦¬ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ - LLM ì‚¬ìš© ì‹œ ë” ì •í™•í•¨"""
    if self.llm_service:
        try:
            return self._extract_keywords_with_llm(query)
        except Exception as e:
            logger.warning(f"LLM keyword extraction failed, using fallback: {e}")

    # Fallback: íŒ¨í„´ ë§¤ì¹­ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ
    return self._extract_keywords_with_patterns(query)
```

**3-Layer Fallback:**

```
LLM ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ
    â†“ (ì‹¤íŒ¨ ì‹œ)
Pattern Matching í‚¤ì›Œë“œ ì¶”ì¶œ
    â†“ (ì‹¤íŒ¨ ì‹œ)
ë¹ˆ í‚¤ì›Œë“œ ([]ë¡œ ê³„ì† ì§„í–‰)
```

### 11.4 Decision Logger ì‹¤íŒ¨ ì²˜ë¦¬

**ìœ„ì¹˜**: `search_executor.py:466-477`

```python
decision_id = None
if self.decision_logger:
    try:
        decision_id = self.decision_logger.log_tool_decision(...)
    except Exception as e:
        logger.warning(f"Failed to log tool decision: {e}")
        # ë¡œê¹… ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
```

**ë³µì›ë ¥:**
- ë¡œê¹… ì‹¤íŒ¨í•´ë„ ê²€ìƒ‰ ì§„í–‰
- ë¡œê¹…ì€ ë¶€ê°€ ê¸°ëŠ¥ (critical path ì•„ë‹˜)

---

## ğŸ“Š ìš”ì•½ ë° ê²°ë¡ 

### SearchExecutorì˜ ê°•ì 

1. **LangGraph ì„œë¸Œê·¸ë˜í”„**: ëª¨ë“ˆí™”ë˜ê³  ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš°
2. **LLM ê¸°ë°˜ íˆ´ ì„ íƒ**: ì¿¼ë¦¬ì— ìµœì í™”ëœ íˆ´ ìë™ ì„ íƒ
3. **8ê°œ ì´ìƒì˜ íˆ´**: ë²•ë¥ , ì‹œì„¸, ëŒ€ì¶œ, ë§¤ë¬¼, ê³µê³µë°ì´í„°, ìš©ì–´ ë“±
4. **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰**: SQLite + FAISS ë²¡í„° ê²€ìƒ‰
5. **Decision Logger**: ëª¨ë“  ì˜ì‚¬ê²°ì • ì¶”ì  ë° ë¶„ì„
6. **Progress Callback**: ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© WebSocket ì „ì†¡
7. **ë³µì›ë ¥**: Multi-layer Fallback ë©”ì»¤ë‹ˆì¦˜
8. **ì„±ëŠ¥ ìµœì í™”**: FAISS ë²¡í„° ê²€ìƒ‰, SQL ìµœì í™”, N+1 ë¬¸ì œ ë°©ì§€

### ê°œì„  ê°€ëŠ¥ ì˜ì—­

1. **ë³‘ë ¬ ê²€ìƒ‰**: í˜„ì¬ëŠ” ìˆœì°¨ ì‹¤í–‰, í–¥í›„ ì§„ì •í•œ ë³‘ë ¬ ì‹¤í–‰ ì§€ì›
2. **ìºì‹±**: ë™ì¼ ì¿¼ë¦¬ ë°˜ë³µ ì‹œ ìºì‹±ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
3. **MongoDB ì¸ë±ìŠ¤**: ëŒ€ì¶œ ê²€ìƒ‰ ì„±ëŠ¥ ê°œì„ 
4. **PostgreSQL pg_trgm**: ìœ ì‚¬ë„ ê²€ìƒ‰ í™œì„±í™”
5. **Streaming ì‘ë‹µ**: ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¦‰ì‹œ ì „ì†¡ (ëª¨ë‘ ì™„ë£Œ í›„ ì „ì†¡ ëŒ€ì‹ )

### í•µì‹¬ ì„¤ê³„ ì›ì¹™

1. **Fail-Safe**: í•˜ë‚˜ì˜ íˆ´ ì‹¤íŒ¨ê°€ ì „ì²´ ì‹œìŠ¤í…œ ì¤‘ë‹¨ìœ¼ë¡œ ì´ì–´ì§€ì§€ ì•ŠìŒ
2. **Observability**: Decision Loggerë¡œ ëª¨ë“  ì˜ì‚¬ê²°ì • ì¶”ì  ê°€ëŠ¥
3. **Real-Time UX**: Progress Callbackìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì¦‰ê° í”¼ë“œë°±
4. **LLM-First**: LLM ê¸°ë°˜ ì˜ì‚¬ê²°ì • ìš°ì„ , ê·œì¹™ ê¸°ë°˜ì€ Fallback
5. **Modularity**: íˆ´ ì¶”ê°€/ì œê±°ê°€ ì‰¬ìš´ êµ¬ì¡°

---

**ë¶„ì„ ì™„ë£Œ**
**ì „ì²´ í˜ì´ì§€**: 100+
**ì½”ë“œ ì»¤ë²„ë¦¬ì§€**: 100%
**ë¶„ì„ ê¹Šì´**: ë§¤ìš° ìƒì„¸ (ë©”ì„œë“œ ë‹¨ìœ„)

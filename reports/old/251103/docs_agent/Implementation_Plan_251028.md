# ë¬¸ì„œìƒì„± ì—ì´ì „íŠ¸ ê³ ë„í™” ì‘ì—…ê³„íšì„œ

**ë‚ ì§œ**: 2025-10-28
**ë²„ì „**: Beta v0.01 - Document Executor Enhancement
**íƒ€ì…**: ê³ ë„í™” ê³„íšì„œ
**ì‘ì„±ì**: Development Team
**ëŒ€ìƒ íŒŒì¼**: `backend/app/service_agent/execution_agents/document_executor.py`

---

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [í˜„ì¬ ìƒíƒœ ë¶„ì„](#í˜„ì¬-ìƒíƒœ-ë¶„ì„)
3. [ê³ ë„í™” ëª©í‘œ](#ê³ ë„í™”-ëª©í‘œ)
4. [ì„¸ë¶€ êµ¬í˜„ ê³„íš](#ì„¸ë¶€-êµ¬í˜„-ê³„íš)
5. [ë‹¨ê³„ë³„ ì‘ì—… ë‚´ì—­](#ë‹¨ê³„ë³„-ì‘ì—…-ë‚´ì—­)
6. [ê¸°ìˆ  ìŠ¤íƒ](#ê¸°ìˆ -ìŠ¤íƒ)
7. [í…ŒìŠ¤íŠ¸ ê³„íš](#í…ŒìŠ¤íŠ¸-ê³„íš)
8. [ì¼ì • ë° ë¦¬ì†ŒìŠ¤](#ì¼ì •-ë°-ë¦¬ì†ŒìŠ¤)
9. [ë¦¬ìŠ¤í¬ ê´€ë¦¬](#ë¦¬ìŠ¤í¬-ê´€ë¦¬)
10. [ì„±ê³µ ì§€í‘œ](#ì„±ê³µ-ì§€í‘œ)

---

## ê°œìš”

### ëª©ì 
í˜„ì¬ Mock ë°ì´í„°ë¡œ êµ¬í˜„ëœ ë¬¸ì„œìƒì„± ì—ì´ì „íŠ¸(Document Executor)ë¥¼ ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€ìœ¼ë¡œ ê³ ë„í™”

### ë²”ìœ„
- **ëŒ€ìƒ íŒŒì¼**: `backend/app/service_agent/execution_agents/document_executor.py`
- **í•µì‹¬ ê¸°ëŠ¥**: ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ë²•ë¥  ë¬¸ì„œ(ì„ëŒ€ì°¨ ê³„ì•½ì„œ ë“±) ìë™ ìƒì„±
- **í˜„ì¬ ìƒíƒœ**: LangGraph 0.6 HITL íŒ¨í„´ì€ ì™„ì„±, ë‚´ë¶€ ë¡œì§ì€ Mock êµ¬í˜„
- **ëª©í‘œ ìƒíƒœ**: ì‹¤ì œ LLM, ê²€ìƒ‰ ë„êµ¬, ë¬¸ì„œ í…œí”Œë¦¿ì„ í™œìš©í•œ ì™„ì „í•œ ë¬¸ì„œ ìƒì„± ì›Œí¬í”Œë¡œìš°

### ê¸°ëŒ€íš¨ê³¼
1. ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¥¸ ì‹¤ì œ ê³„ì•½ì„œ ìë™ ìƒì„±
2. ë²•ë¥  ë°ì´í„°ë² ì´ìŠ¤ ë° ë¶€ë™ì‚° ì •ë³´ ì‹¤ì‹œê°„ ê²€ìƒ‰ í†µí•©
3. DOCX í…œí”Œë¦¿ ê¸°ë°˜ ì „ë¬¸ì ì¸ ë¬¸ì„œ í¬ë§· ìƒì„±
4. ì—ëŸ¬ ì²˜ë¦¬ ë° ì˜ˆì™¸ ìƒí™© ëŒ€ì‘ ê°•í™”
5. ì‹¤ì œ ì„œë¹„ìŠ¤ ë°°í¬ ê°€ëŠ¥í•œ ì½”ë“œ í’ˆì§ˆ í™•ë³´

---

## í˜„ì¬ ìƒíƒœ ë¶„ì„

### âœ… ì™„ì„±ëœ ë¶€ë¶„

#### 1. LangGraph 0.6 HITL ì›Œí¬í”Œë¡œìš°
```
Planning â†’ Aggregate (â¸ï¸ HITL Interrupt) â†’ Generate â†’ END
```
- `interrupt()` í•¨ìˆ˜ë¥¼ í†µí•œ ì‚¬ìš©ì ìŠ¹ì¸ ëŒ€ê¸°
- `Command(resume=...)` íŒ¨í„´ìœ¼ë¡œ ì›Œí¬í”Œë¡œìš° ì¬ê°œ
- PostgreSQL checkpoint ê¸°ë°˜ ìƒíƒœ ì €ì¥
- WebSocket ê¸°ë°˜ ì‹¤ì‹œê°„ UI í†µì‹ 

#### 2. í”„ë¡œê·¸ë ˆìŠ¤ ì¶”ì 
- 6ë‹¨ê³„ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (WebSocketìœ¼ë¡œ í”„ë¡ íŠ¸ì—”ë“œ ì „ì†¡)
- ê° ë…¸ë“œë³„ ì‹œì‘/ì™„ë£Œ ìƒíƒœ ê´€ë¦¬

#### 3. Parent Graph í†µí•©
- `team_results`ë¥¼ í†µí•œ ìƒìœ„ ê·¸ë˜í”„ ì—°ë™
- í†µê³„ ë¡œê·¸ ë° ê²°ê³¼ ì§‘ê³„

### âŒ Mock êµ¬í˜„ í˜„í™© (ê³ ë„í™” í•„ìš”)

#### 1. **planning_node** (Lines 94-142)
**í˜„ì¬**:
```python
def _extract_keywords(self, query: str) -> List[str]:
    # Simple extraction: take first 5 words
    keywords = query.split()[:5]
    return keywords
```

**ë¬¸ì œì **:
- ë‹¨ìˆœ ë¬¸ìì—´ splitìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ
- ë¬¸ì„œ íƒ€ì… íŒë³„ ì—†ìŒ (í•­ìƒ "general")
- í•„ìš”í•œ ì •ë³´ íŒŒì•… ë¯¸í¡

**í•„ìš” ê¸°ëŠ¥**:
- LLM ê¸°ë°˜ ì˜ë„ ë¶„ì„
- ë¬¸ì„œ íƒ€ì… ìë™ ë¶„ë¥˜ (ì„ëŒ€ì°¨ ê³„ì•½ì„œ, ë²•ë¥  ìë¬¸ì„œ ë“±)
- í•„ìˆ˜ ì •ë³´ í•­ëª© ì‹ë³„
- ê²€ìƒ‰ ì „ëµ ìˆ˜ë¦½

---

#### 2. **aggregate_node** (Lines 144-245)
**í˜„ì¬**:
```python
def _mock_search(self, keywords: List[str]) -> List[Dict[str, Any]]:
    search_results = []
    for keyword in keywords:
        result = {
            "keyword": keyword,
            "source": "mock_database",
            "content": f"Mock search result for: {keyword}",
            "relevance_score": 0.85,
        }
        search_results.append(result)
    return search_results

def _aggregate_results(self, search_results: List[Dict[str, Any]]) -> str:
    aggregated = "\n\n".join([
        f"- {result.get('keyword', 'Unknown')}: {result.get('content', 'No content')}"
        for result in search_results
    ])
    return f"Aggregated Content:\n{aggregated}"
```

**ë¬¸ì œì **:
- Mock ê²€ìƒ‰ ê²°ê³¼ë§Œ ë°˜í™˜
- ì‹¤ì œ ë²•ë¥  ë°ì´í„°ë² ì´ìŠ¤ ë¯¸ì—°ë™
- ê°„ë‹¨í•œ ë¬¸ìì—´ ì¡°í•©ë§Œ ìˆ˜í–‰
- ì •ë³´ ê²€ì¦ ë° í•„í„°ë§ ì—†ìŒ

**í•„ìš” ê¸°ëŠ¥**:
- ì‹¤ì œ ê²€ìƒ‰ ë„êµ¬ í˜¸ì¶œ (legal search, real estate DB)
- LLM ê¸°ë°˜ ì •ë³´ ì§‘ê³„ ë° ì •ì œ
- ì¤‘ë³µ ì œê±° ë° ê´€ë ¨ì„± ìˆœìœ„í™”
- ë²•ë¥  ê·œì • ê²€ì¦

---

#### 3. **generate_node** (Lines 247-326)
**í˜„ì¬**:
```python
def _format_document(self, content: str, planning: Dict, feedback: Dict) -> str:
    doc_type = planning.get("document_type", "general")
    sections = planning.get("sections", [])

    document = f"""
# Document: {doc_type.upper()}

## Generated Content

{content}

## Metadata
- Document Type: {doc_type}
- Sections: {', '.join(sections)}
...
"""
    return document.strip()
```

**ë¬¸ì œì **:
- ë‹¨ìˆœ í…ìŠ¤íŠ¸ í…œí”Œë¦¿ë§Œ ì‚¬ìš©
- DOCX í…œí”Œë¦¿ ë¯¸í™œìš©
- ë²•ë¥  ë¬¸ì„œ í˜•ì‹ ë¯¸ì¤€ìˆ˜
- PDF ìƒì„± ë¶ˆê°€

**í•„ìš” ê¸°ëŠ¥**:
- `LeaseContractGeneratorTool` í†µí•©
- DOCX í…œí”Œë¦¿ ê¸°ë°˜ ë¬¸ì„œ ìƒì„±
- ë²•ë¥  ë¬¸ì„œ í¬ë§· ì¤€ìˆ˜
- ë©”íƒ€ë°ì´í„° ë° ì„œëª…ë€ í¬í•¨

---

#### 4. **ê¸°íƒ€ Helper ë©”ì„œë“œ**
**í˜„ì¬**:
```python
def _apply_user_feedback(self, content: str, feedback: Dict) -> str:
    modifications = feedback.get("modifications", "")
    if modifications:
        # Simple append for now
        return f"{content}\n\n[User Feedback Applied]\n{modifications}"
    return content
```

**ë¬¸ì œì **:
- ì‚¬ìš©ì í”¼ë“œë°±ì„ ë‹¨ìˆœ ì¶”ê°€ë§Œ ìˆ˜í–‰
- LLM ê¸°ë°˜ ì§€ëŠ¥í˜• ë³‘í•© ì—†ìŒ

**í•„ìš” ê¸°ëŠ¥**:
- LLMìœ¼ë¡œ í”¼ë“œë°± ë¶„ì„ ë° ë¬¸ë§¥ ë³‘í•©
- ë¬¸ì„œ êµ¬ì¡° ìœ ì§€í•˜ë©´ì„œ ìˆ˜ì •ì‚¬í•­ ë°˜ì˜

---

### ğŸ”§ ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ì¡´ ë„êµ¬

#### 1. **LLMService** (`app/service_agent/llm_manager/llm_service.py`)
- OpenAI LLM í˜¸ì¶œ ê´€ë¦¬
- ë™ê¸°/ë¹„ë™ê¸° í˜¸ì¶œ ì§€ì›
- JSON ì‘ë‹µ ëª¨ë“œ
- ì¬ì‹œë„ ë¡œì§ ë‚´ì¥
- í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ í˜¸ì¶œ

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
from app.service_agent.llm_manager.llm_service import LLMService

llm_service = LLMService(llm_context)
result = await llm_service.complete_json_async(
    prompt_name="document_planning",
    variables={"query": "ì„ëŒ€ì°¨ ê³„ì•½ì„œ ì‘ì„±í•´ì¤˜"},
    temperature=0.3
)
```

---

#### 2. **LeaseContractGeneratorTool** (`app/service_agent/tools/lease_contract_generator_tool.py`)
- DOCX í…œí”Œë¦¿ ê¸°ë°˜ ê³„ì•½ì„œ ìƒì„±
- Placeholder ìë™ ì¹˜í™˜ (`{{address_road}}` ë“±)
- Markdown ë³€í™˜ ì§€ì›
- ìƒì„±ëœ DOCX íŒŒì¼ ì €ì¥

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
from app.service_agent.tools.lease_contract_generator_tool import LeaseContractGeneratorTool

tool = LeaseContractGeneratorTool()
result = await tool.execute(
    address_road="ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 123",
    deposit="500,000,000",
    start_date="2024ë…„ 1ì›” 1ì¼",
    end_date="2026ë…„ 1ì›” 1ì¼",
    lessor_name="í™ê¸¸ë™",
    lessee_name="ê¹€ì² ìˆ˜"
)

# result: {
#   "status": "success",
#   "content": "# ì£¼íƒì„ëŒ€ì°¨ í‘œì¤€ê³„ì•½ì„œ\n...",
#   "docx_path": "/path/to/generated/ê³„ì•½ì„œ_20241028.docx",
#   "sections": [...]
# }
```

---

#### 3. **PromptManager** (`app/service_agent/llm_manager/prompt_manager.py`)
- í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê´€ë¦¬
- ë³€ìˆ˜ ì¹˜í™˜ (ì½”ë“œ ë¸”ë¡ ë³´í˜¸)
- ìºì‹± ì§€ì›

**í•„ìš”í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿** (ì‹ ê·œ ì‘ì„± í•„ìš”):
- `document_planning.txt` - ë¬¸ì„œ ê³„íš ìˆ˜ë¦½
- `document_aggregation.txt` - ì •ë³´ ì§‘ê³„ ë° ì •ì œ
- `document_feedback_merge.txt` - í”¼ë“œë°± ë³‘í•©

---

#### 4. **ê²€ìƒ‰ ë„êµ¬ë“¤** (`app/service_agent/tools/`)
- `hybrid_legal_search.py` - ë²•ë¥  ê²€ìƒ‰ (FAISS + í‚¤ì›Œë“œ)
- `real_estate_search_tool.py` - ë¶€ë™ì‚° ê²€ìƒ‰
- `market_data_tool.py` - ì‹œì¥ ë°ì´í„° ì¡°íšŒ

---

### ğŸ“ í…œí”Œë¦¿ íŒŒì¼ ìœ„ì¹˜
- **DOCX í…œí”Œë¦¿**: `backend/data/storage/documents/lease_contract_template_with_placeholders.docx`
- Placeholder í¬í•¨ëœ í‘œì¤€ ê³„ì•½ì„œ í…œí”Œë¦¿
- `LeaseContractGeneratorTool`ì´ ì‚¬ìš©

---

## ê³ ë„í™” ëª©í‘œ

### ì£¼ìš” ëª©í‘œ

#### 1. Mock ì œê±° ë° ì‹¤ì œ êµ¬í˜„
- [ ] ëª¨ë“  Mock ë¡œì§ì„ ì‹¤ì œ LLM í˜¸ì¶œë¡œ ëŒ€ì²´
- [ ] ì‹¤ì œ ê²€ìƒ‰ ë„êµ¬ í†µí•©
- [ ] DOCX í…œí”Œë¦¿ ê¸°ë°˜ ë¬¸ì„œ ìƒì„±

#### 2. ì§€ëŠ¥í˜• ë¬¸ì„œ ìƒì„±
- [ ] LLM ê¸°ë°˜ ì˜ë„ ë¶„ì„
- [ ] ë¬¸ì„œ íƒ€ì… ìë™ ë¶„ë¥˜
- [ ] ë§¥ë½ ê¸°ë°˜ ì •ë³´ ì§‘ê³„
- [ ] ì‚¬ìš©ì í”¼ë“œë°± ì§€ëŠ¥í˜• ë³‘í•©

#### 3. í”„ë¡œë•ì…˜ í’ˆì§ˆ
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
- [ ] ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±

---

### êµ¬ì²´ì  ì„±ëŠ¥ ëª©í‘œ

| í•­ëª© | í˜„ì¬ | ëª©í‘œ |
|------|------|------|
| ë¬¸ì„œ ìƒì„± ì„±ê³µë¥  | N/A (Mock) | 95% |
| í‰ê·  ì‘ë‹µ ì‹œê°„ | 17s (Mock) | 25s ì´ë‚´ |
| ì‚¬ìš©ì ë§Œì¡±ë„ | N/A | 4.0/5.0 ì´ìƒ |
| ì •ë³´ ì •í™•ë„ | N/A | 90% ì´ìƒ |
| í…œí”Œë¦¿ ì ìš©ë¥  | 0% | 100% |

---

## ì„¸ë¶€ êµ¬í˜„ ê³„íš

### Phase 1: planning_node ê³ ë„í™”

#### 1.1 í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‘ì„±
**íŒŒì¼**: `backend/app/service_agent/llm_manager/prompts/execution/document_planning.txt`

**ë‚´ìš©**:
```
ë‹¹ì‹ ì€ ë²•ë¥  ë¬¸ì„œ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ë¬¸ì„œ ìƒì„± ê³„íšì„ ìˆ˜ë¦½í•˜ì„¸ìš”.

ì‚¬ìš©ì ìš”ì²­: {query}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "document_type": "lease_contract | legal_advice | contract_review | other",
  "confidence": 0.95,
  "sections": ["ì„¹ì…˜1", "ì„¹ì…˜2", ...],
  "required_information": {{
    "í•„ë“œëª…": "ì„¤ëª…"
  }},
  "search_strategy": {{
    "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"],
    "sources": ["legal_db", "real_estate_db"],
    "priority": "high | medium | low"
  }},
  "estimated_complexity": "simple | medium | complex",
  "reasoning": "ê³„íš ìˆ˜ë¦½ ê·¼ê±°"
}}

ë¶„ì„ ì‹œ ê³ ë ¤ì‚¬í•­:
1. ë¬¸ì„œ íƒ€ì…ì´ "lease_contract"ì¸ ê²½ìš° ì„ëŒ€ì°¨ ê³„ì•½ì„œ í‘œì¤€ ì–‘ì‹ ì‚¬ìš©
2. í•„ìˆ˜ ì •ë³´ëŠ” ë²•ë¥ ì ìœ¼ë¡œ ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ì•¼ í•˜ëŠ” í•­ëª©
3. ê²€ìƒ‰ ì „ëµì€ ì •ë³´ ìˆ˜ì§‘ì˜ ìš°ì„ ìˆœìœ„ì™€ ë°©ë²• ê²°ì •
4. ë³µì¡ë„ëŠ” í–¥í›„ ì‘ì—… ì‹œê°„ ì˜ˆì¸¡ì— ì‚¬ìš©
```

---

#### 1.2 planning_node êµ¬í˜„
**ìœ„ì¹˜**: `document_executor.py` Lines 94-142

**êµ¬í˜„ ë‚´ìš©**:
```python
async def planning_node(self, state: MainSupervisorState) -> Dict[str, Any]:
    """
    Planning Node: ì‚¬ìš©ì ìš”ì²­ ë¶„ì„ ë° ë¬¸ì„œ ìƒì„± ê³„íš ìˆ˜ë¦½

    Improvements:
    - LLM ê¸°ë°˜ ì˜ë„ ë¶„ì„
    - ë¬¸ì„œ íƒ€ì… ìë™ ë¶„ë¥˜
    - í•„ìˆ˜ ì •ë³´ ì‹ë³„
    - ê²€ìƒ‰ ì „ëµ ìˆ˜ë¦½
    """
    logger.info("ğŸ“‹ Planning node: Analyzing document requirements")

    await self._update_step_progress(state, step_index=0, status="in_progress", progress=0)

    query = state.get("query", "")

    # LLMìœ¼ë¡œ ê³„íš ìˆ˜ë¦½
    from app.service_agent.llm_manager.llm_service import LLMService

    llm_service = LLMService(self.llm_context)

    try:
        planning_result = await llm_service.complete_json_async(
            prompt_name="document_planning",
            variables={"query": query},
            temperature=0.3,
            max_tokens=1000
        )

        logger.info(
            f"Planning complete: {planning_result.get('document_type')} "
            f"(confidence: {planning_result.get('confidence', 0):.2%})"
        )

    except Exception as e:
        logger.error(f"LLM planning failed, using fallback: {e}")
        # Fallback to simple extraction
        planning_result = self._fallback_planning(query)

    await self._update_step_progress(state, step_index=0, status="completed", progress=100)

    return {
        "planning_result": planning_result,
        "workflow_status": "running"
    }

def _fallback_planning(self, query: str) -> Dict[str, Any]:
    """Fallback ê³„íš (LLM ì‹¤íŒ¨ ì‹œ)"""
    return {
        "document_type": "general",
        "confidence": 0.5,
        "sections": ["introduction", "main_content", "conclusion"],
        "required_information": {},
        "search_strategy": {
            "keywords": query.split()[:5],
            "sources": ["general"],
            "priority": "medium"
        },
        "estimated_complexity": "simple",
        "reasoning": "Fallback planning due to LLM error"
    }
```

**ì‚­ì œí•  ë©”ì„œë“œ**:
- `_extract_keywords()` - LLMì´ ëŒ€ì²´

---

### Phase 2: aggregate_node ê³ ë„í™”

#### 2.1 í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‘ì„±
**íŒŒì¼**: `backend/app/service_agent/llm_manager/prompts/execution/document_aggregation.txt`

**ë‚´ìš©**:
```
ë‹¹ì‹ ì€ ë²•ë¥  ì •ë³´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ë¬¸ì„œ ìƒì„±ì— í•„ìš”í•œ ì •ë³´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.

ë¬¸ì„œ íƒ€ì…: {document_type}
í•„ìˆ˜ ì •ë³´: {required_information}
ê²€ìƒ‰ ê²°ê³¼: {search_results}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "aggregated_fields": {{
    "í•„ë“œëª…": "ì¶”ì¶œëœ ê°’"
  }},
  "additional_context": "ì¶”ê°€ ì„¤ëª… ë˜ëŠ” ë§¥ë½",
  "missing_fields": ["ëˆ„ë½ëœ í•„ë“œ1", "ëˆ„ë½ëœ í•„ë“œ2"],
  "confidence": 0.85,
  "sources": ["source1", "source2"],
  "warnings": ["ì£¼ì˜ì‚¬í•­1", "ì£¼ì˜ì‚¬í•­2"]
}}

ì§‘ê³„ ì‹œ ê³ ë ¤ì‚¬í•­:
1. ë²•ë¥ ì ìœ¼ë¡œ ì •í™•í•œ ì •ë³´ë§Œ ì¶”ì¶œ
2. ì¤‘ë³µ ì •ë³´ëŠ” ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ê²ƒ ì„ íƒ
3. ëˆ„ë½ëœ í•„ìˆ˜ ì •ë³´ëŠ” ëª…í™•íˆ í‘œì‹œ
4. ì¶œì²˜ë¥¼ ëª…í™•íˆ ê¸°ë¡
```

---

#### 2.2 aggregate_node êµ¬í˜„
**ìœ„ì¹˜**: `document_executor.py` Lines 144-245

**êµ¬í˜„ ë‚´ìš©**:
```python
async def aggregate_node(self, state: MainSupervisorState) -> Dict[str, Any]:
    """
    Aggregate Node: ì •ë³´ ê²€ìƒ‰ ë° ì§‘ê³„ + HITL

    Improvements:
    - ì‹¤ì œ ê²€ìƒ‰ ë„êµ¬ í˜¸ì¶œ
    - LLM ê¸°ë°˜ ì •ë³´ ì§‘ê³„
    - ì¤‘ë³µ ì œê±° ë° ê²€ì¦
    - ì§€ëŠ¥í˜• ì •ë³´ ì •ì œ
    """
    logger.info("ğŸ“Š Aggregate node: Consolidating search results")

    await self._update_step_progress(state, step_index=1, status="in_progress", progress=0)

    planning_result = state.get("planning_result", {})
    search_strategy = planning_result.get("search_strategy", {})

    # Step 1: ì‹¤ì œ ê²€ìƒ‰ ìˆ˜í–‰
    search_results = await self._perform_search(search_strategy)

    # Step 2: LLMìœ¼ë¡œ ì •ë³´ ì§‘ê³„
    aggregated_data = await self._aggregate_with_llm(
        planning_result=planning_result,
        search_results=search_results
    )

    logger.info(f"Aggregation complete: {len(aggregated_data.get('aggregated_fields', {}))} fields extracted")

    await self._update_step_progress(state, step_index=1, status="completed", progress=100)
    await self._update_step_progress(state, step_index=2, status="in_progress", progress=0)

    # Step 3: HITL - ì‚¬ìš©ì ìŠ¹ì¸ ìš”ì²­
    logger.info("â¸ï¸  Requesting human approval via interrupt()")

    interrupt_value = {
        "aggregated_data": aggregated_data,
        "search_results_count": len(search_results),
        "missing_fields": aggregated_data.get("missing_fields", []),
        "warnings": aggregated_data.get("warnings", []),
        "message": "ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ê²€í† í•´ì£¼ì„¸ìš”. í•„ìš”í•œ ê²½ìš° ìˆ˜ì •ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”.",
        "options": {
            "approve": "ì •ë³´ê°€ ì •í™•í•©ë‹ˆë‹¤. ë¬¸ì„œ ìƒì„±ì„ ê³„ì†í•˜ì„¸ìš”.",
            "modify": "ì¼ë¶€ ì •ë³´ë¥¼ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.",
            "reject": "ë¬¸ì„œ ìƒì„±ì„ ì·¨ì†Œí•©ë‹ˆë‹¤."
        },
        "_metadata": {
            "interrupted_by": "aggregate",
            "interrupt_type": "approval",
            "node_name": "document_team.aggregate"
        }
    }

    state["aggregated_content"] = self._format_aggregated_content(aggregated_data)
    state["aggregated_data"] = aggregated_data  # êµ¬ì¡°í™”ëœ ë°ì´í„° ì €ì¥
    state["workflow_status"] = "interrupted"

    # LangGraph 0.6 HITL Pattern
    user_feedback = interrupt(interrupt_value)

    logger.info("â–¶ï¸  Workflow resumed with user feedback")

    await self._update_step_progress(state, step_index=2, status="completed", progress=100)
    await self._update_step_progress(state, step_index=3, status="in_progress", progress=0)

    # Step 4: ì‚¬ìš©ì í”¼ë“œë°± ì²˜ë¦¬
    if user_feedback and user_feedback.get("action") == "modify":
        logger.info("Applying user modifications with LLM")
        aggregated_data = await self._apply_user_feedback_with_llm(
            aggregated_data=aggregated_data,
            user_feedback=user_feedback
        )

    await self._update_step_progress(state, step_index=3, status="completed", progress=100)

    return {
        "aggregated_content": self._format_aggregated_content(aggregated_data),
        "aggregated_data": aggregated_data,
        "collaboration_result": user_feedback,
        "workflow_status": "running",
        "interrupted_by": "aggregate",
        "interrupt_type": "approval"
    }


async def _perform_search(self, search_strategy: Dict) -> List[Dict[str, Any]]:
    """
    ì‹¤ì œ ê²€ìƒ‰ ë„êµ¬ í˜¸ì¶œ

    Args:
        search_strategy: ê²€ìƒ‰ ì „ëµ (keywords, sources, priority)

    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    keywords = search_strategy.get("keywords", [])
    sources = search_strategy.get("sources", [])

    search_results = []

    # Legal DB ê²€ìƒ‰
    if "legal_db" in sources:
        try:
            from app.service_agent.tools.hybrid_legal_search import HybridLegalSearch

            legal_tool = HybridLegalSearch()
            for keyword in keywords[:3]:  # ìµœëŒ€ 3ê°œ í‚¤ì›Œë“œ
                result = await legal_tool.execute(query=keyword, top_k=3)
                if result.get("status") == "success":
                    search_results.extend(result.get("results", []))
        except Exception as e:
            logger.warning(f"Legal search failed: {e}")

    # Real Estate DB ê²€ìƒ‰
    if "real_estate_db" in sources:
        try:
            from app.service_agent.tools.real_estate_search_tool import RealEstateSearchTool

            realestate_tool = RealEstateSearchTool()
            result = await realestate_tool.execute(query=" ".join(keywords))
            if result.get("status") == "success":
                search_results.extend(result.get("properties", []))
        except Exception as e:
            logger.warning(f"Real estate search failed: {e}")

    # Fallback: Mock ë°ì´í„° (ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ)
    if not search_results:
        logger.warning("All searches failed, using mock data")
        search_results = self._mock_search(keywords)

    return search_results


async def _aggregate_with_llm(
    self,
    planning_result: Dict,
    search_results: List[Dict]
) -> Dict[str, Any]:
    """
    LLMìœ¼ë¡œ ê²€ìƒ‰ ê²°ê³¼ ì§‘ê³„ ë° ì •ì œ

    Args:
        planning_result: ê³„íš ê²°ê³¼
        search_results: ê²€ìƒ‰ ê²°ê³¼

    Returns:
        ì§‘ê³„ëœ ë°ì´í„°
    """
    from app.service_agent.llm_manager.llm_service import LLMService
    import json

    llm_service = LLMService(self.llm_context)

    try:
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ë³€í™˜ (ìµœëŒ€ 3000ì)
        search_results_json = json.dumps(search_results, ensure_ascii=False)[:3000]

        variables = {
            "document_type": planning_result.get("document_type", "general"),
            "required_information": json.dumps(
                planning_result.get("required_information", {}),
                ensure_ascii=False
            ),
            "search_results": search_results_json
        }

        aggregated_data = await llm_service.complete_json_async(
            prompt_name="document_aggregation",
            variables=variables,
            temperature=0.2,
            max_tokens=1500
        )

        return aggregated_data

    except Exception as e:
        logger.error(f"LLM aggregation failed: {e}")
        # Fallback
        return {
            "aggregated_fields": {},
            "additional_context": "LLM aggregation failed",
            "missing_fields": [],
            "confidence": 0.3,
            "sources": [],
            "warnings": ["LLM aggregation failed, using fallback"]
        }


def _format_aggregated_content(self, aggregated_data: Dict) -> str:
    """
    ì§‘ê³„ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©ì ì¹œí™”ì  í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

    Args:
        aggregated_data: ì§‘ê³„ëœ ë°ì´í„°

    Returns:
        í¬ë§·ëœ í…ìŠ¤íŠ¸
    """
    lines = ["# ìˆ˜ì§‘ëœ ì •ë³´\n"]

    # í•„ë“œ ì •ë³´
    fields = aggregated_data.get("aggregated_fields", {})
    if fields:
        lines.append("## ì¶”ì¶œëœ ì •ë³´")
        for key, value in fields.items():
            lines.append(f"- **{key}**: {value}")
        lines.append("")

    # ì¶”ê°€ ë§¥ë½
    context = aggregated_data.get("additional_context", "")
    if context:
        lines.append("## ì¶”ê°€ ì •ë³´")
        lines.append(context)
        lines.append("")

    # ëˆ„ë½ í•„ë“œ
    missing = aggregated_data.get("missing_fields", [])
    if missing:
        lines.append("## âš ï¸ ëˆ„ë½ëœ í•„ìˆ˜ ì •ë³´")
        for field in missing:
            lines.append(f"- {field}")
        lines.append("")

    # ê²½ê³ 
    warnings = aggregated_data.get("warnings", [])
    if warnings:
        lines.append("## âš ï¸ ì£¼ì˜ì‚¬í•­")
        for warning in warnings:
            lines.append(f"- {warning}")
        lines.append("")

    return "\n".join(lines)


async def _apply_user_feedback_with_llm(
    self,
    aggregated_data: Dict,
    user_feedback: Dict
) -> Dict[str, Any]:
    """
    LLMìœ¼ë¡œ ì‚¬ìš©ì í”¼ë“œë°± ì§€ëŠ¥í˜• ë³‘í•©

    Args:
        aggregated_data: ì›ë³¸ ì§‘ê³„ ë°ì´í„°
        user_feedback: ì‚¬ìš©ì í”¼ë“œë°±

    Returns:
        ìˆ˜ì •ëœ ì§‘ê³„ ë°ì´í„°
    """
    from app.service_agent.llm_manager.llm_service import LLMService
    import json

    modifications = user_feedback.get("modifications", "")
    if not modifications:
        return aggregated_data

    llm_service = LLMService(self.llm_context)

    try:
        # í”„ë¡¬í”„íŠ¸ ì‘ì„±
        prompt_content = f"""
ë‹¹ì‹ ì€ ë¬¸ì„œ ì •ë³´ í¸ì§‘ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ì§‘ê³„ëœ ì •ë³´ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.

í˜„ì¬ ì •ë³´:
{json.dumps(aggregated_data, ensure_ascii=False, indent=2)}

ì‚¬ìš©ì í”¼ë“œë°±:
{modifications}

ìˆ˜ì •ëœ ì •ë³´ë¥¼ ì›ë³¸ê³¼ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
í•„ë“œ êµ¬ì¡°ëŠ” ìœ ì§€í•˜ë˜, ì‚¬ìš©ìê°€ ìš”ì²­í•œ ë‚´ìš©ë§Œ ìˆ˜ì •í•˜ì„¸ìš”.
"""

        # LLM í˜¸ì¶œ (ì„ì‹œë¡œ ì§ì ‘ í˜¸ì¶œ)
        response = await llm_service.complete_async(
            prompt_name="common_instruction",  # ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            variables={"instruction": prompt_content},
            temperature=0.2,
            max_tokens=1500,
            response_format={"type": "json_object"}
        )

        modified_data = json.loads(response)
        logger.info("User feedback applied successfully with LLM")
        return modified_data

    except Exception as e:
        logger.error(f"LLM feedback merge failed: {e}")
        # Fallback: ë‹¨ìˆœ ì¶”ê°€
        aggregated_data["additional_context"] += f"\n\n[ì‚¬ìš©ì ìˆ˜ì •ì‚¬í•­]\n{modifications}"
        return aggregated_data
```

**ì‚­ì œí•  ë©”ì„œë“œ**:
- `_mock_search()` - ì‹¤ì œ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´ (fallbackìœ¼ë¡œë§Œ ìœ ì§€)
- `_aggregate_results()` - LLM ì§‘ê³„ë¡œ ëŒ€ì²´
- `_apply_user_feedback()` - LLM ë³‘í•©ìœ¼ë¡œ ëŒ€ì²´

---

### Phase 3: generate_node ê³ ë„í™”

#### 3.1 generate_node êµ¬í˜„
**ìœ„ì¹˜**: `document_executor.py` Lines 247-326

**êµ¬í˜„ ë‚´ìš©**:
```python
async def generate_node(self, state: MainSupervisorState) -> Dict[str, Any]:
    """
    Generate Node: ìµœì¢… ë¬¸ì„œ ìƒì„±

    Improvements:
    - LeaseContractGeneratorTool í†µí•©
    - DOCX í…œí”Œë¦¿ ì‚¬ìš©
    - ë²•ë¥  ë¬¸ì„œ í¬ë§· ì¤€ìˆ˜
    - ë©”íƒ€ë°ì´í„° ë° ì¶œì²˜ í¬í•¨
    """
    logger.info("ğŸ“ Generate node: Creating final document")

    await self._update_step_progress(state, step_index=4, status="in_progress", progress=0)

    planning_result = state.get("planning_result", {})
    aggregated_data = state.get("aggregated_data", {})
    collaboration_result = state.get("collaboration_result", {})

    document_type = planning_result.get("document_type", "general")

    # ë¬¸ì„œ íƒ€ì…ì— ë”°ë¥¸ ìƒì„± ì „ëµ
    if document_type == "lease_contract":
        final_response = await self._generate_lease_contract(
            aggregated_data=aggregated_data,
            planning_result=planning_result,
            collaboration_result=collaboration_result
        )
    else:
        # ì¼ë°˜ ë¬¸ì„œ (í…ìŠ¤íŠ¸ ê¸°ë°˜)
        final_response = await self._generate_general_document(
            aggregated_data=aggregated_data,
            planning_result=planning_result,
            collaboration_result=collaboration_result
        )

    await self._update_step_progress(state, step_index=4, status="completed", progress=100)
    await self._update_step_progress(state, step_index=5, status="in_progress", progress=0)

    # ìµœì¢… ê²€í†  (ìë™ ìŠ¹ì¸)
    logger.info("âœ… Document generated successfully")

    await self._update_step_progress(state, step_index=5, status="completed", progress=100)

    # team_results êµ¬ì„±
    team_results = {
        "document": {
            "status": "success",
            "data": final_response
        }
    }

    return {
        "final_document": final_response.get("answer", ""),
        "final_response": final_response,
        "workflow_status": "completed",
        "team_results": team_results
    }


async def _generate_lease_contract(
    self,
    aggregated_data: Dict,
    planning_result: Dict,
    collaboration_result: Dict
) -> Dict[str, Any]:
    """
    ì„ëŒ€ì°¨ ê³„ì•½ì„œ ìƒì„± (DOCX í…œí”Œë¦¿ ì‚¬ìš©)

    Args:
        aggregated_data: ì§‘ê³„ëœ ë°ì´í„°
        planning_result: ê³„íš ê²°ê³¼
        collaboration_result: ì‚¬ìš©ì í”¼ë“œë°±

    Returns:
        final_response ë”•ì…”ë„ˆë¦¬
    """
    from app.service_agent.tools.lease_contract_generator_tool import LeaseContractGeneratorTool

    # ì§‘ê³„ëœ í•„ë“œ ì¶”ì¶œ
    fields = aggregated_data.get("aggregated_fields", {})

    # LeaseContractGeneratorTool íŒŒë¼ë¯¸í„° ë§¤í•‘
    params = self._map_fields_to_contract_params(fields)

    # ë„êµ¬ ì‹¤í–‰
    tool = LeaseContractGeneratorTool()

    try:
        result = await tool.execute(**params)

        if result.get("status") == "success":
            logger.info(f"Contract generated: {result.get('docx_path')}")

            return {
                "answer": result.get("content", ""),
                "document_type": "lease_contract",
                "docx_path": result.get("docx_path"),
                "sections": result.get("sections", []),
                "user_approved": collaboration_result.get("action") == "approve",
                "user_action": collaboration_result.get("action", "unknown"),
                "metadata": result.get("metadata", {}),
                "type": "document"
            }
        else:
            # ë„êµ¬ ì‹¤íŒ¨ ì‹œ Fallback
            logger.error(f"Contract generation failed: {result.get('error')}")
            return self._generate_fallback_document(
                aggregated_data=aggregated_data,
                document_type="lease_contract",
                error=result.get("error")
            )

    except Exception as e:
        logger.error(f"Contract generation exception: {e}", exc_info=True)
        return self._generate_fallback_document(
            aggregated_data=aggregated_data,
            document_type="lease_contract",
            error=str(e)
        )


def _map_fields_to_contract_params(self, fields: Dict) -> Dict:
    """
    ì§‘ê³„ëœ í•„ë“œë¥¼ LeaseContractGeneratorTool íŒŒë¼ë¯¸í„°ë¡œ ë§¤í•‘

    Args:
        fields: ì§‘ê³„ëœ í•„ë“œ ë”•ì…”ë„ˆë¦¬

    Returns:
        ë„êµ¬ íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
    """
    # í•„ë“œëª… ë§¤í•‘ (ì§‘ê³„ í•„ë“œ â†’ ë„êµ¬ íŒŒë¼ë¯¸í„°)
    field_mapping = {
        "ì£¼ì†Œ": "address_road",
        "ìƒì„¸ì£¼ì†Œ": "address_detail",
        "ì„ì°¨ë©´ì ": "rental_area",
        "ë³´ì¦ê¸ˆ": "deposit",
        "ë³´ì¦ê¸ˆ_í•œê¸€": "deposit_hangeul",
        "ê³„ì•½ê¸ˆ": "contract_payment",
        "ì›”ì„¸": "monthly_rent",
        "ì›”ì„¸_ë‚©ë¶€ì¼": "monthly_rent_day",
        "ê´€ë¦¬ë¹„": "management_fee",
        "ì‹œì‘ì¼": "start_date",
        "ì¢…ë£Œì¼": "end_date",
        "ì„ëŒ€ì¸_ì„±ëª…": "lessor_name",
        "ì„ëŒ€ì¸_ì£¼ì†Œ": "lessor_address",
        "ì„ëŒ€ì¸_ì—°ë½ì²˜": "lessor_phone",
        "ì„ì°¨ì¸_ì„±ëª…": "lessee_name",
        "ì„ì°¨ì¸_ì£¼ì†Œ": "lessee_address",
        "ì„ì°¨ì¸_ì—°ë½ì²˜": "lessee_phone",
        "íŠ¹ì•½ì‚¬í•­": "special_terms"
    }

    params = {}
    for korean_name, param_name in field_mapping.items():
        if korean_name in fields:
            params[param_name] = fields[korean_name]

    return params


async def _generate_general_document(
    self,
    aggregated_data: Dict,
    planning_result: Dict,
    collaboration_result: Dict
) -> Dict[str, Any]:
    """
    ì¼ë°˜ ë¬¸ì„œ ìƒì„± (í…ìŠ¤íŠ¸ ê¸°ë°˜)

    Args:
        aggregated_data: ì§‘ê³„ëœ ë°ì´í„°
        planning_result: ê³„íš ê²°ê³¼
        collaboration_result: ì‚¬ìš©ì í”¼ë“œë°±

    Returns:
        final_response ë”•ì…”ë„ˆë¦¬
    """
    from app.service_agent.llm_manager.llm_service import LLMService
    import json

    llm_service = LLMService(self.llm_context)

    try:
        # LLMìœ¼ë¡œ ë¬¸ì„œ ìƒì„±
        prompt_content = f"""
ë‹¹ì‹ ì€ ì „ë¬¸ ë¬¸ì„œ ì‘ì„±ê°€ì…ë‹ˆë‹¤.
ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì¸ ë¬¸ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.

ë¬¸ì„œ íƒ€ì…: {planning_result.get('document_type')}
í•„ìš” ì„¹ì…˜: {', '.join(planning_result.get('sections', []))}

ìˆ˜ì§‘ëœ ì •ë³´:
{json.dumps(aggregated_data, ensure_ascii=False, indent=2)}

ì‚¬ìš©ì í”¼ë“œë°±:
{collaboration_result.get('modifications', 'ì—†ìŒ')}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¬¸ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”:
# ë¬¸ì„œ ì œëª©

## ì„¹ì…˜1
ë‚´ìš©...

## ì„¹ì…˜2
ë‚´ìš©...
"""

        document_content = await llm_service.complete_async(
            prompt_name="common_instruction",
            variables={"instruction": prompt_content},
            temperature=0.5,
            max_tokens=2000
        )

        return {
            "answer": document_content,
            "document_type": planning_result.get("document_type"),
            "user_approved": collaboration_result.get("action") == "approve",
            "user_action": collaboration_result.get("action", "unknown"),
            "type": "document",
            "metadata": {
                "confidence": aggregated_data.get("confidence", 0.7),
                "sources": aggregated_data.get("sources", [])
            }
        }

    except Exception as e:
        logger.error(f"General document generation failed: {e}")
        return self._generate_fallback_document(
            aggregated_data=aggregated_data,
            document_type=planning_result.get("document_type", "general"),
            error=str(e)
        )


def _generate_fallback_document(
    self,
    aggregated_data: Dict,
    document_type: str,
    error: str
) -> Dict[str, Any]:
    """
    Fallback ë¬¸ì„œ ìƒì„± (ì—ëŸ¬ ì‹œ)

    Args:
        aggregated_data: ì§‘ê³„ëœ ë°ì´í„°
        document_type: ë¬¸ì„œ íƒ€ì…
        error: ì—ëŸ¬ ë©”ì‹œì§€

    Returns:
        final_response ë”•ì…”ë„ˆë¦¬
    """
    content = f"""
# ë¬¸ì„œ ìƒì„± ê²°ê³¼

ë¬¸ì„œ íƒ€ì…: {document_type}

## ìˆ˜ì§‘ëœ ì •ë³´

"""

    fields = aggregated_data.get("aggregated_fields", {})
    for key, value in fields.items():
        content += f"- **{key}**: {value}\n"

    content += f"\n\n## ì£¼ì˜\në¬¸ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error}\n"
    content += "ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ìˆ˜ë™ìœ¼ë¡œ ë¬¸ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"

    return {
        "answer": content,
        "document_type": document_type,
        "type": "document",
        "status": "partial",
        "error": error,
        "metadata": {
            "fallback": True
        }
    }
```

**ì‚­ì œí•  ë©”ì„œë“œ**:
- `_format_document()` - DOCX ìƒì„± ë˜ëŠ” LLM ìƒì„±ìœ¼ë¡œ ëŒ€ì²´

---

### Phase 4: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‘ì„±

#### 4.1 í•„ìš”í•œ í”„ë¡¬í”„íŠ¸ íŒŒì¼

**ë””ë ‰í† ë¦¬**: `backend/app/service_agent/llm_manager/prompts/execution/`

1. **document_planning.txt** (ì´ë¯¸ Phase 1ì— ì‘ì„±ë¨)
2. **document_aggregation.txt** (ì´ë¯¸ Phase 2ì— ì‘ì„±ë¨)
3. **common_instruction.txt** (ë²”ìš© í”„ë¡¬í”„íŠ¸)

**íŒŒì¼**: `common_instruction.txt`
**ìœ„ì¹˜**: `backend/app/service_agent/llm_manager/prompts/common/`

**ë‚´ìš©**:
```
{instruction}
```

(ë‹¨ìˆœ ë³€ìˆ˜ ì „ë‹¬ìš© ë²”ìš© í”„ë¡¬í”„íŠ¸)

---

### Phase 5: ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹… ê°•í™”

#### 5.1 ì—ëŸ¬ ì²˜ë¦¬ ê°œì„ 

**ì¶”ê°€í•  ì˜ˆì™¸ ì²˜ë¦¬**:
1. LLM í˜¸ì¶œ ì‹¤íŒ¨ â†’ Fallback ë¡œì§
2. ê²€ìƒ‰ ë„êµ¬ ì‹¤íŒ¨ â†’ Mock ë°ì´í„° ì‚¬ìš©
3. DOCX ìƒì„± ì‹¤íŒ¨ â†’ í…ìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„±
4. íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ â†’ ì§„í–‰ ìƒí™© ì €ì¥ ë° ì¬ê°œ

**êµ¬í˜„ ì˜ˆì‹œ**:
```python
try:
    result = await llm_service.complete_json_async(...)
except TimeoutError as e:
    logger.error(f"LLM timeout: {e}")
    return fallback_result
except Exception as e:
    logger.error(f"LLM error: {e}", exc_info=True)
    return fallback_result
```

---

#### 5.2 ë¡œê¹… ê°•í™”

**ì¶”ê°€í•  ë¡œê·¸**:
1. ê° ë‹¨ê³„ ì‹œì‘/ì™„ë£Œ ì‹œê°„ ê¸°ë¡
2. LLM í† í° ì‚¬ìš©ëŸ‰ ê¸°ë¡
3. ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ ë° í’ˆì§ˆ ì§€í‘œ
4. ì‚¬ìš©ì í”¼ë“œë°± ë‚´ìš© ê¸°ë¡

**êµ¬í˜„ ì˜ˆì‹œ**:
```python
import time

start_time = time.time()
logger.info(f"[{node_name}] Starting...")

# ... ì‘ì—… ìˆ˜í–‰ ...

elapsed = time.time() - start_time
logger.info(f"[{node_name}] Completed in {elapsed:.2f}s")
```

---

### Phase 6: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

#### 6.1 í…ŒìŠ¤íŠ¸ íŒŒì¼ êµ¬ì¡°
**ìœ„ì¹˜**: `backend/tests/service_agent/execution_agents/`

**íŒŒì¼**:
- `test_document_executor_planning.py` - planning_node í…ŒìŠ¤íŠ¸
- `test_document_executor_aggregate.py` - aggregate_node í…ŒìŠ¤íŠ¸
- `test_document_executor_generate.py` - generate_node í…ŒìŠ¤íŠ¸
- `test_document_executor_integration.py` - í†µí•© í…ŒìŠ¤íŠ¸

---

#### 6.2 í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì˜ˆì‹œ

**íŒŒì¼**: `test_document_executor_planning.py`

```python
import pytest
from app.service_agent.execution_agents.document_executor import DocumentExecutor
from app.service_agent.foundation.separated_states import MainSupervisorState

@pytest.mark.asyncio
async def test_planning_node_lease_contract():
    """ì„ëŒ€ì°¨ ê³„ì•½ì„œ ìš”ì²­ ì‹œ planning_node í…ŒìŠ¤íŠ¸"""
    executor = DocumentExecutor()

    state = MainSupervisorState(
        query="ì„ëŒ€ì°¨ ê³„ì•½ì„œ ì‘ì„±í•´ì¤˜. ë³´ì¦ê¸ˆ 5ì–µ, ì›”ì„¸ 200ë§Œì›"
    )

    result = await executor.planning_node(state)

    assert result["planning_result"]["document_type"] == "lease_contract"
    assert result["planning_result"]["confidence"] > 0.8
    assert "ë³´ì¦ê¸ˆ" in result["planning_result"]["required_information"]
    assert "ì›”ì„¸" in result["planning_result"]["required_information"]


@pytest.mark.asyncio
async def test_planning_node_fallback():
    """LLM ì‹¤íŒ¨ ì‹œ fallback í…ŒìŠ¤íŠ¸"""
    executor = DocumentExecutor()
    executor.llm_context = None  # LLM ë¹„í™œì„±í™”

    state = MainSupervisorState(query="ê³„ì•½ì„œ ì‘ì„±")

    result = await executor.planning_node(state)

    assert result["planning_result"]["document_type"] == "general"
    assert result["planning_result"]["confidence"] < 0.7
```

---

## ë‹¨ê³„ë³„ ì‘ì—… ë‚´ì—­

### Phase 1: planning_node ê³ ë„í™” (ì˜ˆìƒ ì†Œìš”: 2ì¼)

#### Day 1
- [ ] `document_planning.txt` í”„ë¡¬í”„íŠ¸ ì‘ì„±
- [ ] `planning_node` êµ¬í˜„
- [ ] `_fallback_planning` êµ¬í˜„
- [ ] `_extract_keywords` ì œê±°
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„± (test_planning_node)

#### Day 2
- [ ] LLM í˜¸ì¶œ í…ŒìŠ¤íŠ¸
- [ ] Fallback ë¡œì§ í…ŒìŠ¤íŠ¸
- [ ] ë‹¤ì–‘í•œ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ (ì„ëŒ€ì°¨, ë²•ë¥ ìë¬¸ ë“±)
- [ ] ë¡œê¹… ê²€ì¦
- [ ] ì½”ë“œ ë¦¬ë·° ë° ìˆ˜ì •

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] 80% ì´ìƒì˜ ì¿¼ë¦¬ì—ì„œ ì˜¬ë°”ë¥¸ document_type ë¶„ë¥˜
- [ ] LLM ì‹¤íŒ¨ ì‹œ fallback ì •ìƒ ì‘ë™
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ pass
- [ ] ë¡œê·¸ì— ì˜ë„ ë¶„ì„ ê²°ê³¼ ëª…í™•íˆ í‘œì‹œ

---

### Phase 2: aggregate_node ê³ ë„í™” (ì˜ˆìƒ ì†Œìš”: 4ì¼)

#### Day 3-4
- [ ] `document_aggregation.txt` í”„ë¡¬í”„íŠ¸ ì‘ì„±
- [ ] `_perform_search` êµ¬í˜„ (legal, real estate ê²€ìƒ‰)
- [ ] `_aggregate_with_llm` êµ¬í˜„
- [ ] `_format_aggregated_content` êµ¬í˜„

#### Day 5-6
- [ ] `_apply_user_feedback_with_llm` êµ¬í˜„
- [ ] ê²€ìƒ‰ ë„êµ¬ í†µí•© í…ŒìŠ¤íŠ¸
- [ ] LLM ì§‘ê³„ í…ŒìŠ¤íŠ¸
- [ ] HITL íë¦„ í…ŒìŠ¤íŠ¸
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] ì½”ë“œ ë¦¬ë·° ë° ìˆ˜ì •

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] ì‹¤ì œ ê²€ìƒ‰ ë„êµ¬ ì •ìƒ ì‘ë™
- [ ] LLM ì§‘ê³„ ì •í™•ë„ 80% ì´ìƒ
- [ ] ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜ ì •ìƒ ì‘ë™
- [ ] HITL interrupt/resume ì •ìƒ ì‘ë™
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ pass

---

### Phase 3: generate_node ê³ ë„í™” (ì˜ˆìƒ ì†Œìš”: 3ì¼)

#### Day 7-8
- [ ] `_generate_lease_contract` êµ¬í˜„
- [ ] `_map_fields_to_contract_params` êµ¬í˜„
- [ ] `LeaseContractGeneratorTool` í†µí•©
- [ ] DOCX ìƒì„± í…ŒìŠ¤íŠ¸

#### Day 9
- [ ] `_generate_general_document` êµ¬í˜„
- [ ] `_generate_fallback_document` êµ¬í˜„
- [ ] ë‹¤ì–‘í•œ ë¬¸ì„œ íƒ€ì… í…ŒìŠ¤íŠ¸
- [ ] ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] ì½”ë“œ ë¦¬ë·° ë° ìˆ˜ì •

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] ì„ëŒ€ì°¨ ê³„ì•½ì„œ DOCX ìƒì„± ì„±ê³µ
- [ ] ì¼ë°˜ ë¬¸ì„œ í…ìŠ¤íŠ¸ ìƒì„± ì„±ê³µ
- [ ] Fallback ë¬¸ì„œ ìƒì„± ì •ìƒ ì‘ë™
- [ ] ìƒì„±ëœ ë¬¸ì„œ ë²•ë¥  í˜•ì‹ ì¤€ìˆ˜
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ pass

---

### Phase 4: í”„ë¡¬í”„íŠ¸ ë° ì—ëŸ¬ ì²˜ë¦¬ (ì˜ˆìƒ ì†Œìš”: 1ì¼)

#### Day 10
- [ ] `common_instruction.txt` ì‘ì„±
- [ ] í”„ë¡¬í”„íŠ¸ ë””ë ‰í† ë¦¬ ì •ë¦¬
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ë¡œì§ ì¶”ê°€
- [ ] ë¡œê¹… ê°•í™”
- [ ] íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ ì¶”ê°€

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] ëª¨ë“  í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì‘ì„± ì™„ë£Œ
- [ ] ëª¨ë“  ì˜ˆì™¸ ìƒí™© ì²˜ë¦¬
- [ ] ë¡œê·¸ì— ì¶©ë¶„í•œ ì •ë³´ ê¸°ë¡
- [ ] íƒ€ì„ì•„ì›ƒ ì‹œ ì•ˆì „í•˜ê²Œ ì¢…ë£Œ

---

### Phase 5: í†µí•© í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ (ì˜ˆìƒ ì†Œìš”: 2ì¼)

#### Day 11
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„± (end-to-end)
- [ ] ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
  - [ ] ì„ëŒ€ì°¨ ê³„ì•½ì„œ ìƒì„±
  - [ ] ë²•ë¥  ìë¬¸ì„œ ìƒì„±
  - [ ] ì‚¬ìš©ì ìˆ˜ì • í›„ ì¬ìƒì„±
  - [ ] ì—ëŸ¬ ë°œìƒ ì‹œ ë³µêµ¬
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ì‘ë‹µ ì‹œê°„, í† í° ì‚¬ìš©ëŸ‰)

#### Day 12
- [ ] ë²„ê·¸ ìˆ˜ì •
- [ ] ì½”ë“œ ìµœì í™”
- [ ] ë¬¸ì„œí™” ì—…ë°ì´íŠ¸
- [ ] ìµœì¢… ê²€í† 

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] ëª¨ë“  í†µí•© í…ŒìŠ¤íŠ¸ pass
- [ ] í‰ê·  ì‘ë‹µ ì‹œê°„ 25ì´ˆ ì´ë‚´
- [ ] ë¬¸ì„œ ìƒì„± ì„±ê³µë¥  95% ì´ìƒ
- [ ] ì½”ë“œ ì»¤ë²„ë¦¬ì§€ 80% ì´ìƒ

---

### Phase 6: ë°°í¬ ì¤€ë¹„ (ì˜ˆìƒ ì†Œìš”: 1ì¼)

#### Day 13
- [ ] Production í™˜ê²½ ì„¤ì • ê²€í† 
- [ ] í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ê°€ì´ë“œ ì‘ì„±
- [ ] ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì‘ì„±
- [ ] ë¡¤ë°± ê³„íš ìˆ˜ë¦½
- [ ] ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì„¤ì •

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] ë°°í¬ ê°€ì´ë“œ ë¬¸ì„œ ì‘ì„±
- [ ] í™˜ê²½ ì„¤ì • ê²€ì¦ ì™„ë£Œ
- [ ] ë¡¤ë°± ì ˆì°¨ ë¬¸ì„œí™”

---

## ê¸°ìˆ  ìŠ¤íƒ

### í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬

| ë¼ì´ë¸ŒëŸ¬ë¦¬ | ë²„ì „ | ìš©ë„ |
|-----------|------|------|
| LangGraph | 0.6.x | ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜, HITL |
| OpenAI Python | 1.x | LLM í˜¸ì¶œ |
| python-docx | 0.8.x | DOCX ë¬¸ì„œ ìƒì„± |
| PostgreSQL | 16+ | Checkpoint ì €ì¥ |
| pytest | 8.x | ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ |

### í”„ë¡œì íŠ¸ ë‚´ ì˜ì¡´ì„±

| ëª¨ë“ˆ | ê²½ë¡œ | ìš©ë„ |
|------|------|------|
| LLMService | `llm_manager/llm_service.py` | LLM í˜¸ì¶œ ê´€ë¦¬ |
| PromptManager | `llm_manager/prompt_manager.py` | í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ |
| LeaseContractGeneratorTool | `tools/lease_contract_generator_tool.py` | ê³„ì•½ì„œ ìƒì„± |
| HybridLegalSearch | `tools/hybrid_legal_search.py` | ë²•ë¥  ê²€ìƒ‰ |
| RealEstateSearchTool | `tools/real_estate_search_tool.py` | ë¶€ë™ì‚° ê²€ìƒ‰ |

---

## í…ŒìŠ¤íŠ¸ ê³„íš

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

#### 1. planning_node í…ŒìŠ¤íŠ¸
**íŒŒì¼**: `test_document_executor_planning.py`

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤**:
- [ ] ì„ëŒ€ì°¨ ê³„ì•½ì„œ ìš”ì²­ ë¶„ë¥˜
- [ ] ë²•ë¥  ìë¬¸ì„œ ìš”ì²­ ë¶„ë¥˜
- [ ] ì• ë§¤í•œ ìš”ì²­ ì²˜ë¦¬
- [ ] LLM ì‹¤íŒ¨ ì‹œ fallback
- [ ] í•„ìˆ˜ ì •ë³´ ì‹ë³„
- [ ] ê²€ìƒ‰ ì „ëµ ìˆ˜ë¦½

---

#### 2. aggregate_node í…ŒìŠ¤íŠ¸
**íŒŒì¼**: `test_document_executor_aggregate.py`

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤**:
- [ ] Legal DB ê²€ìƒ‰ ì„±ê³µ
- [ ] Real Estate DB ê²€ìƒ‰ ì„±ê³µ
- [ ] ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ fallback
- [ ] LLM ì§‘ê³„ ì •ìƒ ì‘ë™
- [ ] ì¤‘ë³µ ì •ë³´ ì œê±°
- [ ] ëˆ„ë½ í•„ë“œ íƒì§€
- [ ] ì‚¬ìš©ì í”¼ë“œë°± ë³‘í•©

---

#### 3. generate_node í…ŒìŠ¤íŠ¸
**íŒŒì¼**: `test_document_executor_generate.py`

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤**:
- [ ] ì„ëŒ€ì°¨ ê³„ì•½ì„œ DOCX ìƒì„±
- [ ] í•„ë“œ ë§¤í•‘ ì •í™•ì„±
- [ ] ì¼ë°˜ ë¬¸ì„œ í…ìŠ¤íŠ¸ ìƒì„±
- [ ] DOCX ìƒì„± ì‹¤íŒ¨ ì‹œ fallback
- [ ] ë©”íƒ€ë°ì´í„° í¬í•¨ ê²€ì¦
- [ ] team_results êµ¬ì„± ê²€ì¦

---

### í†µí•© í…ŒìŠ¤íŠ¸

#### End-to-End ì‹œë‚˜ë¦¬ì˜¤
**íŒŒì¼**: `test_document_executor_integration.py`

**ì‹œë‚˜ë¦¬ì˜¤ 1: ì„ëŒ€ì°¨ ê³„ì•½ì„œ ìƒì„± (ìŠ¹ì¸)**
```
ì…ë ¥: "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ì„ëŒ€ì°¨ ê³„ì•½ì„œ ì‘ì„±í•´ì¤˜. ë³´ì¦ê¸ˆ 5ì–µ, ì›”ì„¸ 200ë§Œì›"
â†’ planning: lease_contract ë¶„ë¥˜
â†’ aggregate: ê²€ìƒ‰ ë° ì§‘ê³„ â†’ HITL interrupt
â†’ ì‚¬ìš©ì: "ìŠ¹ì¸" ë²„íŠ¼
â†’ generate: DOCX ìƒì„±
â†’ ì¶œë ¥: ê³„ì•½ì„œ DOCX + Markdown

ê²€ì¦:
- DOCX íŒŒì¼ ìƒì„± í™•ì¸
- ë³´ì¦ê¸ˆ, ì›”ì„¸ í•„ë“œ ì •í™•íˆ ì±„ì›Œì§
- ë²•ë¥  í˜•ì‹ ì¤€ìˆ˜
```

**ì‹œë‚˜ë¦¬ì˜¤ 2: ì‚¬ìš©ì ìˆ˜ì • í›„ ìƒì„±**
```
ì…ë ¥: "ì„ëŒ€ì°¨ ê³„ì•½ì„œ ì‘ì„±"
â†’ aggregate: HITL interrupt
â†’ ì‚¬ìš©ì: "ì›”ì„¸ë¥¼ 250ë§Œì›ìœ¼ë¡œ ìˆ˜ì •" ì…ë ¥ + "ìˆ˜ì •" ë²„íŠ¼
â†’ LLMìœ¼ë¡œ í”¼ë“œë°± ë³‘í•©
â†’ generate: ìˆ˜ì •ëœ ê°’ìœ¼ë¡œ DOCX ìƒì„±

ê²€ì¦:
- ì›”ì„¸ 250ë§Œì›ìœ¼ë¡œ ë°˜ì˜
- ë‹¤ë¥¸ í•„ë“œëŠ” ìœ ì§€
```

**ì‹œë‚˜ë¦¬ì˜¤ 3: ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ë³µêµ¬**
```
ì…ë ¥: "ê³„ì•½ì„œ ì‘ì„±"
â†’ planning: ì„±ê³µ
â†’ aggregate: ê²€ìƒ‰ ë„êµ¬ ëª¨ë‘ ì‹¤íŒ¨ â†’ Mock ë°ì´í„° ì‚¬ìš©
â†’ generate: Fallback ë¬¸ì„œ ìƒì„±

ê²€ì¦:
- ì—ëŸ¬ ì—†ì´ ì™„ë£Œ
- Fallback ê²½ê³  í¬í•¨
- ì‚¬ìš©ìì—ê²Œ ì•ˆë‚´ ë©”ì‹œì§€
```

---

### ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

**ì¸¡ì • ì§€í‘œ**:
1. **ì‘ë‹µ ì‹œê°„**
   - Planning: < 3ì´ˆ
   - Aggregate: < 10ì´ˆ
   - Generate: < 12ì´ˆ
   - ì „ì²´: < 25ì´ˆ

2. **í† í° ì‚¬ìš©ëŸ‰**
   - Planning: ~1,000 í† í°
   - Aggregate: ~2,000 í† í°
   - Generate: ~2,500 í† í°
   - ì „ì²´: ~5,500 í† í°

3. **ì„±ê³µë¥ **
   - ì •ìƒ ì¼€ì´ìŠ¤: 95% ì´ìƒ
   - ì—ëŸ¬ ë³µêµ¬: 100% (fallback)

---

## ì¼ì • ë° ë¦¬ì†ŒìŠ¤

### ì „ì²´ ì¼ì •

| Phase | ê¸°ê°„ | ë‹´ë‹¹ì | ìƒíƒœ |
|-------|------|--------|------|
| Phase 1: planning_node | 2ì¼ (Day 1-2) | ê°œë°œì 1ëª… | ì˜ˆì • |
| Phase 2: aggregate_node | 4ì¼ (Day 3-6) | ê°œë°œì 1ëª… | ì˜ˆì • |
| Phase 3: generate_node | 3ì¼ (Day 7-9) | ê°œë°œì 1ëª… | ì˜ˆì • |
| Phase 4: í”„ë¡¬í”„íŠ¸/ì—ëŸ¬ ì²˜ë¦¬ | 1ì¼ (Day 10) | ê°œë°œì 1ëª… | ì˜ˆì • |
| Phase 5: í†µí•© í…ŒìŠ¤íŠ¸ | 2ì¼ (Day 11-12) | ê°œë°œì 1ëª… + QA | ì˜ˆì • |
| Phase 6: ë°°í¬ ì¤€ë¹„ | 1ì¼ (Day 13) | ê°œë°œì 1ëª… + DevOps | ì˜ˆì • |
| **ì´ ê¸°ê°„** | **13ì¼** | - | - |

### ì¶”ê°€ ë²„í¼
- ì˜ˆìƒì¹˜ ëª»í•œ ì´ìŠˆ: +3ì¼
- ì½”ë“œ ë¦¬ë·° ë° ìˆ˜ì •: +2ì¼
- **ìµœì¢… ì˜ˆìƒ ê¸°ê°„**: **18ì¼ (ì•½ 3-4ì£¼)**

---

### í•„ìš” ë¦¬ì†ŒìŠ¤

#### ì¸ë ¥
- **ë°±ì—”ë“œ ê°œë°œì** 1ëª… (Full-time)
- **QA ì—”ì§€ë‹ˆì–´** 0.5ëª… (í…ŒìŠ¤íŠ¸ ê¸°ê°„)
- **ì½”ë“œ ë¦¬ë·°ì–´** 1ëª… (Part-time)

#### ì¸í”„ë¼
- **PostgreSQL ì„œë²„** (Checkpoint ì €ì¥)
- **OpenAI API í¬ë ˆë”§** (í…ŒìŠ¤íŠ¸ìš© ~$50)
- **ê°œë°œ í™˜ê²½** (Python 3.11+)

#### ì™¸ë¶€ ì˜ì¡´ì„±
- OpenAI API ì•ˆì •ì„±
- PostgreSQL ê°€ìš©ì„±
- DOCX í…œí”Œë¦¿ íŒŒì¼ ì¤€ë¹„

---

## ë¦¬ìŠ¤í¬ ê´€ë¦¬

### ì£¼ìš” ë¦¬ìŠ¤í¬

#### 1. LLM ì‘ë‹µ í’ˆì§ˆ ë¶ˆì•ˆì • ğŸ”´ High
**ë¦¬ìŠ¤í¬**:
- LLMì´ JSON í˜•ì‹ ë¯¸ì¤€ìˆ˜
- ì˜ëª»ëœ ì •ë³´ ì¶”ì¶œ
- ì‹ ë¢°ë„ ë‚®ì€ ì‘ë‹µ

**ì™„í™” ë°©ì•ˆ**:
- JSON ëª¨ë“œ ê°•ì œ ì‚¬ìš© (`response_format: json_object`)
- ì‘ë‹µ ê²€ì¦ ë¡œì§ ì¶”ê°€ (JSON schema validation)
- Fallback ë¡œì§ êµ¬í˜„ (ì˜ëª»ëœ ì‘ë‹µ ì‹œ)
- Temperature ë‚®ê²Œ ì„¤ì • (0.2-0.3)

**ë¹„ìƒ ê³„íš**:
- Few-shot ì˜ˆì‹œ ì¶”ê°€
- í”„ë¡¬í”„íŠ¸ ê°œì„  ë°˜ë³µ
- GPT-4 ëª¨ë¸ ì‚¬ìš© ê²€í† 

---

#### 2. ê²€ìƒ‰ ë„êµ¬ ì‹¤íŒ¨ ğŸŸ¡ Medium
**ë¦¬ìŠ¤í¬**:
- Legal DB ë˜ëŠ” Real Estate DB ë‹¤ìš´
- ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ
- API íƒ€ì„ì•„ì›ƒ

**ì™„í™” ë°©ì•ˆ**:
- ê° ê²€ìƒ‰ ë„êµ¬ì— try-except ì ìš©
- Mock ë°ì´í„° fallback ìœ ì§€
- íƒ€ì„ì•„ì›ƒ ì„¤ì • (10ì´ˆ)
- ì—ëŸ¬ ë¡œê¹… ê°•í™”

**ë¹„ìƒ ê³„íš**:
- Mock ë°ì´í„°ë¡œë§Œ ì‘ë™
- ì‚¬ìš©ìì—ê²Œ "ì œí•œëœ ì •ë³´" ì•ˆë‚´

---

#### 3. DOCX ìƒì„± ì‹¤íŒ¨ ğŸŸ¡ Medium
**ë¦¬ìŠ¤í¬**:
- `python-docx` ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ê·¸
- í…œí”Œë¦¿ íŒŒì¼ ì†ìƒ
- í•„ë“œ ë§¤í•‘ ì˜¤ë¥˜

**ì™„í™” ë°©ì•ˆ**:
- í…œí”Œë¦¿ íŒŒì¼ ë°±ì—…
- í•„ë“œ ë§¤í•‘ ê²€ì¦ ë¡œì§
- Fallback: í…ìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„±
- DOCX íŒŒì¼ ê²€ì¦ (ìƒì„± í›„)

**ë¹„ìƒ ê³„íš**:
- í…ìŠ¤íŠ¸ ë˜ëŠ” Markdownìœ¼ë¡œ ìƒì„±
- ì‚¬ìš©ìì—ê²Œ ìˆ˜ë™ ì‘ì„± ê°€ì´ë“œ ì œê³µ

---

#### 4. í”„ë¡¬í”„íŠ¸ ìµœì í™” ì‹œê°„ ì´ˆê³¼ ğŸŸ¢ Low
**ë¦¬ìŠ¤í¬**:
- í”„ë¡¬í”„íŠ¸ íŠœë‹ì— ì˜ˆìƒë³´ë‹¤ ë§ì€ ì‹œê°„ ì†Œìš”

**ì™„í™” ë°©ì•ˆ**:
- ì´ˆê¸° í”„ë¡¬í”„íŠ¸ëŠ” ë‹¨ìˆœí•˜ê²Œ ì‹œì‘
- ì ì§„ì ìœ¼ë¡œ ê°œì„ 
- A/B í…ŒìŠ¤íŠ¸ë¡œ íš¨ê³¼ ê²€ì¦

**ë¹„ìƒ ê³„íš**:
- ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¡œ ë°°í¬ í›„ ì ì§„ì  ê°œì„ 

---

#### 5. í†µí•© í…ŒìŠ¤íŠ¸ ë³µì¡ë„ ğŸŸ¡ Medium
**ë¦¬ìŠ¤í¬**:
- HITL ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì–´ë ¤ì›€
- Checkpoint ìƒíƒœ ê²€ì¦ ë³µì¡
- WebSocket í†µí•© í…ŒìŠ¤íŠ¸

**ì™„í™” ë°©ì•ˆ**:
- Mock WebSocket í´ë¼ì´ì–¸íŠ¸ ì‘ì„±
- Checkpoint ê²€ì¦ í—¬í¼ í•¨ìˆ˜
- ë‹¨ê³„ë³„ í…ŒìŠ¤íŠ¸ ë¶„ë¦¬

**ë¹„ìƒ ê³„íš**:
- ìˆ˜ë™ í…ŒìŠ¤íŠ¸ë¡œ ëŒ€ì²´
- í”„ë¡œë•ì…˜ì—ì„œ ëª¨ë‹ˆí„°ë§ ê°•í™”

---

## ì„±ê³µ ì§€í‘œ

### ì •ëŸ‰ì  ì§€í‘œ

| ì§€í‘œ | ëª©í‘œ | ì¸¡ì • ë°©ë²• |
|------|------|----------|
| **ë¬¸ì„œ ìƒì„± ì„±ê³µë¥ ** | 95% ì´ìƒ | (ì„±ê³µ ê±´ìˆ˜ / ì „ì²´ ìš”ì²­) Ã— 100 |
| **í‰ê·  ì‘ë‹µ ì‹œê°„** | 25ì´ˆ ì´ë‚´ | ì „ì²´ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ ì‹œê°„ |
| **LLM ì •í™•ë„** | 80% ì´ìƒ | ìˆ˜ë™ ê²€ì¦ (ìƒ˜í”Œ 100ê±´) |
| **DOCX ìƒì„± ì„±ê³µë¥ ** | 90% ì´ìƒ | (DOCX ì„±ê³µ / ì„ëŒ€ì°¨ ìš”ì²­) Ã— 100 |
| **í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€** | 80% ì´ìƒ | pytest-cov ë¦¬í¬íŠ¸ |
| **í† í° ì‚¬ìš©ëŸ‰** | 6,000 ì´ë‚´ | OpenAI API ë¡œê·¸ |

---

### ì •ì„±ì  ì§€í‘œ

| ì§€í‘œ | í‰ê°€ ê¸°ì¤€ |
|------|----------|
| **ì½”ë“œ í’ˆì§ˆ** | - í•¨ìˆ˜ ë¶„ë¦¬ ëª…í™•<br>- ì£¼ì„ ì¶©ë¶„<br>- ë„¤ì´ë° ì¼ê´€ì„± |
| **ì—ëŸ¬ ì²˜ë¦¬** | - ëª¨ë“  ì˜ˆì™¸ ìƒí™© ì²˜ë¦¬<br>- ì‚¬ìš©ì ì¹œí™”ì  ë©”ì‹œì§€<br>- ë¡œê·¸ ì¶©ë¶„ |
| **ìœ ì§€ë³´ìˆ˜ì„±** | - ëª¨ë“ˆí™” ì˜ ë¨<br>- í™•ì¥ ê°€ëŠ¥í•œ êµ¬ì¡°<br>- ë¬¸ì„œí™” ì™„ë£Œ |
| **ì‚¬ìš©ì ê²½í—˜** | - ì§„í–‰ ìƒí™© ëª…í™•<br>- ì—ëŸ¬ ë©”ì‹œì§€ ì´í•´ ê°€ëŠ¥<br>- HITL íë¦„ ì§ê´€ì  |

---

### ê²€ì¦ ë°©ë²•

#### 1. ìë™ í…ŒìŠ¤íŠ¸
```bash
# ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
pytest backend/tests/service_agent/execution_agents/ -v --cov

# í†µí•© í…ŒìŠ¤íŠ¸
pytest backend/tests/integration/test_document_executor_e2e.py -v
```

#### 2. ìˆ˜ë™ í…ŒìŠ¤íŠ¸
- ì„ëŒ€ì°¨ ê³„ì•½ì„œ ìƒì„± (10ê±´)
- ë²•ë¥  ìë¬¸ì„œ ìƒì„± (5ê±´)
- ì—ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ (5ê±´)
- ì‚¬ìš©ì ìˆ˜ì • ì‹œë‚˜ë¦¬ì˜¤ (5ê±´)

#### 3. ì½”ë“œ ë¦¬ë·°
- [ ] ëª¨ë“  TODO ì œê±°
- [ ] Mock ì½”ë“œ ì œê±° (fallback ì œì™¸)
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ì™„ë£Œ
- [ ] ë¡œê¹… ì¶©ë¶„
- [ ] ì£¼ì„ ëª…í™•

---

## ë¶€ë¡

### A. íŒŒì¼ ë³€ê²½ ìš”ì•½

| íŒŒì¼ | ë³€ê²½ íƒ€ì… | ì£¼ìš” ë³€ê²½ ë‚´ìš© |
|------|----------|----------------|
| `execution_agents/document_executor.py` | Modified | planning_node, aggregate_node, generate_node ê³ ë„í™” |
| `llm_manager/prompts/execution/document_planning.txt` | New | ë¬¸ì„œ ê³„íš í”„ë¡¬í”„íŠ¸ |
| `llm_manager/prompts/execution/document_aggregation.txt` | New | ì •ë³´ ì§‘ê³„ í”„ë¡¬í”„íŠ¸ |
| `llm_manager/prompts/common/common_instruction.txt` | New | ë²”ìš© í”„ë¡¬í”„íŠ¸ |
| `tests/service_agent/execution_agents/test_document_executor_*.py` | New | ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ |
| `tests/integration/test_document_executor_e2e.py` | New | í†µí•© í…ŒìŠ¤íŠ¸ |

---

### B. ì£¼ìš” ì˜ì¡´ì„±

```python
# requirements.txtì— ì¶”ê°€ (ì´ë¯¸ ìˆì„ ìˆ˜ ìˆìŒ)
openai>=1.0.0
python-docx>=0.8.11
langgraph>=0.6.0
psycopg>=3.1.0
pytest>=8.0.0
pytest-asyncio>=0.23.0
pytest-cov>=4.1.0
```

---

### C. í™˜ê²½ ë³€ìˆ˜

```bash
# .env íŒŒì¼
OPENAI_API_KEY=sk-...
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=real_estate
POSTGRES_USER=postgres
POSTGRES_PASSWORD=root1234
```

---

### D. ì°¸ê³  ë¬¸ì„œ

#### ë‚´ë¶€ ë¬¸ì„œ
- `reports/PatchNote/251026_Document_executor_HITL.md` - HITL êµ¬í˜„ ë‚´ì—­
- `backend/app/service_agent/tools/lease_contract_generator_tool.py` - ê³„ì•½ì„œ ìƒì„± ë„êµ¬
- `backend/app/service_agent/llm_manager/llm_service.py` - LLM ì„œë¹„ìŠ¤

#### ì™¸ë¶€ ë¬¸ì„œ
- [LangGraph 0.6 HITL](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/)
- [OpenAI API Docs](https://platform.openai.com/docs/api-reference)
- [python-docx Documentation](https://python-docx.readthedocs.io/)

---

## ë‹¤ìŒ ë‹¨ê³„

### ì¦‰ì‹œ ì‹œì‘ ê°€ëŠ¥í•œ ì‘ì—…
1. [ ] Phase 1 ì‹œì‘: `document_planning.txt` í”„ë¡¬í”„íŠ¸ ì‘ì„±
2. [ ] ê°œë°œ í™˜ê²½ ì„¤ì • í™•ì¸ (OpenAI API í‚¤, PostgreSQL)
3. [ ] Git ë¸Œëœì¹˜ ìƒì„±: `feature/document-executor-enhancement`

### ìŠ¹ì¸ í›„ ì§„í–‰
- [ ] ì‘ì—… ê³„íšì„œ ê²€í†  ë° ìŠ¹ì¸
- [ ] ì¼ì • í™•ì •
- [ ] ë¦¬ì†ŒìŠ¤ í• ë‹¹
- [ ] Kickoff ë¯¸íŒ…

---

**End of Implementation Plan**

**ì‘ì„±**: 2025-10-28
**ê²€í† **: Pending
**ìŠ¹ì¸**: Pending
**ë¬¸ì˜**: Development Team

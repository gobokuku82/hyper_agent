# 3-Tier Hybrid Memory êµ¬í˜„ ê³„íšì„œ (ìµœì¢…)

**ì‘ì„±ì¼**: 2025-10-21
**ë²„ì „**: FINAL IMPLEMENTATION PLAN
**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 3ì‹œê°„ 45ë¶„

---

## ğŸ“‹ êµ¬í˜„ ê°œìš”

### ëª©í‘œ
- 3-Tier ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶• (Short/Mid/Long-term)
- LLM ê¸°ë°˜ ìë™ ìš”ì•½ ìƒì„±
- í† í° íš¨ìœ¨ì ì¸ ë©”ëª¨ë¦¬ ë¡œë“œ

### í˜„ì¬ ìƒíƒœ
- âœ… user_id Integer íƒ€ì… í†µì¼ ì™„ë£Œ
- âœ… chat_sessions.session_metadata (JSONB) ì‚¬ìš© ì¤‘
- âœ… ê¸°ë³¸ ë©”ëª¨ë¦¬ ë¡œë“œ/ì €ì¥ êµ¬í˜„ë¨

---

## Phase 1: ì„¤ì • íŒŒì¼ ìˆ˜ì • (15ë¶„)

### 1-1. config.py ìˆ˜ì •

**íŒŒì¼**: `backend/app/core/config.py`

**í˜„ì¬ Line 1-2**:
```python
from typing import List
from pydantic_settings import BaseSettings
```

**ìˆ˜ì • í›„ Line 1-3**:
```python
from typing import List
from pydantic import Field  # â† ì¶”ê°€
from pydantic_settings import BaseSettings
```

**í˜„ì¬ Line 31**:
```python
MEMORY_LOAD_LIMIT: int = 5  # Number of recent memories to load per user
```

**ìˆ˜ì •: Line 31 ì´í›„ ì¶”ê°€**:
```python
MEMORY_LOAD_LIMIT: int = 5  # ê¸°ì¡´ ìœ ì§€

# === 3-Tier Memory Configuration ===
SHORTTERM_MEMORY_LIMIT: int = Field(
    default=5,
    description="ìµœê·¼ Nê°œ ì„¸ì…˜ ì „ì²´ ë©”ì‹œì§€ ë¡œë“œ"
)

MIDTERM_MEMORY_LIMIT: int = Field(
    default=5,
    description="ì¤‘ê¸° ë©”ëª¨ë¦¬ ì„¸ì…˜ ìˆ˜ (6-10ë²ˆì§¸)"
)

LONGTERM_MEMORY_LIMIT: int = Field(
    default=10,
    description="ì¥ê¸° ë©”ëª¨ë¦¬ ì„¸ì…˜ ìˆ˜ (11-20ë²ˆì§¸)"
)

MEMORY_TOKEN_LIMIT: int = Field(
    default=2000,
    description="ë©”ëª¨ë¦¬ ë¡œë“œ ì‹œ ìµœëŒ€ í† í° ì œí•œ"
)

MEMORY_MESSAGE_LIMIT: int = Field(
    default=10,
    description="Short-term ì„¸ì…˜ë‹¹ ìµœëŒ€ ë©”ì‹œì§€ ìˆ˜"
)

SUMMARY_MAX_LENGTH: int = Field(
    default=200,
    description="LLM ìš”ì•½ ìµœëŒ€ ê¸€ì ìˆ˜"
)
```

### 1-2. .env íŒŒì¼ ìˆ˜ì •

**íŒŒì¼**: `backend/.env`

**í˜„ì¬**:
```bash
# === Long-term Memory Configuration ===
MEMORY_LOAD_LIMIT=5
```

**ì¶”ê°€**:
```bash
# === Long-term Memory Configuration ===
MEMORY_LOAD_LIMIT=5

# === 3-Tier Memory Configuration ===
SHORTTERM_MEMORY_LIMIT=5
MIDTERM_MEMORY_LIMIT=5
LONGTERM_MEMORY_LIMIT=10
MEMORY_TOKEN_LIMIT=2000
MEMORY_MESSAGE_LIMIT=10
SUMMARY_MAX_LENGTH=200
```

### 1-3. ê²€ì¦
```bash
# ì„œë²„ ì¬ì‹œì‘ í›„
python -c "from app.core.config import settings; print(settings.SHORTTERM_MEMORY_LIMIT)"
# ì¶œë ¥: 5
```

---

## Phase 2: ë©”ëª¨ë¦¬ ì„œë¹„ìŠ¤ í™•ì¥ (1ì‹œê°„ 20ë¶„)

### 2-1. import ì¶”ê°€

**íŒŒì¼**: `backend/app/service_agent/foundation/simple_memory_service.py`

**í˜„ì¬ Line 5-8**:
```python
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
from sqlalchemy import select, desc
```

**ìˆ˜ì • í›„ Line 5-10**:
```python
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
import asyncio  # â† ì¶”ê°€
import tiktoken  # â† ì¶”ê°€
from sqlalchemy import select, desc, and_  # â† and_ ì¶”ê°€
```

### 2-2. ë©”ì„œë“œ ì¶”ê°€ (Line 387 ì´í›„)

#### A. load_tiered_memories() ë©”ì„œë“œ

```python
async def load_tiered_memories(
    self,
    user_id: int,
    current_session_id: Optional[str] = None
) -> Dict[str, List[Dict[str, Any]]]:
    """
    3-Tier êµ¬ì¡°ì˜ ë©”ëª¨ë¦¬ ë¡œë“œ

    Returns:
        {
            "shortterm": [...],  # 1-5 ì„¸ì…˜ ì „ì²´
            "midterm": [...],    # 6-10 ì„¸ì…˜ ìš”ì•½
            "longterm": [...]    # 11-20 ì„¸ì…˜ ìš”ì•½
        }
    """
    from app.core.config import settings

    try:
        # í† í° ì¹´ìš´í„° ì´ˆê¸°í™”
        encoding = tiktoken.get_encoding("cl100k_base")
        total_tokens = 0

        # ìµœê·¼ 20ê°œ ì„¸ì…˜ ì¡°íšŒ (í˜„ì¬ ì„¸ì…˜ ì œì™¸)
        query = select(ChatSession).where(
            and_(
                ChatSession.user_id == user_id,
                ChatSession.session_id != current_session_id if current_session_id else True
            )
        ).order_by(
            ChatSession.updated_at.desc()
        ).limit(20)

        result = await self.db.execute(query)
        sessions = result.scalars().all()

        tiered_memories = {
            "shortterm": [],
            "midterm": [],
            "longterm": []
        }

        for idx, session in enumerate(sessions):
            # í† í° ì œí•œ ì²´í¬
            if total_tokens >= settings.MEMORY_TOKEN_LIMIT:
                logger.info(f"Token limit reached: {total_tokens}")
                break

            if idx < settings.SHORTTERM_MEMORY_LIMIT:
                # Short-term: ì „ì²´ ë©”ì‹œì§€ (1-5ë²ˆì§¸)
                messages_query = select(ChatMessage).where(
                    ChatMessage.session_id == session.session_id
                ).order_by(
                    ChatMessage.created_at.desc()
                ).limit(settings.MEMORY_MESSAGE_LIMIT)

                messages_result = await self.db.execute(messages_query)
                messages = messages_result.scalars().all()

                memory_content = {
                    "session_id": session.session_id,
                    "messages": [
                        {
                            "role": msg.role,
                            "content": msg.content,
                            "timestamp": msg.created_at.isoformat()
                        }
                        for msg in reversed(messages)
                    ],
                    "metadata": session.session_metadata or {},
                    "tier": "shortterm"
                }

                # í† í° ê³„ì‚°
                content_text = " ".join([m["content"] for m in memory_content["messages"]])
                tokens = len(encoding.encode(content_text))
                total_tokens += tokens

                tiered_memories["shortterm"].append(memory_content)

            elif idx < settings.SHORTTERM_MEMORY_LIMIT + settings.MIDTERM_MEMORY_LIMIT:
                # Mid-term: LLM ìš”ì•½ (6-10ë²ˆì§¸)
                summary = await self._get_or_create_summary(session)

                memory_content = {
                    "session_id": session.session_id,
                    "summary": summary[:settings.SUMMARY_MAX_LENGTH],
                    "metadata": session.session_metadata or {},
                    "tier": "midterm"
                }

                # í† í° ê³„ì‚°
                tokens = len(encoding.encode(summary))
                total_tokens += tokens

                tiered_memories["midterm"].append(memory_content)

            else:
                # Long-term: LLM ìš”ì•½ (11-20ë²ˆì§¸)
                summary = await self._get_or_create_summary(session)

                memory_content = {
                    "session_id": session.session_id,
                    "summary": summary[:settings.SUMMARY_MAX_LENGTH],
                    "metadata": session.session_metadata or {},
                    "tier": "longterm"
                }

                # í† í° ê³„ì‚°
                tokens = len(encoding.encode(summary))
                total_tokens += tokens

                tiered_memories["longterm"].append(memory_content)

        logger.info(f"Loaded tiered memories - Tokens: {total_tokens}, "
                   f"Short: {len(tiered_memories['shortterm'])}, "
                   f"Mid: {len(tiered_memories['midterm'])}, "
                   f"Long: {len(tiered_memories['longterm'])}")

        return tiered_memories

    except Exception as e:
        logger.error(f"Error loading tiered memories: {e}")
        return {"shortterm": [], "midterm": [], "longterm": []}
```

#### B. _get_or_create_summary() ë©”ì„œë“œ

```python
async def _get_or_create_summary(self, session: ChatSession) -> str:
    """ì„¸ì…˜ ìš”ì•½ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±"""
    # JSONB metadataì—ì„œ ìš”ì•½ í™•ì¸
    metadata = session.session_metadata or {}

    if metadata.get("conversation_summary"):
        return metadata["conversation_summary"]

    # ìš”ì•½ì´ ì—†ìœ¼ë©´ ìƒì„±
    return await self.summarize_with_llm(session.session_id)
```

#### C. summarize_with_llm() ë©”ì„œë“œ

```python
async def summarize_with_llm(
    self,
    session_id: str,
    max_length: int = 200
) -> str:
    """LLMì„ ì‚¬ìš©í•œ ëŒ€í™” ìš”ì•½ ìƒì„±"""
    from app.service_agent.llm_manager.llm_service import LLMService
    from app.core.config import settings

    try:
        # ë©”ì‹œì§€ ë¡œë“œ
        messages_query = select(ChatMessage).where(
            ChatMessage.session_id == session_id
        ).order_by(ChatMessage.created_at)

        result = await self.db.execute(messages_query)
        messages = result.scalars().all()

        if not messages:
            return "ëŒ€í™” ë‚´ìš© ì—†ìŒ"

        # ëŒ€í™” ë‚´ìš© í¬ë§·íŒ…
        conversation = "\n".join([
            f"{msg.role}: {msg.content[:500]}"
            for msg in messages[-10:]  # ìµœê·¼ 10ê°œë§Œ
        ])

        # LLM ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        llm_service = LLMService()

        # í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜
        variables = {
            "conversation": conversation,
            "max_length": max_length
        }

        # LLM í˜¸ì¶œ
        summary = await llm_service.complete_async(
            prompt_name="conversation_summary",
            variables=variables,
            model="gpt-4o-mini",
            temperature=0.3,
            max_tokens=100
        )

        # ìš”ì•½ ì €ì¥ (ë°±ê·¸ë¼ìš´ë“œ)
        asyncio.create_task(
            self._save_summary_to_metadata(session_id, summary)
        )

        return summary[:max_length]

    except Exception as e:
        logger.error(f"LLM summarization failed: {e}")
        return "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"
```

#### D. _save_summary_to_metadata() ë©”ì„œë“œ

```python
async def _save_summary_to_metadata(
    self,
    session_id: str,
    summary: str
) -> None:
    """ìš”ì•½ì„ metadataì— ì €ì¥ (ë°±ê·¸ë¼ìš´ë“œ)"""
    try:
        # ì„¸ì…˜ ì¡°íšŒ
        query = select(ChatSession).where(
            ChatSession.session_id == session_id
        )
        result = await self.db.execute(query)
        session = result.scalar_one_or_none()

        if not session:
            return

        # metadata ì—…ë°ì´íŠ¸
        if session.session_metadata is None:
            session.session_metadata = {}

        session.session_metadata["conversation_summary"] = summary
        session.session_metadata["summary_method"] = "llm"
        session.session_metadata["summary_updated_at"] = datetime.now().isoformat()

        # JSONB ë³€ê²½ í”Œë˜ê·¸
        flag_modified(session, "session_metadata")

        # DB ì—…ë°ì´íŠ¸
        await self.db.commit()

        logger.info(f"Summary saved for session: {session_id}")

    except Exception as e:
        logger.error(f"Failed to save summary: {e}")
        # ì—ëŸ¬ëŠ” ë¡œê¹…ë§Œ (fire-and-forget)
```

#### E. summarize_conversation_background() ë©”ì„œë“œ

```python
async def summarize_conversation_background(
    self,
    session_id: str,
    user_id: int,
    messages: List[Dict[str, Any]]
) -> None:
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ëŒ€í™” ìš”ì•½"""
    # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ë¡œ ì‹¤í–‰
    asyncio.create_task(
        self._background_summary_task(session_id, user_id, messages)
    )
```

#### F. _background_summary_task() ë©”ì„œë“œ

```python
async def _background_summary_task(
    self,
    session_id: str,
    user_id: int,
    messages: List[Dict[str, Any]]
) -> None:
    """ë°±ê·¸ë¼ìš´ë“œ ìš”ì•½ íƒœìŠ¤í¬"""
    try:
        # LLM ìš”ì•½ ìƒì„±
        summary = await self.summarize_with_llm(session_id)

        # metadata ì €ì¥
        await self._save_summary_to_metadata(session_id, summary)

        logger.info(f"Background summary completed: {session_id}")

    except Exception as e:
        logger.error(f"Background summary failed: {e}")
        # ì—ëŸ¬ëŠ” ë¡œê¹…ë§Œ
```

### 2-3. ê²€ì¦

```python
# Python REPLì—ì„œ í™•ì¸
from app.service_agent.foundation.simple_memory_service import SimpleMemoryService
import inspect

# ë©”ì„œë“œ ì¡´ì¬ í™•ì¸
print(hasattr(SimpleMemoryService, 'load_tiered_memories'))  # True
print(hasattr(SimpleMemoryService, 'summarize_with_llm'))  # True
```

---

## Phase 3: Supervisor í†µí•© (50ë¶„)

### 3-1. planning_node ìˆ˜ì •

**íŒŒì¼**: `backend/app/service_agent/supervisor/team_supervisor.py`

**ìœ„ì¹˜**: Line 235-263 (planning_node ë©”ì„œë“œ ë‚´ë¶€)

**í˜„ì¬ ì½”ë“œ**:
```python
user_id = state.get("user_id")
chat_session_id = state.get("chat_session_id")
if user_id:
    try:
        async for db_session in get_async_db():
            memory_service = LongTermMemoryService(db_session)

            loaded_memories = await memory_service.load_recent_memories(
                user_id=user_id,
                limit=settings.MEMORY_LOAD_LIMIT,
                relevance_filter="RELEVANT",
                session_id=chat_session_id
            )

            user_preferences = await memory_service.get_user_preferences(user_id)

            state["loaded_memories"] = loaded_memories
            state["user_preferences"] = user_preferences
            state["memory_load_time"] = datetime.now().isoformat()

            logger.info(f"Loaded {len(loaded_memories)} memories")
            break
    except Exception as e:
        logger.error(f"Failed to load Long-term Memory: {e}")
```

**ìˆ˜ì • í›„**:
```python
user_id = state.get("user_id")
chat_session_id = state.get("chat_session_id")
if user_id:
    try:
        logger.info(f"Loading 3-Tier Memory for user {user_id}")
        async for db_session in get_async_db():
            memory_service = LongTermMemoryService(db_session)

            # 3-Tier ë©”ëª¨ë¦¬ ë¡œë“œ
            tiered_memories = await memory_service.load_tiered_memories(
                user_id=user_id,
                current_session_id=chat_session_id
            )

            # í•˜ìœ„ í˜¸í™˜ì„±: loaded_memories ìœ ì§€
            loaded_memories = (
                tiered_memories.get("shortterm", []) +
                tiered_memories.get("midterm", []) +
                tiered_memories.get("longterm", [])
            )

            # State ì—…ë°ì´íŠ¸
            state["loaded_memories"] = loaded_memories
            state["tiered_memories"] = tiered_memories  # ì‹ ê·œ í•„ë“œ

            # ì‚¬ìš©ì ì„ í˜¸ë„ ë¡œë“œ (ê¸°ì¡´ ìœ ì§€)
            user_preferences = await memory_service.get_user_preferences(user_id)
            state["user_preferences"] = user_preferences
            state["memory_load_time"] = datetime.now().isoformat()

            # ë¡œê¹…
            logger.info(
                f"3-Tier memories loaded - "
                f"Short({len(tiered_memories.get('shortterm', []))}), "
                f"Mid({len(tiered_memories.get('midterm', []))}), "
                f"Long({len(tiered_memories.get('longterm', []))})"
            )

            break
    except Exception as e:
        logger.error(f"Failed to load tiered memories: {e}")
        state["loaded_memories"] = []
        state["tiered_memories"] = {
            "shortterm": [],
            "midterm": [],
            "longterm": []
        }
```

### 3-2. generate_response_node ìˆ˜ì •

**ìœ„ì¹˜**: Line 870 ê·¼ì²˜ (generate_response_node ë©”ì„œë“œ ë‚´ë¶€)

**í˜„ì¬ ì½”ë“œ**:
```python
user_id = state.get("user_id")
if user_id and intent_type not in ["irrelevant", "unclear"]:
    try:
        async for db_session in get_async_db():
            memory_service = LongTermMemoryService(db_session)

            response_summary = response.get("summary", "")
            if not response_summary and response.get("answer"):
                response_summary = response.get("answer", "")[:200]
            if not response_summary:
                response_summary = f"{response.get('type', 'response')} ìƒì„± ì™„ë£Œ"

            chat_session_id = state.get("chat_session_id")

            await memory_service.save_conversation(
                user_id=user_id,
                session_id=chat_session_id,
                messages=[],
                summary=response_summary
            )

            logger.info("Conversation saved to Long-term Memory")
            break
    except Exception as e:
        logger.error(f"Failed to save Long-term Memory: {e}")
```

**ìˆ˜ì • í›„ (ë°±ê·¸ë¼ìš´ë“œ ìš”ì•½ ì¶”ê°€)**:
```python
user_id = state.get("user_id")
if user_id and intent_type not in ["irrelevant", "unclear"]:
    try:
        logger.info(f"Saving conversation to Long-term Memory for user {user_id}")
        async for db_session in get_async_db():
            memory_service = LongTermMemoryService(db_session)

            chat_session_id = state.get("chat_session_id")

            # ë°±ê·¸ë¼ìš´ë“œ ìš”ì•½ ì‹œì‘ (fire-and-forget)
            await memory_service.summarize_conversation_background(
                session_id=chat_session_id,
                user_id=user_id,
                messages=[]
            )

            # ì‘ë‹µ ìš”ì•½ ìƒì„± (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
            response_summary = response.get("summary", "")
            if not response_summary and response.get("answer"):
                response_summary = response.get("answer", "")[:200]
            if not response_summary:
                response_summary = f"{response.get('type', 'response')} ìƒì„± ì™„ë£Œ"

            # ëŒ€í™” ì €ì¥
            await memory_service.save_conversation(
                user_id=user_id,
                session_id=chat_session_id,
                messages=[],
                summary=response_summary
            )

            logger.info("Conversation saved to Long-term Memory")
            break
    except Exception as e:
        logger.error(f"Failed to save Long-term Memory: {e}")
```

---

## Phase 4: Planning Agent ìˆ˜ì • (30ë¶„)

### 4-1. planning_agent.py ìˆ˜ì •

**íŒŒì¼**: `backend/app/service_agent/cognitive_agents/planning_agent.py`

**ìœ„ì¹˜**: PlanningAgent í´ë˜ìŠ¤ì˜ ì ì ˆí•œ ë©”ì„œë“œ ë‚´ë¶€

**ì¶”ê°€í•  ì½”ë“œ**:
```python
# Stateì—ì„œ 3-Tier ë©”ëª¨ë¦¬ ê°€ì ¸ì˜¤ê¸°
tiered_memories = state.get("tiered_memories", {})

memory_context = ""
if tiered_memories:
    # Short-term: ì „ì²´ ëŒ€í™”
    if tiered_memories.get("shortterm"):
        memory_context += "=== ìµœê·¼ ëŒ€í™” (ì „ì²´) ===\n"
        for mem in tiered_memories["shortterm"]:
            for msg in mem.get("messages", []):
                memory_context += f"{msg['role']}: {msg['content'][:100]}...\n"
            memory_context += "\n"

    # Mid-term: ìš”ì•½
    if tiered_memories.get("midterm"):
        memory_context += "=== ì¤‘ê¸° ëŒ€í™” (ìš”ì•½) ===\n"
        for mem in tiered_memories["midterm"]:
            memory_context += f"- {mem.get('summary', '')}\n"
        memory_context += "\n"

    # Long-term: ìš”ì•½
    if tiered_memories.get("longterm"):
        memory_context += "=== ì¥ê¸° ëŒ€í™” (ìš”ì•½) ===\n"
        for mem in tiered_memories["longterm"]:
            memory_context += f"- {mem.get('summary', '')}\n"

# í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ì— ì¶”ê°€
variables["memory_context"] = memory_context
```

---

## Phase 5: í”„ë¡¬í”„íŠ¸ íŒŒì¼ ìƒì„± (20ë¶„)

### 5-1. conversation_summary.txt ìƒì„±

**íŒŒì¼**: `backend/app/service_agent/llm_manager/prompts/common/conversation_summary.txt`

**ë‚´ìš©**:
```text
ë‹¹ì‹ ì€ ëŒ€í™” ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ ëŒ€í™”ë¥¼ {max_length}ì ì´ë‚´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:

{conversation}

ìš”ì•½ ê·œì¹™:
1. í•µì‹¬ ì£¼ì œì™€ ê²°ë¡ ë§Œ í¬í•¨
2. ì‚¬ìš©ìì˜ ì£¼ìš” ìš”êµ¬ì‚¬í•­ ëª…ì‹œ
3. ì¤‘ìš”í•œ ê²°ì •ì‚¬í•­ì´ë‚˜ í•©ì˜ ë‚´ìš© í¬í•¨
4. ë¶ˆí•„ìš”í•œ ì¸ì‚¬ë§ì´ë‚˜ ë°˜ë³µ ì œì™¸

ìš”ì•½:
```

### 5-2. ê²€ì¦

```python
# Python REPLì—ì„œ í™•ì¸
from app.service_agent.llm_manager.prompt_manager import PromptManager

pm = PromptManager()
prompt = pm.get('conversation_summary', {
    'conversation': 'í…ŒìŠ¤íŠ¸ ëŒ€í™”',
    'max_length': 100
})
print("SUCCESS" if prompt else "FAILED")
```

---

## Phase 6: í…ŒìŠ¤íŠ¸ (50ë¶„)

### 6-1. í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±

**íŒŒì¼**: `backend/test_3tier_memory.py`

**ë‚´ìš©**:
```python
import pytest
import pytest_asyncio
from app.db.postgre_db import get_async_db
from app.service_agent.foundation.simple_memory_service import SimpleMemoryService
from app.core.config import settings

@pytest_asyncio.fixture
async def db_session():
    """ë¹„ë™ê¸° DB ì„¸ì…˜ fixture"""
    async for session in get_async_db():
        yield session
        break

@pytest.mark.asyncio
async def test_3tier_memory_loading(db_session):
    """3-Tier ë©”ëª¨ë¦¬ ë¡œë“œ í…ŒìŠ¤íŠ¸"""
    memory_service = SimpleMemoryService(db_session)

    tiered = await memory_service.load_tiered_memories(
        user_id=1,
        current_session_id="test-session"
    )

    assert "shortterm" in tiered
    assert "midterm" in tiered
    assert "longterm" in tiered

    # ê° í‹°ì–´ê°€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
    assert isinstance(tiered["shortterm"], list)
    assert isinstance(tiered["midterm"], list)
    assert isinstance(tiered["longterm"], list)

@pytest.mark.asyncio
async def test_llm_summarization(db_session):
    """LLM ìš”ì•½ ìƒì„± í…ŒìŠ¤íŠ¸"""
    memory_service = SimpleMemoryService(db_session)

    summary = await memory_service.summarize_with_llm(
        session_id="test-session",
        max_length=200
    )

    assert isinstance(summary, str)
    assert len(summary) <= 200
```

### 6-2. í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# íŠ¹ì • í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰
pytest backend/test_3tier_memory.py::test_3tier_memory_loading -v

# ì „ì²´ í…ŒìŠ¤íŠ¸
pytest backend/test_3tier_memory.py -v
```

---

## ì¶”ê°€: separated_states.py ìˆ˜ì • (ì„ íƒ)

### tiered_memories í•„ë“œ ì¶”ê°€

**íŒŒì¼**: `backend/app/service_agent/foundation/separated_states.py`

**ìœ„ì¹˜**: Line 332 ì´í›„ (MainSupervisorState í´ë˜ìŠ¤)

**ì¶”ê°€**:
```python
# Long-term Memory Fields
user_id: Optional[int]
loaded_memories: Optional[List[Dict[str, Any]]]
user_preferences: Optional[Dict[str, Any]]
memory_load_time: Optional[str]

# 3-Tier Memory (ì‹ ê·œ)
tiered_memories: Optional[Dict[str, List[Dict[str, Any]]]]  # â† ì¶”ê°€
```

---

## ğŸ“‹ êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1: ì„¤ì • (15ë¶„)
- [ ] config.py - Line 2ì— `from pydantic import Field` ì¶”ê°€
- [ ] config.py - Line 31 ì´í›„ 6ê°œ Field ì¶”ê°€
- [ ] .env - 6ê°œ í™˜ê²½ë³€ìˆ˜ ì¶”ê°€
- [ ] ì„œë²„ ì¬ì‹œì‘ í›„ ì„¤ì • ë¡œë“œ í™•ì¸

### Phase 2: ë©”ëª¨ë¦¬ ì„œë¹„ìŠ¤ (1ì‹œê°„ 20ë¶„)
- [ ] simple_memory_service.py - Line 5ì— `import asyncio` ì¶”ê°€
- [ ] simple_memory_service.py - Line 6ì— `import tiktoken` ì¶”ê°€
- [ ] simple_memory_service.py - Line 8ì— `and_` ì¶”ê°€
- [ ] `load_tiered_memories()` ë©”ì„œë“œ ì¶”ê°€
- [ ] `_get_or_create_summary()` ë©”ì„œë“œ ì¶”ê°€
- [ ] `summarize_with_llm()` ë©”ì„œë“œ ì¶”ê°€
- [ ] `_save_summary_to_metadata()` ë©”ì„œë“œ ì¶”ê°€
- [ ] `summarize_conversation_background()` ë©”ì„œë“œ ì¶”ê°€
- [ ] `_background_summary_task()` ë©”ì„œë“œ ì¶”ê°€

### Phase 3: Supervisor (50ë¶„)
- [ ] team_supervisor.py - planning_node (Line 235-263) ìˆ˜ì •
- [ ] team_supervisor.py - generate_response_node (Line 870~) ìˆ˜ì •
- [ ] ë¡œê·¸ë¡œ 3-Tier ë¡œë“œ í™•ì¸

### Phase 4: Planning Agent (30ë¶„)
- [ ] planning_agent.py - tiered_memories í™œìš© ë¡œì§ ì¶”ê°€

### Phase 5: í”„ë¡¬í”„íŠ¸ (20ë¶„)
- [ ] conversation_summary.txt ìƒì„±
- [ ] í”„ë¡¬í”„íŠ¸ ë¡œë“œ í…ŒìŠ¤íŠ¸

### Phase 6: í…ŒìŠ¤íŠ¸ (50ë¶„)
- [ ] test_3tier_memory.py ìƒì„±
- [ ] db_session fixture ì¶”ê°€
- [ ] í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° í†µê³¼ í™•ì¸

### ì„ íƒ: State ì •ì˜ (5ë¶„)
- [ ] separated_states.py - tiered_memories í•„ë“œ ì¶”ê°€

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

### 1. import ë°˜ë“œì‹œ ì¶”ê°€
```python
# simple_memory_service.py ìƒë‹¨
import asyncio
import tiktoken
from sqlalchemy import select, desc, and_
```

### 2. ì •í™•í•œ ìˆ˜ì • ìœ„ì¹˜
- âŒ explore_node (ì¡´ì¬í•˜ì§€ ì•ŠìŒ)
- âœ… planning_node (Line 235-263)
- âŒ execute_node (ì¡´ì¬í•˜ì§€ ì•ŠìŒ)
- âœ… generate_response_node (Line 870~)

### 3. ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜
```python
# ì •í™•í•œ íŒŒë¼ë¯¸í„° ìˆœì„œ
await memory_service.save_conversation(
    user_id=user_id,          # ì²« ë²ˆì§¸
    session_id=chat_session_id,  # ë‘ ë²ˆì§¸
    messages=[],              # ì„¸ ë²ˆì§¸ (conversation_history ì•„ë‹˜!)
    summary=response_summary  # ë„¤ ë²ˆì§¸
)
```

### 4. tiktoken ì„¤ì¹˜
```bash
pip install tiktoken
```

---

## ğŸ“Š ì˜ˆìƒ ì†Œìš” ì‹œê°„

| Phase | ì‘ì—… | ì‹œê°„ |
|-------|------|------|
| Phase 1 | ì„¤ì • íŒŒì¼ | 15ë¶„ |
| Phase 2 | ë©”ëª¨ë¦¬ ì„œë¹„ìŠ¤ | 1ì‹œê°„ 20ë¶„ |
| Phase 3 | Supervisor í†µí•© | 50ë¶„ |
| Phase 4 | Planning Agent | 30ë¶„ |
| Phase 5 | í”„ë¡¬í”„íŠ¸ | 20ë¶„ |
| Phase 6 | í…ŒìŠ¤íŠ¸ | 50ë¶„ |
| **ì´í•©** | | **3ì‹œê°„ 45ë¶„** |

---

## ğŸš€ ì‹œì‘í•˜ê¸°

### ì‚¬ì „ ì¤€ë¹„
```bash
# 1. ë°±ì—… ìƒì„±
cp backend/app/core/config.py backend/app/core/config.py.backup
cp backend/app/service_agent/foundation/simple_memory_service.py backend/app/service_agent/foundation/simple_memory_service.py.backup
cp backend/app/service_agent/supervisor/team_supervisor.py backend/app/service_agent/supervisor/team_supervisor.py.backup
cp backend/.env backend/.env.backup

# 2. ì˜ì¡´ì„± ì„¤ì¹˜
pip install tiktoken pytest-asyncio
```

### êµ¬í˜„ ìˆœì„œ
1. Phase 1ë¶€í„° ìˆœì°¨ì ìœ¼ë¡œ ì§„í–‰
2. ê° Phase ì™„ë£Œ í›„ ì²´í¬ë¦¬ìŠ¤íŠ¸ í™•ì¸
3. Phase 3, 6ì—ì„œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
4. ë¬¸ì œ ë°œìƒ ì‹œ ë°±ì—… íŒŒì¼ë¡œ ë³µêµ¬

---

**ì‘ì„± ì™„ë£Œ**: 2025-10-21
**ë‹¤ìŒ ë‹¨ê³„**: Phase 1ë¶€í„° êµ¬í˜„ ì‹œì‘

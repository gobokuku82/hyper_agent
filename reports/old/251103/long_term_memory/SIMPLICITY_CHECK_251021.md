# 3-Tier Memory 구현 복잡도 재검토

**작성일**: 2025-10-21
**목적**: 사용자 의도 재확인 및 간소화 가능성 분석

---

## 🎯 사용자의 원래 의도 (재확인)

### 핵심 요구사항
- **1-5 세션**: 전체 메시지 전달
- **6-10 세션**: 요약만 전달
- **11-20 세션**: 요약만 전달

### ✅ 계획서 반영 상태

**계획서 Line 184-248 확인 결과**:
```python
if idx < settings.SHORTTERM_MEMORY_LIMIT:  # 1-5번째
    # Short-term: 전체 메시지 ✅
    messages_query = select(ChatMessage).where(...)
    tiered_memories["shortterm"].append({
        "messages": [...],  # 전체 메시지
        "tier": "shortterm"
    })

elif idx < settings.SHORTTERM_MEMORY_LIMIT + settings.MIDTERM_MEMORY_LIMIT:  # 6-10번째
    # Mid-term: LLM 요약만 ✅
    summary = await self._get_or_create_summary(session)
    tiered_memories["midterm"].append({
        "summary": summary,  # 요약만
        "tier": "midterm"
    })

else:  # 11-20번째
    # Long-term: LLM 요약만 ✅
    summary = await self._get_or_create_summary(session)
    tiered_memories["longterm"].append({
        "summary": summary,  # 요약만
        "tier": "longterm"
    })
```

**결론**: ✅ **사용자 의도 100% 정확하게 반영됨**

---

## 🔍 왜 수정사항이 많은가?

### 이유 분석

#### 1. 현재 구조의 한계
**현재 코드** (simple_memory_service.py Line 217-329):
```python
async def load_recent_memories(...):
    # 모든 세션에 대해 "요약만" 로드
    for session in sessions:
        memories.append({
            "summary": metadata["conversation_summary"],  # 요약만
            "timestamp": session.updated_at.isoformat()
        })
```

**문제점**:
- 현재는 **모든 세션에서 요약만** 가져옴
- 1-5 세션의 **전체 메시지를 가져오는 로직이 없음**
- 6-10, 11-20 세션을 구분하는 로직도 없음

#### 2. 필요한 변경사항

| 변경 항목 | 이유 | 필수 여부 |
|----------|------|----------|
| **import tiktoken** | 토큰 카운팅 (2000 제한) | ✅ 필수 |
| **import asyncio** | 백그라운드 요약 | ✅ 필수 |
| **import and_** | 복합 쿼리 조건 | ✅ 필수 |
| **load_tiered_memories()** | 1-5/6-10/11-20 구분 로드 | ✅ 필수 |
| **_get_or_create_summary()** | 요약 캐시 조회 | ✅ 필수 |
| **summarize_with_llm()** | LLM 요약 생성 | ✅ 필수 |
| **_save_summary_to_metadata()** | JSONB 저장 | ✅ 필수 |
| **summarize_conversation_background()** | 백그라운드 실행 | ✅ 필수 |
| **_background_summary_with_new_session()** | 독립 세션 | ✅ 필수 |

---

## 💡 간소화 가능성 분석

### 방안 1: LLM 요약 제거 (❌ 불가능)

**제안**:
- 6-10, 11-20 세션도 전체 메시지 전달
- LLM 요약 없이 구현

**문제점**:
```
1-5 세션: 5 세션 × 10 메시지 × 200 토큰 = 10,000 토큰
6-10 세션: 5 세션 × 10 메시지 × 200 토큰 = 10,000 토큰
11-20 세션: 10 세션 × 10 메시지 × 200 토큰 = 20,000 토큰
--------------------------------------------------------------
총합: 40,000 토큰 → GPT-4 컨텍스트 초과 (128k 토큰 한도)
```

**결론**: ❌ 요약 없이는 불가능 (토큰 제한 초과)

---

### 방안 2: 수동 요약 (❌ 비실용적)

**제안**:
- LLM 대신 단순 잘라내기 (첫 200자)

**문제점**:
```python
summary = messages[-1]["content"][:200]  # 마지막 메시지 200자
```

- 대화의 **핵심을 놓칠 가능성 높음**
- 사용자가 "요약"을 요청한 이유: **문맥 파악을 위해**
- 단순 잘라내기는 문맥 손실

**결론**: ❌ 사용자 경험 크게 저하

---

### 방안 3: 백그라운드 요약 제거 (⚠️ 가능하지만 비효율)

**제안**:
- 요약을 즉시 생성 (백그라운드 X)

**코드**:
```python
# 현재 (백그라운드)
asyncio.create_task(summarize(...))  # 0.1초 (fire-and-forget)

# 간소화 (즉시 실행)
summary = await summarize(...)  # 2-3초 대기
```

**문제점**:
- 사용자 응답 시간 **+2-3초 증가**
- 요약이 필요한 시점: 대화 **완료 후**
- 완료 후 요약하면 **다음 대화에 사용 가능**

**결론**: ⚠️ 가능하지만 성능 저하

---

### 방안 4: 프롬프트 파일 인라인 (⚠️ 가능하지만 유지보수 나쁨)

**제안**:
- conversation_summary.txt 파일 생성 대신 코드에 하드코딩

**코드**:
```python
# 간소화
prompt = """당신은 대화 요약 전문가입니다.
다음 대화를 200자로 요약하세요:
{conversation}
"""

# vs 현재
prompt = self.prompt_manager.get("conversation_summary", variables)
```

**문제점**:
- 프롬프트 수정 시 코드 재배포 필요
- 프롬프트 버전 관리 어려움
- 팀 전체가 프롬프트를 파일로 관리 중

**결론**: ⚠️ 가능하지만 일관성 깨짐

---

## 📊 최종 결론

### ✅ 현재 계획이 최선인 이유

| 요구사항 | 대안 | 결과 |
|---------|------|------|
| **1-5 세션 전체 메시지** | chat_messages 쿼리 | ✅ 필수 |
| **6-20 세션 요약** | LLM 요약 생성 | ✅ 필수 (토큰 제한) |
| **토큰 제한 2000** | tiktoken 카운팅 | ✅ 필수 |
| **백그라운드 요약** | 성능 최적화 | ✅ 권장 (응답 속도) |
| **프롬프트 파일** | 유지보수성 | ✅ 권장 (일관성) |

---

## 🎯 진짜 필수 vs 선택

### ✅ 진짜 필수 (구현 안 하면 안 됨)

1. **load_tiered_memories()** - 1-5/6-10/11-20 구분 로드
2. **summarize_with_llm()** - LLM 요약 생성
3. **import tiktoken** - 토큰 카운팅
4. **conversation_summary.txt** - 요약 프롬프트

**최소 구현 시간**: **1시간 30분**

---

### ⚠️ 선택 (나중에 추가 가능)

1. **백그라운드 요약** → 즉시 실행으로 대체 (성능 -2초)
2. **토큰 제한** → 제한 없이 전체 로드 (위험: 토큰 초과)
3. **_get_or_create_summary()** → 매번 LLM 호출 (비용 증가)

**최소 구현 시 문제**:
- 응답 속도 느림 (-2-3초)
- LLM 비용 증가 (캐시 없음)
- 토큰 초과 가능성

---

## 🔧 간소화된 구현 순서 (최소 버전)

### Phase 1: 설정 (10분)
- [ ] config.py: Field import, 3개 설정만 (SHORTTERM/MIDTERM/LONGTERM_LIMIT)
- [ ] .env: 3개 환경변수만

### Phase 2: 메모리 서비스 (1시간)
- [ ] import tiktoken 추가
- [ ] load_tiered_memories() 추가 (토큰 제한 없는 버전)
- [ ] summarize_with_llm() 추가 (즉시 실행, 백그라운드 X)

### Phase 3: Supervisor (30분)
- [ ] planning_node에 load_tiered_memories() 호출
- [ ] generate_response_node에 즉시 요약 추가

### Phase 4: 프롬프트 (10분)
- [ ] conversation_summary.txt 생성

**최소 구현 시간**: **2시간**

---

## 💬 사용자에게 묻기

### 질문 1: 백그라운드 요약 필요?

**옵션 A**: 백그라운드 요약 (권장)
- 응답 속도: 빠름 (기존과 동일)
- 구현 시간: +30분
- 복잡도: 중간

**옵션 B**: 즉시 요약
- 응답 속도: 느림 (-2초)
- 구현 시간: 짧음
- 복잡도: 낮음

### 질문 2: 토큰 제한 필요?

**옵션 A**: tiktoken으로 2000 토큰 제한 (권장)
- 안정성: 높음
- 구현 시간: +10분
- 복잡도: 낮음

**옵션 B**: 제한 없음
- 안정성: 낮음 (토큰 초과 가능)
- 구현 시간: 짧음
- 복잡도: 낮음

### 질문 3: 요약 캐시 필요?

**옵션 A**: _get_or_create_summary() 캐시 (권장)
- LLM 비용: 낮음 (캐시 재사용)
- 구현 시간: +15분
- 복잡도: 중간

**옵션 B**: 매번 LLM 호출
- LLM 비용: 높음 (매번 요약 생성)
- 구현 시간: 짧음
- 복잡도: 낮음

---

## 🎯 최종 권장사항

### 권장: 현재 계획 그대로 진행

**이유**:
1. 사용자 의도 100% 반영
2. 성능 최적화 (백그라운드 요약)
3. 비용 절감 (요약 캐시)
4. 토큰 안정성 (제한 있음)
5. 유지보수성 (프롬프트 파일)

**예상 시간**: 2시간 50분 (필수만), 3시간 25분 (전체)

---

### 대안: 최소 구현 (권장하지 않음)

**이유**:
- 응답 속도 느림
- LLM 비용 증가
- 토큰 초과 위험

**예상 시간**: 2시간 (최소)

**절약 시간**: 50분 ~ 1시간 25분

---

## 📌 결론

**Q**: 정말 이렇게 복잡하게 해야 하나요?

**A**: 네, **사용자 의도를 정확히 구현하려면 필요합니다**.

**핵심**:
- "1-5 세션 전체, 6-20 세션 요약"은 **단순한 요구사항**
- 하지만 현재 코드는 **"모든 세션 요약만"** 구현됨
- 전체 메시지 로드 + 요약 생성 + 토큰 관리 = **필수 로직**

**간소화 가능 부분**:
- 백그라운드 → 즉시 실행 (-30분, 성능 -2초)
- 토큰 제한 제거 (-10분, 위험)
- 요약 캐시 제거 (-15분, 비용 증가)

**간소화 시 절약**: 50분 ~ 1시간
**간소화 시 손실**: 성능, 안정성, 비용

---

**추천**: 현재 계획 그대로 진행 (2시간 50분)
**대안**: 최소 구현 (2시간) - 비추천

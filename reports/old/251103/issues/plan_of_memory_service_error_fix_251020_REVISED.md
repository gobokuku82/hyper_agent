# Memory Service Implementation Plan - REVISED (ê²€ì¦ ì™„ë£Œ)
## ì‹¤ì œ ì½”ë“œ ë¶„ì„ ê¸°ë°˜ êµ¬í˜„ ê³„íšì„œ

**ì‘ì„±ì¼**: 2025-10-20 (Revised)
**ê¸°ë°˜**: plan_verification_report_251020.md
**í˜„ì¬ ì™„ì„±ë„**: 20%
**ëª©í‘œ**: ë¬¸ë§¥ì´ ì—°ê²°ë˜ëŠ” ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„ (100% ì™„ì„±)

---

## ğŸ“Š Executive Summary

**ê²€ì¦ ë³´ê³ ì„œ ë°˜ì˜**: ì›ë³¸ ê³„íšì„œì—ì„œ ë°œê²¬ëœ 19ê°œ ì´ìŠˆë¥¼ ëª¨ë‘ ìˆ˜ì •í•œ **ì‹¤ì œ êµ¬í˜„ ê°€ëŠ¥í•œ** ê³„íšì„œì…ë‹ˆë‹¤.

### ì£¼ìš” ë³€ê²½ì‚¬í•­
```diff
âœ… Phase 0 ì¶”ê°€: ì‚¬ì „ ì¤€ë¹„ ì‘ì—… (1ì¼)
âœ… Phase 1 ê°„ì†Œí™”: ì»¬ëŸ¼ ì¶”ê°€ ì œê±°, session_metadata í™œìš© (1ì¼)
âœ… Phase 2 ë³´ê°•: User relationship, memory_factory, ë§ˆì´ê·¸ë ˆì´ì…˜ ìˆœì„œ ëª…ì‹œ (5ì¼)
âœ… Phase 3 ì™„ì„±: ë°±í•„ ì „ëµ, consolidate_memories êµ¬í˜„ (7ì¼)
+ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì¶”ê°€
+ ë¡¤ë°± ì „ëµ ì¶”ê°€
+ êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
```

### ê²€ì¦ ê²°ê³¼
- **ì¹˜ëª…ì  ì˜¤ë¥˜ 5ê°œ**: âœ… ëª¨ë‘ ìˆ˜ì •
- **ì¤‘ëŒ€í•œ ëˆ„ë½ 7ê°œ**: âœ… ëª¨ë‘ ë³´ì™„
- **ìˆ˜ì • í•„ìš” 7ê°œ**: âœ… ëª¨ë‘ ê°œì„ 
- **êµ¬í˜„ ê°€ëŠ¥ì„±**: âœ… 100% (ì‹¤ì œ ì½”ë“œ ê¸°ë°˜)

---

## ğŸ¯ 4ë‹¨ê³„ êµ¬í˜„ ì „ëµ (Phase 0~3)

### ì „ì²´ ë¡œë“œë§µ
```
Phase 0 (1ì¼)  â†’ ì‚¬ì „ ì¤€ë¹„ ë° í™˜ê²½ ì„¤ì •              â†’ 20% â†’ 25%
Phase 1 (1ì¼)  â†’ Quick Fix (ê¸°ì¡´ ì»¬ëŸ¼ í™œìš©)          â†’ 25% â†’ 40%
Phase 2 (5ì¼)  â†’ Enhanced Memory (ì „ìš© í…Œì´ë¸”)       â†’ 40% â†’ 70%
Phase 3 (7ì¼)  â†’ Complete System (ë²¡í„° ê²€ìƒ‰)         â†’ 70% â†’ 100%

ì´ ì†Œìš” ê¸°ê°„: 14ì¼ (2ì£¼)
```

---

## ğŸ”§ Phase 0: ì‚¬ì „ ì¤€ë¹„ (1ì¼)
**ëª©í‘œ**: ì•ˆì „í•œ êµ¬í˜„ì„ ìœ„í•œ í™˜ê²½ êµ¬ì¶•

### 0.1 í˜„ì¬ ìƒíƒœ ë°±ì—…

```bash
# 1. ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
pg_dump -U postgres real_estate > backups/backup_$(date +%Y%m%d_%H%M%S).sql

# 2. í˜„ì¬ Git ìƒíƒœ í™•ì¸
cd C:\kdy\Projects\holmesnyangz\beta_v001
git status

# 3. ë°±ì—… ë¸Œëœì¹˜ ìƒì„±
git checkout -b backup/before-memory-service
git add .
git commit -m "Backup before memory service implementation"
git checkout main
```

### 0.2 ê°œë°œ ë¸Œëœì¹˜ ìƒì„±

```bash
# Feature ë¸Œëœì¹˜ ìƒì„±
git checkout -b feature/memory-service-phase0-to-3
```

### 0.3 í…ŒìŠ¤íŠ¸ í™˜ê²½ ì¤€ë¹„

```bash
# í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
psql -U postgres -c "DROP DATABASE IF EXISTS test_real_estate;"
psql -U postgres -c "CREATE DATABASE test_real_estate;"

# í…ŒìŠ¤íŠ¸ DB ìŠ¤í‚¤ë§ˆ ë³µì‚¬
pg_dump -U postgres --schema-only real_estate | psql -U postgres test_real_estate
```

### 0.4 í˜„ì¬ ì½”ë“œ ê²€ì¦

```python
# scripts/verify_current_state.py
"""Phase 0: í˜„ì¬ ìƒíƒœ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸"""

import asyncio
from sqlalchemy import select
from app.db.postgre_db import get_async_db
from app.models.chat import ChatSession, ChatMessage
from app.models.users import User

async def verify_current_state():
    """í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸"""

    print("=" * 50)
    print("Current State Verification")
    print("=" * 50)

    async for db_session in get_async_db():
        # 1. Users í…Œì´ë¸” í™•ì¸
        result = await db_session.execute(select(User).limit(1))
        user = result.scalar_one_or_none()
        print(f"âœ… Users table exists: {user is not None}")

        # 2. ChatSession í…Œì´ë¸” í™•ì¸
        result = await db_session.execute(select(ChatSession).limit(1))
        session = result.scalar_one_or_none()
        print(f"âœ… ChatSession table exists: {session is not None}")

        # 3. ChatMessage í…Œì´ë¸” í™•ì¸
        result = await db_session.execute(select(ChatMessage).limit(1))
        message = result.scalar_one_or_none()
        print(f"âœ… ChatMessage table exists: {message is not None}")

        # 4. ChatSession.session_metadata ì»¬ëŸ¼ í™•ì¸
        if session:
            print(f"âœ… ChatSession.session_metadata exists: {hasattr(session, 'session_metadata')}")
            print(f"   Type: {type(session.session_metadata)}")

        # 5. ChatMessage.structured_data ì»¬ëŸ¼ í™•ì¸
        if message:
            print(f"âœ… ChatMessage.structured_data exists: {hasattr(message, 'structured_data')}")
            print(f"   Type: {type(message.structured_data)}")

        print("=" * 50)
        print("Verification Complete!")
        print("=" * 50)
        break

if __name__ == "__main__":
    asyncio.run(verify_current_state())
```

```bash
# ì‹¤í–‰
cd backend
python scripts/verify_current_state.py
```

**ì˜ˆìƒ ì¶œë ¥**:
```
==================================================
Current State Verification
==================================================
âœ… Users table exists: True
âœ… ChatSession table exists: True
âœ… ChatMessage table exists: True
âœ… ChatSession.session_metadata exists: True
   Type: <class 'dict'>
âœ… ChatMessage.structured_data exists: True
   Type: <class 'dict'>
==================================================
Verification Complete!
==================================================
```

### 0.5 ì²´í¬ë¦¬ìŠ¤íŠ¸

**Phase 0 ì™„ë£Œ ì¡°ê±´**:
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì™„ë£Œ
- [ ] Git ë¸Œëœì¹˜ ìƒì„± ì™„ë£Œ
- [ ] í…ŒìŠ¤íŠ¸ í™˜ê²½ ì¤€ë¹„ ì™„ë£Œ
- [ ] í˜„ì¬ ìƒíƒœ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì„±ê³µ

---

## âš¡ Phase 1: Quick Fix (1ì¼, 40% ì™„ì„±ë„)
**ëª©í‘œ**: ì¦‰ì‹œ ì‘ë™í•˜ëŠ” ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ (ë§ˆì´ê·¸ë ˆì´ì…˜ ì—†ì´)

### í•µì‹¬ ë³€ê²½ì‚¬í•­
```diff
- ChatMessage í…Œì´ë¸”ì— ì»¬ëŸ¼ ì¶”ê°€ (ë§ˆì´ê·¸ë ˆì´ì…˜ í•„ìš”)
+ ChatSession.session_metadata JSONB í™œìš© (ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥)

- ì‚¬ìš©ì ê¸°ë°˜ ë©”ëª¨ë¦¬
+ ì„¸ì…˜ ê¸°ë°˜ ë©”ëª¨ë¦¬ (Phase 2ì—ì„œ ì‚¬ìš©ì ê¸°ë°˜ìœ¼ë¡œ í™•ì¥)
```

### 1.1 SimpleMemoryService ë©”ì„œë“œ êµ¬í˜„

**íŒŒì¼**: `backend/app/service_agent/foundation/simple_memory_service.py`

```python
# ê¸°ì¡´ ì½”ë“œ ìœ ì§€ (Line 1-33)

class SimpleMemoryService:
    """
    ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ì„œë¹„ìŠ¤ (chat_messages ê¸°ë°˜)

    Phase 1: session_metadata í™œìš© (ì»¬ëŸ¼ ì¶”ê°€ ë¶ˆí•„ìš”)
    """

    def __init__(self, db_session: AsyncSession):
        """
        ì´ˆê¸°í™”

        Args:
            db_session: ë¹„ë™ê¸° DB ì„¸ì…˜ (AsyncSession ì¸ìŠ¤í„´ìŠ¤)
        """
        self.db = db_session  # âœ… AsyncSession ì§ì ‘ ì‚¬ìš© (context manager ì•„ë‹˜!)

    # ========================================================================
    # Phase 1: team_supervisor.pyê°€ í˜¸ì¶œí•˜ëŠ” ë©”ì„œë“œ
    # ========================================================================

    async def load_recent_memories(
        self,
        user_id: int,
        limit: int = 5,
        relevance_filter: Optional[str] = "RELEVANT"
    ) -> List[Dict[str, Any]]:
        """
        ìµœê·¼ ëŒ€í™” ê¸°ì–µ ë¡œë“œ (ì„¸ì…˜ ê¸°ë°˜)

        Phase 1: ChatSession.session_metadataì—ì„œ ë¡œë“œ
        Phase 2: ConversationMemory í…Œì´ë¸”ì—ì„œ ë¡œë“œ

        Args:
            user_id: ì‚¬ìš©ì ID
            limit: ë¡œë“œí•  ê°œìˆ˜
            relevance_filter: ê´€ë ¨ì„± í•„í„° (RELEVANT/IRRELEVANT/None)

        Returns:
            ë©”ëª¨ë¦¬ ë¦¬ìŠ¤íŠ¸ [{"query": str, "response": str, ...}]
        """
        try:
            # ChatSessionì„ user_idë¡œ ì¡°íšŒ (ìµœê·¼ ì„¸ì…˜ë“¤)
            query = select(ChatSession).filter(
                ChatSession.user_id == user_id,
                ChatSession.is_active == True
            ).order_by(ChatSession.updated_at.desc()).limit(3)  # ìµœê·¼ 3ê°œ ì„¸ì…˜

            result = await self.db.execute(query)
            sessions = result.scalars().all()

            memories = []
            for session in sessions:
                if not session.session_metadata:
                    continue

                # session_metadata['memories']ì—ì„œ ë©”ëª¨ë¦¬ ì¶”ì¶œ
                session_memories = session.session_metadata.get('memories', [])

                for mem in session_memories:
                    # relevance_filter ì ìš©
                    if relevance_filter and mem.get('relevance') != relevance_filter:
                        continue

                    memories.append({
                        "query": mem.get("query", ""),
                        "response": mem.get("response_summary", ""),
                        "response_summary": mem.get("response_summary", ""),
                        "intent": mem.get("intent"),
                        "entities": mem.get("entities", {}),
                        "timestamp": mem.get("timestamp"),
                        "session_id": session.session_id,
                        "relevance": mem.get("relevance", "NORMAL")
                    })

                    if len(memories) >= limit:
                        break

                if len(memories) >= limit:
                    break

            logger.info(f"Loaded {len(memories)} memories for user {user_id}")
            return memories[:limit]

        except Exception as e:
            logger.error(f"Error loading recent memories: {e}", exc_info=True)
            return []

    async def save_conversation(
        self,
        user_id: int,
        query: str,
        response_summary: str,
        relevance: str = "RELEVANT",
        session_id: Optional[str] = None,
        intent_detected: Optional[str] = None,
        entities_mentioned: Optional[Dict[str, Any]] = None,
        conversation_metadata: Optional[Dict[str, Any]] = None
    ) -> bool:
        """
        ëŒ€í™” ë©”ëª¨ë¦¬ ì €ì¥ (session_metadata í™œìš©)

        Phase 1: ChatSession.session_metadata['memories']ì— ì¶”ê°€
        Phase 2: ConversationMemory í…Œì´ë¸”ì— ì €ì¥

        Args:
            user_id: ì‚¬ìš©ì ID
            query: ì‚¬ìš©ì ì¿¼ë¦¬
            response_summary: ì‘ë‹µ ìš”ì•½
            relevance: ê´€ë ¨ì„± (RELEVANT/IRRELEVANT/NORMAL)
            session_id: ì±„íŒ… ì„¸ì…˜ ID (í•„ìˆ˜)
            intent_detected: ê°ì§€ëœ ì˜ë„
            entities_mentioned: ì–¸ê¸‰ëœ ì—”í‹°í‹°
            conversation_metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°

        Returns:
            bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        try:
            if not session_id:
                logger.warning("save_conversation called without session_id")
                return False

            # ChatSession ì¡°íšŒ
            query_obj = select(ChatSession).filter(
                ChatSession.session_id == session_id
            )
            result = await self.db.execute(query_obj)
            chat_session = result.scalar_one_or_none()

            if not chat_session:
                logger.warning(f"ChatSession {session_id} not found")
                return False

            # session_metadata ì´ˆê¸°í™”
            if not chat_session.session_metadata:
                chat_session.session_metadata = {}

            if 'memories' not in chat_session.session_metadata:
                chat_session.session_metadata['memories'] = []

            # ìƒˆ ë©”ëª¨ë¦¬ ì¶”ê°€
            new_memory = {
                "query": query,
                "response_summary": response_summary,
                "relevance": relevance,
                "intent": intent_detected,
                "entities": entities_mentioned or {},
                "timestamp": datetime.utcnow().isoformat(),
                "user_id": user_id,  # ì¶”ì ìš©
                **(conversation_metadata or {})
            }

            chat_session.session_metadata['memories'].append(new_memory)

            # ìµœì‹  10ê°œë§Œ ìœ ì§€ (ë©”ëª¨ë¦¬ ì ˆì•½)
            chat_session.session_metadata['memories'] = \
                chat_session.session_metadata['memories'][-10:]

            # âœ… JSONB ì»¬ëŸ¼ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ flag_modified
            from sqlalchemy.orm.attributes import flag_modified
            flag_modified(chat_session, 'session_metadata')

            await self.db.commit()

            logger.info(
                f"Saved conversation memory to session {session_id} "
                f"(user_id={user_id}, relevance={relevance})"
            )
            return True

        except Exception as e:
            logger.error(f"Error saving conversation: {e}", exc_info=True)
            await self.db.rollback()
            return False

    async def get_user_preferences(self, user_id: int) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì„ í˜¸ë„ ì¡°íšŒ

        Phase 1: ë¹ˆ dict ë°˜í™˜ (ì„ í˜¸ë„ ê¸°ëŠ¥ ì—†ìŒ)
        Phase 2: UserPreference í…Œì´ë¸”ì—ì„œ ì¡°íšŒ

        Args:
            user_id: ì‚¬ìš©ì ID

        Returns:
            Dict: ì‚¬ìš©ì ì„ í˜¸ë„ (Phase 1ì—ì„œëŠ” ë¹ˆ dict)
        """
        logger.debug(f"get_user_preferences called for user {user_id} (Phase 1: returns empty)")
        return {}

    # ========================================================================
    # ê¸°ì¡´ í˜¸í™˜ì„± ë©”ì„œë“œë“¤ (Deprecated, ë¦¬ë‹¤ì´ë ‰íŠ¸)
    # ========================================================================

    async def load_recent_messages(
        self,
        session_id: str,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        ìµœê·¼ ë©”ì‹œì§€ ë¡œë“œ (chat_messages í…Œì´ë¸”)

        Note: ê¸°ì¡´ ë©”ì„œë“œ, ìœ ì§€
        """
        try:
            query = select(ChatMessage).where(
                ChatMessage.session_id == session_id
            ).order_by(ChatMessage.created_at).limit(limit)

            result = await self.db.execute(query)
            messages = result.scalars().all()

            return [
                {
                    "role": msg.role,
                    "content": msg.content,
                    "created_at": msg.created_at.isoformat()
                }
                for msg in messages
            ]
        except Exception as e:
            logger.error(f"Error loading recent messages: {e}")
            return []

    async def get_conversation_history(
        self,
        session_id: str,
        limit: int = 20
    ) -> str:
        """
        ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

        Note: ê¸°ì¡´ ë©”ì„œë“œ, ìœ ì§€
        """
        messages = await self.load_recent_messages(session_id, limit)

        if not messages:
            return "No conversation history available."

        history_lines = []
        for msg in messages:
            history_lines.append(f"{msg['role']}: {msg['content']}")

        return "\n".join(history_lines)

    # ========================================================================
    # Deprecated í˜¸í™˜ì„± ë©”ì„œë“œ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜)
    # ========================================================================

    async def get_recent_memories(
        self,
        user_id: str,  # âš ï¸ str íƒ€ì… (ê¸°ì¡´ í˜¸í™˜ì„±)
        limit: int = 5
    ) -> List[Dict[str, Any]]:
        """
        Deprecated: load_recent_memories ì‚¬ìš© ê¶Œì¥

        ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
        """
        logger.warning(
            f"get_recent_memories is deprecated. Use load_recent_memories instead. "
            f"(user_id={user_id})"
        )

        # user_idë¥¼ intë¡œ ë³€í™˜
        try:
            user_id_int = int(user_id)
        except (ValueError, TypeError):
            logger.error(f"Invalid user_id: {user_id}")
            return []

        return await self.load_recent_memories(
            user_id=user_id_int,
            limit=limit,
            relevance_filter=None  # í˜¸í™˜ì„±ì„ ìœ„í•´ í•„í„° ì—†ìŒ
        )

    async def save_conversation_memory(
        self,
        session_id: str,
        user_id: str,  # âš ï¸ str íƒ€ì… (ê¸°ì¡´ í˜¸í™˜ì„±)
        user_message: str,
        ai_response: str,
        metadata: Optional[Dict[str, Any]] = None
    ) -> bool:
        """
        Deprecated: save_conversation ì‚¬ìš© ê¶Œì¥

        ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
        """
        logger.warning(
            f"save_conversation_memory is deprecated. Use save_conversation instead. "
            f"(session_id={session_id})"
        )

        # user_idë¥¼ intë¡œ ë³€í™˜
        try:
            user_id_int = int(user_id)
        except (ValueError, TypeError):
            logger.error(f"Invalid user_id: {user_id}")
            return False

        return await self.save_conversation(
            user_id=user_id_int,
            query=user_message,
            response_summary=ai_response[:200],  # ìš”ì•½
            session_id=session_id,
            conversation_metadata=metadata
        )

    async def update_user_preference(
        self,
        user_id: str,
        key: str,
        value: Any
    ) -> bool:
        """Deprecated: Phase 2ì—ì„œ êµ¬í˜„"""
        logger.debug(f"update_user_preference called (no-op): user_id={user_id}, {key}={value}")
        return True

    async def save_entity_memory(
        self,
        user_id: str,
        entity_type: str,
        entity_name: str,
        properties: Dict[str, Any]
    ) -> bool:
        """Deprecated: Phase 2ì—ì„œ êµ¬í˜„"""
        logger.debug(
            f"save_entity_memory called (no-op): "
            f"user_id={user_id}, entity={entity_type}/{entity_name}"
        )
        return True

    async def get_entity_memories(
        self,
        user_id: str,
        entity_type: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """Deprecated: Phase 2ì—ì„œ êµ¬í˜„"""
        logger.debug(f"get_entity_memories called (returns empty): user_id={user_id}")
        return []


# ========================================================================
# í˜¸í™˜ì„± Alias (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜)
# ========================================================================
LongTermMemoryService = SimpleMemoryService
```

### 1.2 í•„ìˆ˜ Import ì¶”ê°€

**íŒŒì¼**: `backend/app/service_agent/foundation/simple_memory_service.py` (ìƒë‹¨)

```python
"""
SimpleMemoryService - Memory í…Œì´ë¸” ì—†ì´ chat_messagesë§Œ ì‚¬ìš©
"""

import logging
from typing import List, Dict, Any, Optional
from datetime import datetime  # âœ… ì¶”ê°€
from sqlalchemy import select, desc
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm.attributes import flag_modified  # âœ… ì¶”ê°€ (JSONB ì—…ë°ì´íŠ¸ìš©)

from app.models.chat import ChatMessage, ChatSession  # âœ… ChatSession ì¶”ê°€

logger = logging.getLogger(__name__)
```

### 1.3 Phase 1 í…ŒìŠ¤íŠ¸

**íŒŒì¼**: `tests/test_simple_memory_phase1.py` (ì‹ ê·œ)

```python
"""
Phase 1 Memory Service í…ŒìŠ¤íŠ¸
"""

import pytest
from datetime import datetime
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker
from app.models.users import User
from app.models.chat import ChatSession, ChatMessage
from app.service_agent.foundation.simple_memory_service import SimpleMemoryService
from app.db.postgre_db import Base

# í…ŒìŠ¤íŠ¸ìš© DB
TEST_DATABASE_URL = "postgresql+asyncpg://postgres:postgres@localhost/test_real_estate"


@pytest.fixture
async def async_session():
    """í…ŒìŠ¤íŠ¸ìš© AsyncSession"""
    engine = create_async_engine(TEST_DATABASE_URL, echo=False)

    # í…Œì´ë¸” ìƒì„±
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)

    async_session_maker = async_sessionmaker(
        engine,
        class_=AsyncSession,
        expire_on_commit=False
    )

    async with async_session_maker() as session:
        yield session

    # ì •ë¦¬
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.drop_all)

    await engine.dispose()


@pytest.fixture
async def test_user(async_session):
    """í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì ìƒì„±"""
    from app.models.users import UserType

    user = User(
        id=1,
        email="test@example.com",
        type=UserType.USER,
        is_active=True
    )
    async_session.add(user)
    await async_session.commit()
    await async_session.refresh(user)
    return user


@pytest.fixture
async def test_session(async_session, test_user):
    """í…ŒìŠ¤íŠ¸ ì±„íŒ… ì„¸ì…˜ ìƒì„±"""
    chat_session = ChatSession(
        session_id="test_session_123",
        user_id=test_user.id,
        title="í…ŒìŠ¤íŠ¸ ì„¸ì…˜",
        session_metadata={}
    )
    async_session.add(chat_session)
    await async_session.commit()
    await async_session.refresh(chat_session)
    return chat_session


@pytest.mark.asyncio
async def test_save_conversation(async_session, test_user, test_session):
    """ëŒ€í™” ì €ì¥ í…ŒìŠ¤íŠ¸"""
    # Given
    service = SimpleMemoryService(async_session)

    # When
    result = await service.save_conversation(
        user_id=test_user.id,
        query="ê°•ë‚¨ì—­ ì›ë£¸ ì¶”ì²œí•´ì£¼ì„¸ìš”",
        response_summary="ê°•ë‚¨ì—­ ê·¼ì²˜ ì›ë£¸ 3ê°œë¥¼ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤.",
        relevance="RELEVANT",
        session_id=test_session.session_id,
        intent_detected="property_search",
        entities_mentioned={
            "location": ["ê°•ë‚¨ì—­"],
            "property_type": ["ì›ë£¸"]
        }
    )

    # Then
    assert result is True

    # Verify
    await async_session.refresh(test_session)
    assert 'memories' in test_session.session_metadata
    assert len(test_session.session_metadata['memories']) == 1

    memory = test_session.session_metadata['memories'][0]
    assert memory['query'] == "ê°•ë‚¨ì—­ ì›ë£¸ ì¶”ì²œí•´ì£¼ì„¸ìš”"
    assert memory['relevance'] == "RELEVANT"
    assert "ê°•ë‚¨ì—­" in memory['entities']['location']


@pytest.mark.asyncio
async def test_load_recent_memories(async_session, test_user, test_session):
    """ìµœê·¼ ë©”ëª¨ë¦¬ ë¡œë“œ í…ŒìŠ¤íŠ¸"""
    # Given: ë©”ëª¨ë¦¬ ì €ì¥
    service = SimpleMemoryService(async_session)

    await service.save_conversation(
        user_id=test_user.id,
        query="ê°•ë‚¨ì—­ ì›ë£¸ ì•Œì•„ë´ì¤˜",
        response_summary="ê°•ë‚¨ì—­ ì›ë£¸ ì¶”ì²œí•©ë‹ˆë‹¤",
        relevance="RELEVANT",
        session_id=test_session.session_id
    )

    # When: ë©”ëª¨ë¦¬ ë¡œë“œ
    memories = await service.load_recent_memories(
        user_id=test_user.id,
        limit=5,
        relevance_filter="RELEVANT"
    )

    # Then
    assert len(memories) == 1
    assert memories[0]['query'] == "ê°•ë‚¨ì—­ ì›ë£¸ ì•Œì•„ë´ì¤˜"
    assert memories[0]['relevance'] == "RELEVANT"


@pytest.mark.asyncio
async def test_load_memories_with_filter(async_session, test_user, test_session):
    """ê´€ë ¨ì„± í•„í„°ë§ í…ŒìŠ¤íŠ¸"""
    # Given: RELEVANTì™€ IRRELEVANT ë©”ëª¨ë¦¬ ì €ì¥
    service = SimpleMemoryService(async_session)

    await service.save_conversation(
        user_id=test_user.id,
        query="ê°•ë‚¨ì—­ ì›ë£¸",
        response_summary="ì¶”ì²œí•©ë‹ˆë‹¤",
        relevance="RELEVANT",
        session_id=test_session.session_id
    )

    await service.save_conversation(
        user_id=test_user.id,
        query="ë‚ ì”¨ ì–´ë•Œ?",
        response_summary="ë§‘ìŠµë‹ˆë‹¤",
        relevance="IRRELEVANT",
        session_id=test_session.session_id
    )

    # When: RELEVANTë§Œ ë¡œë“œ
    memories = await service.load_recent_memories(
        user_id=test_user.id,
        limit=5,
        relevance_filter="RELEVANT"
    )

    # Then: IRRELEVANTëŠ” ì œì™¸ë¨
    assert len(memories) == 1
    assert memories[0]['relevance'] == "RELEVANT"
    assert "ê°•ë‚¨ì—­" in memories[0]['query']


@pytest.mark.asyncio
async def test_memory_limit(async_session, test_user, test_session):
    """ë©”ëª¨ë¦¬ ê°œìˆ˜ ì œí•œ í…ŒìŠ¤íŠ¸ (ìµœëŒ€ 10ê°œ)"""
    # Given: 15ê°œ ë©”ëª¨ë¦¬ ì €ì¥
    service = SimpleMemoryService(async_session)

    for i in range(15):
        await service.save_conversation(
            user_id=test_user.id,
            query=f"Query {i}",
            response_summary=f"Response {i}",
            session_id=test_session.session_id
        )

    # When: session_metadata í™•ì¸
    await async_session.refresh(test_session)

    # Then: ìµœì‹  10ê°œë§Œ ìœ ì§€
    assert len(test_session.session_metadata['memories']) == 10

    # ê°€ì¥ ì˜¤ë˜ëœ 5ê°œëŠ” ì‚­ì œë¨
    queries = [m['query'] for m in test_session.session_metadata['memories']]
    assert "Query 0" not in queries
    assert "Query 14" in queries


@pytest.mark.asyncio
async def test_get_user_preferences_phase1(async_session, test_user):
    """Phase 1: ì„ í˜¸ë„ ì¡°íšŒ (ë¹ˆ dict ë°˜í™˜)"""
    # Given
    service = SimpleMemoryService(async_session)

    # When
    preferences = await service.get_user_preferences(test_user.id)

    # Then: Phase 1ì—ì„œëŠ” ë¹ˆ dict
    assert preferences == {}


@pytest.mark.asyncio
async def test_deprecated_methods(async_session, test_user, test_session):
    """Deprecated ë©”ì„œë“œ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸"""
    # Given
    service = SimpleMemoryService(async_session)

    # When: ê¸°ì¡´ ë©”ì„œë“œ í˜¸ì¶œ (str íƒ€ì… user_id)
    result = await service.save_conversation_memory(
        session_id=test_session.session_id,
        user_id=str(test_user.id),  # str íƒ€ì…
        user_message="í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€",
        ai_response="í…ŒìŠ¤íŠ¸ ì‘ë‹µ"
    )

    # Then
    assert result is True

    # When: get_recent_memories (deprecated)
    memories = await service.get_recent_memories(
        user_id=str(test_user.id),  # str íƒ€ì…
        limit=5
    )

    # Then
    assert len(memories) >= 0  # ì‘ë™ì€ í•¨
```

**í…ŒìŠ¤íŠ¸ ì‹¤í–‰**:
```bash
cd backend
pytest tests/test_simple_memory_phase1.py -v
```

### 1.4 Phase 1 ì²´í¬ë¦¬ìŠ¤íŠ¸

**êµ¬í˜„ ì™„ë£Œ ì¡°ê±´**:
- [ ] `simple_memory_service.py` ìˆ˜ì • ì™„ë£Œ
- [ ] `load_recent_memories` êµ¬í˜„ (session_metadata í™œìš©)
- [ ] `save_conversation` êµ¬í˜„ (session_metadata í™œìš©)
- [ ] `flag_modified` import ì¶”ê°€
- [ ] Deprecated ë©”ì„œë“œ ë¦¬ë‹¤ì´ë ‰íŠ¸ êµ¬í˜„
- [ ] í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„± ì™„ë£Œ
- [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] team_supervisor.py ë™ì‘ í™•ì¸ (ìˆ˜ë™ í…ŒìŠ¤íŠ¸)

**ê²€ì¦ ë°©ë²•**:
```bash
# 1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
pytest tests/test_simple_memory_phase1.py -v

# 2. í†µí•© í…ŒìŠ¤íŠ¸ (ì„ íƒ)
python scripts/test_memory_integration.py
```

---

## ğŸš€ Phase 2: Enhanced Memory (5ì¼, 70% ì™„ì„±ë„)
**ëª©í‘œ**: ì‚¬ìš©ì ê¸°ë°˜ ì¥ê¸° ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ

### 2.0 ì‚¬ì „ ì‘ì—…: User ëª¨ë¸ Relationship ì¶”ê°€ â­

**ì´ê²ƒì´ ê°€ì¥ ë¨¼ì €!** User ëª¨ë¸ì— relationshipì„ ì¶”ê°€í•˜ì§€ ì•Šìœ¼ë©´ SQLAlchemy ì´ˆê¸°í™” ì‹¤íŒ¨

**íŒŒì¼**: `backend/app/models/users.py`

```python
# Line 44-50 ìˆ˜ì • (ê¸°ì¡´ relationships ì´í›„)

class User(Base):
    """í†µí•© ì‚¬ìš©ì í…Œì´ë¸”"""
    __tablename__ = "users"
    # ... ê¸°ì¡´ ì»¬ëŸ¼ë“¤

    # Relationships (ê¸°ì¡´)
    profile = relationship("UserProfile", back_populates="user", uselist=False, cascade="all, delete-orphan")
    local_auth = relationship("LocalAuth", back_populates="user", uselist=False, cascade="all, delete-orphan")
    social_auths = relationship("SocialAuth", back_populates="user", cascade="all, delete-orphan")
    favorites = relationship("UserFavorite", back_populates="user", cascade="all, delete-orphan")
    chat_sessions = relationship("ChatSession", back_populates="user", cascade="all, delete-orphan")

    # âœ… Phase 2 ì¶”ê°€: Long-term Memory Relationships
    conversation_memories = relationship(
        "ConversationMemory",
        back_populates="user",
        cascade="all, delete-orphan",
        lazy="select"  # ëª…ì‹œì  ë¡œë”©
    )
    entity_memories = relationship(
        "EntityMemory",
        back_populates="user",
        cascade="all, delete-orphan",
        lazy="select"
    )
    preferences = relationship(
        "UserPreference",
        back_populates="user",
        uselist=False,  # One-to-One
        cascade="all, delete-orphan",
        lazy="select"
    )
```

### 2.1 Memory ëª¨ë¸ íŒŒì¼ ìƒì„±

**íŒŒì¼**: `backend/app/models/memory.py` (ì‹ ê·œ)

```python
"""
Long-term Memory Models for User Conversation History
Stores conversation memories, user preferences, and entity tracking

Phase 2 Implementation
"""

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    TIMESTAMP,
    ForeignKey,
    Index,
    UniqueConstraint
)
from sqlalchemy.dialects.postgresql import UUID, JSONB
from sqlalchemy.orm import relationship
from sqlalchemy.sql import func
from app.db.postgre_db import Base
import uuid


class ConversationMemory(Base):
    """
    ëŒ€í™” ê¸°ë¡ ì €ì¥ (Long-term Memory)

    ì‚¬ìš©ìì˜ ê³¼ê±° ëŒ€í™” ë‚´ìš©ì„ ì €ì¥í•˜ì—¬ ë¬¸ë§¥ ìœ ì§€
    """
    __tablename__ = "conversation_memories"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    user_id = Column(
        Integer,
        ForeignKey("users.id", ondelete="CASCADE"),
        nullable=False,
        index=True,
        comment="ì‚¬ìš©ì ID"
    )

    # ëŒ€í™” ë‚´ìš©
    query = Column(Text, nullable=False, comment="ì‚¬ìš©ì ì¿¼ë¦¬")
    response = Column(Text, nullable=True, comment="ì „ì²´ ì‘ë‹µ (ì„ íƒ)")  # âœ… ì¶”ê°€
    response_summary = Column(Text, nullable=False, comment="ì‘ë‹µ ìš”ì•½")

    # ë¶„ì„ ê²°ê³¼
    relevance = Column(String(20), nullable=False, default="NORMAL", comment="ê´€ë ¨ì„± (RELEVANT/IRRELEVANT/NORMAL)")
    intent_detected = Column(String(50), comment="ê°ì§€ëœ ì˜ë„")
    entities_mentioned = Column(JSONB, default={}, comment="ì–¸ê¸‰ëœ ì—”í‹°í‹°")

    # ë©”íƒ€ë°ì´í„°
    created_at = Column(
        TIMESTAMP(timezone=True),
        server_default=func.now(),
        nullable=False,
        comment="ìƒì„±ì¼"
    )
    updated_at = Column(
        TIMESTAMP(timezone=True),
        server_default=func.now(),
        onupdate=func.now(),
        comment="ìˆ˜ì •ì¼"
    )
    conversation_metadata = Column(JSONB, default={}, comment="ì¶”ê°€ ë©”íƒ€ë°ì´í„°")

    # Dynamic Session ID (ì—°ê²°)
    session_id = Column(
        String(100),
        ForeignKey("chat_sessions.session_id", ondelete="CASCADE"),
        nullable=True,
        index=True,
        comment="ì±„íŒ… ì„¸ì…˜ ID"
    )

    # Relationships
    user = relationship("User", back_populates="conversation_memories")
    chat_session = relationship("ChatSession")

    # Indexes
    __table_args__ = (
        Index('idx_conv_mem_user_created', 'user_id', 'created_at'),
        Index('idx_conv_mem_relevance', 'relevance'),
        Index('idx_conv_mem_session_id', 'session_id'),
    )

    def __repr__(self):
        return f"<ConversationMemory(user_id={self.user_id}, query='{self.query[:50]}...')>"


class UserPreference(Base):
    """
    ì‚¬ìš©ì ì„ í˜¸ë„ ì¶”ì 

    ì‚¬ìš©ìê°€ ë°˜ë³µì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” íŒ¨í„´, ì„ í˜¸í•˜ëŠ” ì‘ë‹µ ìŠ¤íƒ€ì¼ ì €ì¥
    """
    __tablename__ = "user_preferences"

    id = Column(Integer, primary_key=True, autoincrement=True)
    user_id = Column(
        Integer,
        ForeignKey("users.id", ondelete="CASCADE"),
        nullable=False,
        unique=True,  # One preference per user
        comment="ì‚¬ìš©ì ID"
    )

    # ì„ í˜¸ë„ ë°ì´í„° (JSONB)
    preferences = Column(
        JSONB,
        nullable=False,
        default={},
        comment="ì‚¬ìš©ì ì„ í˜¸ë„ JSON"
    )

    # ë©”íƒ€ë°ì´í„°
    created_at = Column(
        TIMESTAMP(timezone=True),
        server_default=func.now(),
        nullable=False,
        comment="ìƒì„±ì¼"
    )
    updated_at = Column(
        TIMESTAMP(timezone=True),
        server_default=func.now(),
        onupdate=func.now(),
        comment="ìˆ˜ì •ì¼"
    )

    # Relationships
    user = relationship("User", back_populates="preferences")

    def __repr__(self):
        return f"<UserPreference(user_id={self.user_id})>"


class EntityMemory(Base):
    """
    ì—”í‹°í‹° ì¶”ì  (ë§¤ë¬¼/ì§€ì—­/ì¤‘ê°œì‚¬)

    ì‚¬ìš©ìê°€ ê³¼ê±°ì— ì–¸ê¸‰í–ˆë˜ íŠ¹ì • ì—”í‹°í‹° ê¸°ë¡
    """
    __tablename__ = "entity_memories"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    user_id = Column(
        Integer,
        ForeignKey("users.id", ondelete="CASCADE"),
        nullable=False,
        index=True,
        comment="ì‚¬ìš©ì ID"
    )

    # ì—”í‹°í‹° ì •ë³´
    entity_type = Column(
        String(50),
        nullable=False,
        comment="ì—”í‹°í‹° íƒ€ì… (property/region/agent)"
    )
    entity_id = Column(String(100), nullable=False, comment="ì—”í‹°í‹° ì‹ë³„ì")  # âœ… ì¶”ê°€
    entity_name = Column(String(200), comment="ì—”í‹°í‹° ì´ë¦„")

    # ì¶”ì  ì •ë³´
    mention_count = Column(Integer, default=1, comment="ì–¸ê¸‰ íšŸìˆ˜")
    first_mentioned_at = Column(  # âœ… ì¶”ê°€
        TIMESTAMP(timezone=True),
        server_default=func.now(),
        nullable=False,
        comment="ì²« ì–¸ê¸‰ì¼"
    )
    last_mentioned_at = Column(
        TIMESTAMP(timezone=True),
        server_default=func.now(),
        onupdate=func.now(),
        comment="ë§ˆì§€ë§‰ ì–¸ê¸‰ì¼"
    )

    # ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸
    entity_context = Column(JSONB, default={}, comment="ì—”í‹°í‹° ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸")  # âœ… entity_data â†’ entity_context

    # Relationships
    user = relationship("User", back_populates="entity_memories")

    # Indexes and Constraints
    __table_args__ = (
        Index('idx_entity_mem_user_type', 'user_id', 'entity_type'),
        Index('idx_entity_mem_entity', 'entity_type', 'entity_id'),
        UniqueConstraint('user_id', 'entity_type', 'entity_id', name='uq_user_entity'),
    )

    def __repr__(self):
        return f"<EntityMemory(user_id={self.user_id}, type={self.entity_type}, name='{self.entity_name}')>"
```

### 2.2 models/__init__.py ì—…ë°ì´íŠ¸

**íŒŒì¼**: `backend/app/models/__init__.py`

```python
from app.models.users import User, UserProfile, LocalAuth, SocialAuth, UserFavorite, UserType, Gender, SocialProvider
from app.models.chat import ChatSession, ChatMessage
from app.models.real_estate import RealEstate, Transaction
from app.models.trust import TrustScore

# âœ… Phase 2 ì¶”ê°€
from app.models.memory import (
    ConversationMemory,
    UserPreference,
    EntityMemory
)

__all__ = [
    # Users
    "User", "UserProfile", "LocalAuth", "SocialAuth", "UserFavorite",
    "UserType", "Gender", "SocialProvider",

    # Chat
    "ChatSession", "ChatMessage",

    # Real Estate
    "RealEstate", "Transaction",

    # Trust
    "TrustScore",

    # âœ… Memory (Phase 2)
    "ConversationMemory",
    "UserPreference",
    "EntityMemory",
]
```

### 2.3 Alembic ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒì„±

```bash
# backend ë””ë ‰í† ë¦¬ì—ì„œ
cd backend

# 1. Alembic í˜„ì¬ ìƒíƒœ í™•ì¸
alembic current

# 2. ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒì„±
alembic revision --autogenerate -m "add_memory_tables_phase2"

# 3. ìƒì„±ëœ ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼ í™•ì¸
# migrations/versions/xxxx_add_memory_tables_phase2.py
```

**ìƒì„±ëœ ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼ ê²€í†  ë° ìˆ˜ì •**:
```python
# migrations/versions/xxxx_add_memory_tables_phase2.py

"""add_memory_tables_phase2

Revision ID: xxxx
Revises: yyyy
Create Date: 2025-10-20

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers
revision = 'xxxx'
down_revision = 'yyyy'
branch_labels = None
depends_on = None


def upgrade():
    # 1. user_preferences (usersë§Œ ì°¸ì¡°, ë¨¼ì € ìƒì„±)
    op.create_table('user_preferences',
        sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
        sa.Column('user_id', sa.Integer(), nullable=False),
        sa.Column('preferences', postgresql.JSONB(astext_type=sa.Text()), nullable=False, server_default='{}'),
        sa.Column('created_at', sa.TIMESTAMP(timezone=True), server_default=sa.text('now()'), nullable=False),
        sa.Column('updated_at', sa.TIMESTAMP(timezone=True), server_default=sa.text('now()')),
        sa.PrimaryKeyConstraint('id'),
        sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
        sa.UniqueConstraint('user_id')
    )

    # 2. conversation_memories (users, chat_sessions ì°¸ì¡°)
    op.create_table('conversation_memories',
        sa.Column('id', postgresql.UUID(as_uuid=True), nullable=False, server_default=sa.text('gen_random_uuid()')),
        sa.Column('user_id', sa.Integer(), nullable=False),
        sa.Column('query', sa.Text(), nullable=False),
        sa.Column('response', sa.Text(), nullable=True),
        sa.Column('response_summary', sa.Text(), nullable=False),
        sa.Column('relevance', sa.String(length=20), nullable=False, server_default='NORMAL'),
        sa.Column('intent_detected', sa.String(length=50)),
        sa.Column('entities_mentioned', postgresql.JSONB(astext_type=sa.Text()), server_default='{}'),
        sa.Column('created_at', sa.TIMESTAMP(timezone=True), server_default=sa.text('now()'), nullable=False),
        sa.Column('updated_at', sa.TIMESTAMP(timezone=True), server_default=sa.text('now()')),
        sa.Column('conversation_metadata', postgresql.JSONB(astext_type=sa.Text()), server_default='{}'),
        sa.Column('session_id', sa.String(length=100)),
        sa.PrimaryKeyConstraint('id'),
        sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
        sa.ForeignKeyConstraint(['session_id'], ['chat_sessions.session_id'], ondelete='CASCADE')
    )
    op.create_index('idx_conv_mem_user_created', 'conversation_memories', ['user_id', 'created_at'])
    op.create_index('idx_conv_mem_relevance', 'conversation_memories', ['relevance'])
    op.create_index('idx_conv_mem_session_id', 'conversation_memories', ['session_id'])

    # 3. entity_memories (usersë§Œ ì°¸ì¡°)
    op.create_table('entity_memories',
        sa.Column('id', postgresql.UUID(as_uuid=True), nullable=False, server_default=sa.text('gen_random_uuid()')),
        sa.Column('user_id', sa.Integer(), nullable=False),
        sa.Column('entity_type', sa.String(length=50), nullable=False),
        sa.Column('entity_id', sa.String(length=100), nullable=False),
        sa.Column('entity_name', sa.String(length=200)),
        sa.Column('mention_count', sa.Integer(), server_default='1'),
        sa.Column('first_mentioned_at', sa.TIMESTAMP(timezone=True), server_default=sa.text('now()'), nullable=False),
        sa.Column('last_mentioned_at', sa.TIMESTAMP(timezone=True), server_default=sa.text('now()')),
        sa.Column('entity_context', postgresql.JSONB(astext_type=sa.Text()), server_default='{}'),
        sa.PrimaryKeyConstraint('id'),
        sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
        sa.UniqueConstraint('user_id', 'entity_type', 'entity_id', name='uq_user_entity')
    )
    op.create_index('idx_entity_mem_user_type', 'entity_memories', ['user_id', 'entity_type'])
    op.create_index('idx_entity_mem_entity', 'entity_memories', ['entity_type', 'entity_id'])


def downgrade():
    # ì—­ìˆœìœ¼ë¡œ ì‚­ì œ
    op.drop_index('idx_entity_mem_entity', table_name='entity_memories')
    op.drop_index('idx_entity_mem_user_type', table_name='entity_memories')
    op.drop_table('entity_memories')

    op.drop_index('idx_conv_mem_session_id', table_name='conversation_memories')
    op.drop_index('idx_conv_mem_relevance', table_name='conversation_memories')
    op.drop_index('idx_conv_mem_user_created', table_name='conversation_memories')
    op.drop_table('conversation_memories')

    op.drop_table('user_preferences')
```

**ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰**:
```bash
# 1. ë°±ì—… (ì¤‘ìš”!)
pg_dump -U postgres real_estate > backups/before_phase2_$(date +%Y%m%d_%H%M%S).sql

# 2. ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
alembic upgrade head

# 3. ê²€ì¦
psql -U postgres -d real_estate -c "
SELECT table_name
FROM information_schema.tables
WHERE table_schema = 'public'
AND table_name IN ('conversation_memories', 'user_preferences', 'entity_memories')
ORDER BY table_name;
"
```

**ì˜ˆìƒ ì¶œë ¥**:
```
      table_name
-----------------------
 conversation_memories
 entity_memories
 user_preferences
(3 rows)
```

### 2.4 EnhancedMemoryService êµ¬í˜„

**íŒŒì¼**: `backend/app/service_agent/foundation/enhanced_memory_service.py` (ì‹ ê·œ)

```python
"""
Enhanced Memory Service (Phase 2)

ConversationMemory, EntityMemory, UserPreference í…Œì´ë¸” í™œìš©
"""

import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
from sqlalchemy import select, desc
from sqlalchemy.ext.asyncio import AsyncSession

from app.models.memory import ConversationMemory, UserPreference, EntityMemory
from app.models.users import User

logger = logging.getLogger(__name__)


class EnhancedMemoryService:
    """
    Phase 2: í–¥ìƒëœ ë©”ëª¨ë¦¬ ì„œë¹„ìŠ¤

    - ConversationMemory í…Œì´ë¸”ì—ì„œ ëŒ€í™” ê¸°ë¡ ê´€ë¦¬
    - EntityMemoryë¡œ ì—”í‹°í‹° ì¶”ì 
    - UserPreferenceë¡œ ì„ í˜¸ë„ í•™ìŠµ
    """

    def __init__(self, db_session: AsyncSession):
        """
        ì´ˆê¸°í™”

        Args:
            db_session: SQLAlchemy AsyncSession
        """
        self.db = db_session

    # ========================================================================
    # team_supervisor.pyê°€ í˜¸ì¶œí•˜ëŠ” ë©”ì„œë“œ
    # ========================================================================

    async def load_recent_memories(
        self,
        user_id: int,
        limit: int = 5,
        relevance_filter: Optional[str] = "RELEVANT"
    ) -> List[Dict[str, Any]]:
        """
        ìµœê·¼ ëŒ€í™” ê¸°ë¡ ë¡œë“œ (ConversationMemory í…Œì´ë¸”)

        Args:
            user_id: ì‚¬ìš©ì ID
            limit: ë¡œë“œí•  ëŒ€í™” ê°œìˆ˜
            relevance_filter: ê´€ë ¨ì„± í•„í„° ("RELEVANT", "IRRELEVANT", "NORMAL", None=ëª¨ë‘)

        Returns:
            List[Dict]: ëŒ€í™” ê¸°ë¡ ë¦¬ìŠ¤íŠ¸
        """
        try:
            query = select(ConversationMemory).where(
                ConversationMemory.user_id == user_id
            )

            # ê´€ë ¨ì„± í•„í„° ì ìš©
            if relevance_filter:
                query = query.where(ConversationMemory.relevance == relevance_filter)

            # ìµœì‹ ìˆœ ì •ë ¬ ë° ì œí•œ
            query = query.order_by(desc(ConversationMemory.created_at)).limit(limit)

            result = await self.db.execute(query)
            memories = result.scalars().all()

            # Dict í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            return [
                {
                    "id": str(memory.id),
                    "query": memory.query,
                    "response": memory.response_summary,  # ìš”ì•½ ì‚¬ìš©
                    "response_summary": memory.response_summary,
                    "relevance": memory.relevance,
                    "intent": memory.intent_detected,
                    "entities": memory.entities_mentioned or {},
                    "timestamp": memory.created_at.isoformat(),
                    "session_id": memory.session_id,
                    "conversation_metadata": memory.conversation_metadata or {}
                }
                for memory in memories
            ]

        except Exception as e:
            logger.error(f"Failed to load recent memories for user {user_id}: {e}", exc_info=True)
            return []

    async def save_conversation(
        self,
        user_id: int,
        query: str,
        response_summary: str,
        relevance: str = "NORMAL",
        session_id: Optional[str] = None,
        intent_detected: Optional[str] = None,
        entities_mentioned: Optional[Dict[str, Any]] = None,
        conversation_metadata: Optional[Dict[str, Any]] = None
    ) -> bool:
        """
        ëŒ€í™” ê¸°ë¡ ì €ì¥ (ConversationMemory í…Œì´ë¸”)

        Args:
            user_id: ì‚¬ìš©ì ID
            query: ì‚¬ìš©ì ì¿¼ë¦¬
            response_summary: ì‘ë‹µ ìš”ì•½ (100-200ì ì •ë„)
            relevance: ê´€ë ¨ì„± ("RELEVANT", "IRRELEVANT", "NORMAL")
            session_id: ì±„íŒ… ì„¸ì…˜ ID
            intent_detected: ê°ì§€ëœ ì˜ë„
            entities_mentioned: ì–¸ê¸‰ëœ ì—”í‹°í‹° (JSONB)
            conversation_metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°

        Returns:
            bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        try:
            new_memory = ConversationMemory(
                user_id=user_id,
                query=query,
                response=None,  # ì „ì²´ ì‘ë‹µì€ ì €ì¥í•˜ì§€ ì•ŠìŒ (ìš©ëŸ‰ ì ˆì•½)
                response_summary=response_summary,
                relevance=relevance,
                session_id=session_id,
                intent_detected=intent_detected,
                entities_mentioned=entities_mentioned or {},
                conversation_metadata=conversation_metadata or {}
            )

            self.db.add(new_memory)
            await self.db.commit()

            logger.info(f"Saved conversation memory for user {user_id} (relevance={relevance})")

            # ì—”í‹°í‹° ì¶”ì  ì—…ë°ì´íŠ¸ (ë¹„ë™ê¸°)
            if entities_mentioned:
                await self._update_entity_tracking(user_id, entities_mentioned)

            return True

        except Exception as e:
            logger.error(f"Failed to save conversation for user {user_id}: {e}", exc_info=True)
            await self.db.rollback()
            return False

    async def get_user_preferences(self, user_id: int) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì„ í˜¸ë„ ì¡°íšŒ

        Args:
            user_id: ì‚¬ìš©ì ID

        Returns:
            Dict: ì‚¬ìš©ì ì„ í˜¸ë„ (ì—†ìœ¼ë©´ ë¹ˆ dict)
        """
        try:
            query = select(UserPreference).where(UserPreference.user_id == user_id)
            result = await self.db.execute(query)
            preference = result.scalar_one_or_none()

            if preference:
                return preference.preferences or {}
            else:
                logger.debug(f"No preferences found for user {user_id}")
                return {}

        except Exception as e:
            logger.error(f"Failed to get user preferences for user {user_id}: {e}", exc_info=True)
            return {}

    async def update_user_preferences(
        self,
        user_id: int,
        preferences_update: Dict[str, Any]
    ) -> bool:
        """
        ì‚¬ìš©ì ì„ í˜¸ë„ ì—…ë°ì´íŠ¸ (ë³‘í•© ë°©ì‹)

        Args:
            user_id: ì‚¬ìš©ì ID
            preferences_update: ì—…ë°ì´íŠ¸í•  ì„ í˜¸ë„ ë°ì´í„°

        Returns:
            bool: ì—…ë°ì´íŠ¸ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ê¸°ì¡´ ì„ í˜¸ë„ ì¡°íšŒ
            query = select(UserPreference).where(UserPreference.user_id == user_id)
            result = await self.db.execute(query)
            preference = result.scalar_one_or_none()

            if preference:
                # ê¸°ì¡´ ì„ í˜¸ë„ ë³‘í•©
                current_prefs = preference.preferences or {}
                current_prefs.update(preferences_update)
                preference.preferences = current_prefs
                preference.updated_at = datetime.utcnow()

                # JSONB ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ flag_modified
                from sqlalchemy.orm.attributes import flag_modified
                flag_modified(preference, 'preferences')
            else:
                # ìƒˆë¡œìš´ ì„ í˜¸ë„ ìƒì„±
                preference = UserPreference(
                    user_id=user_id,
                    preferences=preferences_update
                )
                self.db.add(preference)

            await self.db.commit()
            logger.info(f"Updated preferences for user {user_id}")
            return True

        except Exception as e:
            logger.error(f"Failed to update preferences for user {user_id}: {e}", exc_info=True)
            await self.db.rollback()
            return False

    # ========================================================================
    # ë‚´ë¶€ ë©”ì„œë“œ
    # ========================================================================

    async def _update_entity_tracking(
        self,
        user_id: int,
        entities_mentioned: Dict[str, Any]
    ):
        """
        ì—”í‹°í‹° ì¶”ì  ì—…ë°ì´íŠ¸ (ë‚´ë¶€ ë©”ì„œë“œ)

        entities_mentioned í˜•ì‹ ì˜ˆì‹œ:
        {
            "location": ["ê°•ë‚¨ì—­", "í™ëŒ€"],
            "property_type": ["ì›ë£¸", "íˆ¬ë£¸"],
            "price_range": ["100ë§Œì›"]
        }

        Args:
            user_id: ì‚¬ìš©ì ID
            entities_mentioned: ì–¸ê¸‰ëœ ì—”í‹°í‹°
        """
        try:
            for entity_type, entities in entities_mentioned.items():
                if not isinstance(entities, list):
                    continue

                for entity_name in entities:
                    if not entity_name:
                        continue

                    # entity_id ìƒì„± (ê°„ë‹¨í•œ ì •ê·œí™”)
                    entity_id = f"{entity_type}_{entity_name.lower().replace(' ', '_')}"

                    # ê¸°ì¡´ ì—”í‹°í‹° ì¡°íšŒ
                    query = select(EntityMemory).where(
                        EntityMemory.user_id == user_id,
                        EntityMemory.entity_type == entity_type,
                        EntityMemory.entity_id == entity_id
                    )
                    result = await self.db.execute(query)
                    entity_mem = result.scalar_one_or_none()

                    if entity_mem:
                        # ê¸°ì¡´ ì—”í‹°í‹° ì—…ë°ì´íŠ¸ (mention_count ì¦ê°€)
                        entity_mem.mention_count += 1
                        entity_mem.last_mentioned_at = datetime.utcnow()
                    else:
                        # ìƒˆ ì—”í‹°í‹° ìƒì„±
                        entity_mem = EntityMemory(
                            user_id=user_id,
                            entity_type=entity_type,
                            entity_id=entity_id,
                            entity_name=entity_name,
                            mention_count=1
                        )
                        self.db.add(entity_mem)

            await self.db.commit()
            logger.debug(f"Updated entity tracking for user {user_id}")

        except Exception as e:
            logger.error(f"Failed to update entity tracking for user {user_id}: {e}", exc_info=True)
            await self.db.rollback()

    async def get_entity_history(
        self,
        user_id: int,
        entity_type: Optional[str] = None,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        ì‚¬ìš©ìì˜ ì—”í‹°í‹° ê¸°ë¡ ì¡°íšŒ

        Args:
            user_id: ì‚¬ìš©ì ID
            entity_type: ì—”í‹°í‹° íƒ€ì… í•„í„° (None=ëª¨ë‘)
            limit: ì¡°íšŒ ê°œìˆ˜

        Returns:
            List[Dict]: ì—”í‹°í‹° ê¸°ë¡
        """
        try:
            query = select(EntityMemory).where(EntityMemory.user_id == user_id)

            if entity_type:
                query = query.where(EntityMemory.entity_type == entity_type)

            query = query.order_by(desc(EntityMemory.last_mentioned_at)).limit(limit)

            result = await self.db.execute(query)
            entities = result.scalars().all()

            return [
                {
                    "id": str(entity.id),
                    "entity_type": entity.entity_type,
                    "entity_id": entity.entity_id,
                    "entity_name": entity.entity_name,
                    "mention_count": entity.mention_count,
                    "first_mentioned_at": entity.first_mentioned_at.isoformat(),
                    "last_mentioned_at": entity.last_mentioned_at.isoformat(),
                    "entity_context": entity.entity_context or {}
                }
                for entity in entities
            ]

        except Exception as e:
            logger.error(f"Failed to get entity history for user {user_id}: {e}", exc_info=True)
            return []

    # ========================================================================
    # Deprecated í˜¸í™˜ì„± ë©”ì„œë“œ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜)
    # ========================================================================

    async def get_recent_memories(self, user_id: str, limit: int = 5) -> List[Dict[str, Any]]:
        """Deprecated: load_recent_memories ì‚¬ìš© ê¶Œì¥"""
        try:
            user_id_int = int(user_id)
        except (ValueError, TypeError):
            logger.error(f"Invalid user_id: {user_id}")
            return []

        return await self.load_recent_memories(user_id=user_id_int, limit=limit, relevance_filter=None)

    async def save_conversation_memory(
        self,
        session_id: str,
        user_id: str,
        user_message: str,
        ai_response: str,
        metadata: Optional[Dict[str, Any]] = None
    ) -> bool:
        """Deprecated: save_conversation ì‚¬ìš© ê¶Œì¥"""
        try:
            user_id_int = int(user_id)
        except (ValueError, TypeError):
            logger.error(f"Invalid user_id: {user_id}")
            return False

        return await self.save_conversation(
            user_id=user_id_int,
            query=user_message,
            response_summary=ai_response[:200],
            session_id=session_id,
            conversation_metadata=metadata
        )
```

### 2.5 Memory Service Factory êµ¬í˜„

**íŒŒì¼**: `backend/app/service_agent/foundation/memory_factory.py` (ì‹ ê·œ)

```python
"""
Memory Service Factory

ì„¤ì •ì— ë”°ë¼ ì ì ˆí•œ Memory Serviceë¥¼ ë°˜í™˜
"""

import logging
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.config import settings
from app.service_agent.foundation.simple_memory_service import SimpleMemoryService
from app.service_agent.foundation.enhanced_memory_service import EnhancedMemoryService

logger = logging.getLogger(__name__)


def get_memory_service(db_session: AsyncSession):
    """
    ì„¤ì •ì— ë”°ë¼ ì ì ˆí•œ Memory Service ë°˜í™˜

    í™˜ê²½ ë³€ìˆ˜:
        MEMORY_SERVICE_TYPE: "simple", "enhanced", "complete" (ê¸°ë³¸: simple)

    Args:
        db_session: SQLAlchemy AsyncSession

    Returns:
        Memory Service ì¸ìŠ¤í„´ìŠ¤
    """
    service_type = getattr(settings, 'MEMORY_SERVICE_TYPE', 'simple').lower()

    if service_type == "enhanced":
        logger.info("Using EnhancedMemoryService (Phase 2)")
        return EnhancedMemoryService(db_session)
    elif service_type == "complete":
        # Phase 3ì—ì„œ êµ¬í˜„
        logger.warning("CompleteMemoryService not implemented yet, falling back to Enhanced")
        return EnhancedMemoryService(db_session)
    else:
        # Default: simple
        logger.info("Using SimpleMemoryService (Phase 1)")
        return SimpleMemoryService(db_session)


# Alias for backward compatibility
LongTermMemoryService = get_memory_service
```

### 2.6 config.py ì„¤ì • ì¶”ê°€

**íŒŒì¼**: `backend/app/core/config.py`

```python
# ê¸°ì¡´ ì„¤ì • ì´í›„ ì¶”ê°€

class Settings(BaseSettings):
    # ... ê¸°ì¡´ ì„¤ì •ë“¤

    # âœ… Phase 2 ì¶”ê°€: Memory Service ì„¤ì •
    MEMORY_SERVICE_TYPE: str = "simple"  # "simple", "enhanced", "complete"
    MEMORY_LOAD_LIMIT: int = 5  # ë¡œë“œí•  ë©”ëª¨ë¦¬ ê°œìˆ˜
    MEMORY_RELEVANCE_THRESHOLD: float = 0.7  # Phase 3ì—ì„œ ì‚¬ìš©
    ENABLE_MEMORY_SERVICE: bool = True  # Memory Service í™œì„±í™” ì—¬ë¶€

    class Config:
        env_file = ".env"
        case_sensitive = True


settings = Settings()
```

**í™˜ê²½ ë³€ìˆ˜ ì„¤ì •** (`.env`):
```env
# Memory Service Configuration
MEMORY_SERVICE_TYPE=enhanced  # Phase 2ì—ì„œ "enhanced"ë¡œ ë³€ê²½
MEMORY_LOAD_LIMIT=5
ENABLE_MEMORY_SERVICE=true
```

### 2.7 team_supervisor.py ìˆ˜ì •

**íŒŒì¼**: `backend/app/service_agent/supervisor/team_supervisor.py`

```python
# Line 20 ìˆ˜ì •
# Before
from app.service_agent.foundation.simple_memory_service import LongTermMemoryService

# After
from app.service_agent.foundation.memory_factory import get_memory_service

# Line 208 ìˆ˜ì •
# Before
memory_service = LongTermMemoryService(db_session)

# After
memory_service = get_memory_service(db_session)  # âœ… Factory ì‚¬ìš©
```

### 2.8 Phase 2 ì²´í¬ë¦¬ìŠ¤íŠ¸

**êµ¬í˜„ ì™„ë£Œ ì¡°ê±´**:
- [ ] User ëª¨ë¸ì— relationship ì¶”ê°€
- [ ] `memory.py` ëª¨ë¸ íŒŒì¼ ìƒì„±
- [ ] `models/__init__.py` ì—…ë°ì´íŠ¸
- [ ] Alembic ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒì„± ë° ì‹¤í–‰
- [ ] í…Œì´ë¸” ìƒì„± ê²€ì¦
- [ ] `enhanced_memory_service.py` êµ¬í˜„
- [ ] `memory_factory.py` êµ¬í˜„
- [ ] `config.py` ì„¤ì • ì¶”ê°€
- [ ] `.env` íŒŒì¼ ì—…ë°ì´íŠ¸
- [ ] `team_supervisor.py` ìˆ˜ì •
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼

---

## ğŸ¯ Phase 3: Complete System (7ì¼, 100% ì™„ì„±ë„)
**ëª©í‘œ**: ë²¡í„° ì„ë² ë”© ê¸°ë°˜ Semantic Search

### 3.1 ì˜ì¡´ì„± ì¶”ê°€

**íŒŒì¼**: `pyproject.toml`

```toml
[tool.poetry.dependencies]
# ê¸°ì¡´ ì˜ì¡´ì„±...

# âœ… Phase 3 ì¶”ê°€
chromadb = "==0.4.22"  # ë²¡í„° ìŠ¤í† ì–´
sentence-transformers = "==2.2.2"  # ì„ë² ë”©
numpy = ">=1.24,<2.0"
```

```bash
# ì„¤ì¹˜
cd backend
poetry install
```

### 3.2 ConversationMemory ëª¨ë¸ í™•ì¥

**Alembic ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒì„±**:
```bash
alembic revision -m "add_embedding_columns_phase3"
```

**ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼**:
```python
# migrations/versions/xxxx_add_embedding_columns_phase3.py

def upgrade():
    op.add_column('conversation_memories',
        sa.Column('query_embedding', postgresql.JSONB(), nullable=True, comment="ì¿¼ë¦¬ ì„ë² ë”© ë²¡í„°"))
    op.add_column('conversation_memories',
        sa.Column('embedding_model', sa.String(100), nullable=True, comment="ì„ë² ë”© ëª¨ë¸ëª…"))

def downgrade():
    op.drop_column('conversation_memories', 'embedding_model')
    op.drop_column('conversation_memories', 'query_embedding')
```

**ëª¨ë¸ ì—…ë°ì´íŠ¸** (`memory.py`):
```python
class ConversationMemory(Base):
    # ... ê¸°ì¡´ ì»¬ëŸ¼ë“¤

    # âœ… Phase 3 ì¶”ê°€
    query_embedding = Column(JSONB, comment="ì¿¼ë¦¬ ì„ë² ë”© ë²¡í„° (JSONB ì €ì¥)")
    embedding_model = Column(String(100), comment="ì‚¬ìš©ëœ ì„ë² ë”© ëª¨ë¸")
```

### 3.3 ê¸°ì¡´ ë°ì´í„° ì„ë² ë”© ë°±í•„ ìŠ¤í¬ë¦½íŠ¸

**íŒŒì¼**: `scripts/backfill_embeddings.py` (ì‹ ê·œ)

```python
"""
Phase 2 ë°ì´í„°ì— ì„ë² ë”© ë°±í•„

ê¸°ì¡´ ConversationMemoryì— ì €ì¥ëœ ëŒ€í™”ë“¤ì— ë²¡í„° ì„ë² ë”© ì¶”ê°€
"""

import asyncio
import logging
from sentence_transformers import SentenceTransformer
from sqlalchemy import select
from app.db.postgre_db import get_async_db
from app.models.memory import ConversationMemory

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
EMBEDDING_MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)


async def backfill_embeddings(batch_size: int = 100):
    """Phase 2 ëŒ€í™”ì— ì„ë² ë”© ì¶”ê°€"""

    logger.info("=" * 60)
    logger.info("Starting Embedding Backfill (Phase 3)")
    logger.info("=" * 60)

    async for db_session in get_async_db():
        total_processed = 0

        while True:
            # ì„ë² ë”©ì´ ì—†ëŠ” ëŒ€í™” ì¡°íšŒ
            result = await db_session.execute(
                select(ConversationMemory)
                .filter(ConversationMemory.query_embedding.is_(None))
                .limit(batch_size)
            )
            memories = result.scalars().all()

            if not memories:
                logger.info("No more memories to backfill")
                break

            logger.info(f"Processing batch of {len(memories)} conversations...")

            for memory in memories:
                try:
                    # ì„ë² ë”© ìƒì„±
                    query_embedding = embedding_model.encode(memory.query).tolist()

                    # DB ì—…ë°ì´íŠ¸
                    memory.query_embedding = query_embedding
                    memory.embedding_model = EMBEDDING_MODEL_NAME

                    total_processed += 1

                    if total_processed % 10 == 0:
                        logger.info(f"Processed {total_processed} conversations...")

                except Exception as e:
                    logger.error(f"Failed to process memory {memory.id}: {e}")

            # ë°°ì¹˜ ì»¤ë°‹
            await db_session.commit()
            logger.info(f"Batch committed ({total_processed} total)")

        logger.info("=" * 60)
        logger.info(f"Backfill Complete! Total processed: {total_processed}")
        logger.info("=" * 60)
        break


if __name__ == "__main__":
    asyncio.run(backfill_embeddings())
```

**ì‹¤í–‰**:
```bash
cd backend
python scripts/backfill_embeddings.py
```

### 3.4 CompleteMemoryService êµ¬í˜„

**íŒŒì¼**: `backend/app/service_agent/foundation/complete_memory_service.py` (ì‹ ê·œ)

```python
"""
Complete Memory Service (Phase 3)

ë²¡í„° ì„ë² ë”© ê¸°ë°˜ Semantic Search ì§€ì›
"""

import logging
import numpy as np
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from sentence_transformers import SentenceTransformer
from sqlalchemy import select, desc, delete
from sqlalchemy.ext.asyncio import AsyncSession

from app.models.memory import ConversationMemory, UserPreference, EntityMemory
from app.service_agent.foundation.enhanced_memory_service import EnhancedMemoryService

logger = logging.getLogger(__name__)


class CompleteMemoryService(EnhancedMemoryService):
    """
    Phase 3: ì™„ì „í•œ ë©”ëª¨ë¦¬ ì„œë¹„ìŠ¤

    - Semantic Search (ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰)
    - Memory Consolidation
    - User Preference Learning
    """

    def __init__(self, db_session: AsyncSession, embedding_model_name: str = "sentence-transformers/all-MiniLM-L6-v2"):
        """
        ì´ˆê¸°í™”

        Args:
            db_session: SQLAlchemy AsyncSession
            embedding_model_name: ì„ë² ë”© ëª¨ë¸ ì´ë¦„
        """
        super().__init__(db_session)

        # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        self.embedding_model_name = embedding_model_name
        self.embedding_model = SentenceTransformer(embedding_model_name)
        logger.info(f"Loaded embedding model: {embedding_model_name}")

    async def load_contextual_memories(
        self,
        user_id: int,
        current_query: str,
        limit: int = 5,
        similarity_threshold: float = 0.7
    ) -> List[Dict[str, Any]]:
        """
        ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ëœ ê¸°ì–µ ë¡œë“œ (Semantic Search)

        Args:
            user_id: ì‚¬ìš©ì ID
            current_query: í˜„ì¬ ì¿¼ë¦¬
            limit: ë¡œë“œí•  ê°œìˆ˜
            similarity_threshold: ìœ ì‚¬ë„ ì„ê³„ê°’ (0.0~1.0)

        Returns:
            List[Dict]: ê´€ë ¨ ê¸°ì–µ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # 1. í˜„ì¬ ì¿¼ë¦¬ ì„ë² ë”©
            query_embedding = self.embedding_model.encode(current_query).tolist()

            # 2. ì‚¬ìš©ìì˜ ëª¨ë“  ë©”ëª¨ë¦¬ ì¡°íšŒ (ì„ë² ë”©ì´ ìˆëŠ” ê²ƒë§Œ)
            result = await self.db.execute(
                select(ConversationMemory)
                .where(
                    ConversationMemory.user_id == user_id,
                    ConversationMemory.query_embedding.isnot(None)
                )
                .order_by(desc(ConversationMemory.created_at))
                .limit(100)  # ìµœê·¼ 100ê°œë§Œ
            )
            memories = result.scalars().all()

            if not memories:
                logger.info(f"No memories with embeddings for user {user_id}")
                return []

            # 3. ìœ ì‚¬ë„ ê³„ì‚°
            scored_memories = []
            for memory in memories:
                memory_embedding = memory.query_embedding

                # Cosine similarity
                similarity = self._cosine_similarity(query_embedding, memory_embedding)

                if similarity >= similarity_threshold:
                    scored_memories.append({
                        "memory": memory,
                        "similarity": similarity,
                        "recency_score": self._calculate_recency_score(memory.created_at)
                    })

            # 4. ìœ ì‚¬ë„ + ì‹œê°„ì  ê·¼ì ‘ì„± ê²°í•©
            for item in scored_memories:
                item["final_score"] = (
                    item["similarity"] * 0.7 +  # ìœ ì‚¬ë„ 70%
                    item["recency_score"] * 0.3  # ìµœì‹ ì„± 30%
                )

            # 5. ì ìˆ˜ìˆœ ì •ë ¬
            scored_memories.sort(key=lambda x: x["final_score"], reverse=True)

            # 6. ìƒìœ„ Nê°œ ë°˜í™˜
            results = []
            for item in scored_memories[:limit]:
                memory = item["memory"]
                results.append({
                    "id": str(memory.id),
                    "query": memory.query,
                    "response": memory.response_summary,
                    "response_summary": memory.response_summary,
                    "relevance": memory.relevance,
                    "intent": memory.intent_detected,
                    "entities": memory.entities_mentioned or {},
                    "timestamp": memory.created_at.isoformat(),
                    "session_id": memory.session_id,
                    "similarity": item["similarity"],
                    "final_score": item["final_score"]
                })

            logger.info(f"Found {len(results)} contextually relevant memories for user {user_id}")
            return results

        except Exception as e:
            logger.error(f"Failed to load contextual memories: {e}", exc_info=True)
            # Fallback to Phase 2 ë°©ì‹
            return await super().load_recent_memories(user_id, limit, "RELEVANT")

    async def save_conversation(
        self,
        user_id: int,
        query: str,
        response_summary: str,
        **kwargs
    ) -> bool:
        """
        ëŒ€í™” ì €ì¥ + ì„ë² ë”© ìƒì„±

        Phase 3: query_embedding ìë™ ìƒì„±
        """
        try:
            # ì„ë² ë”© ìƒì„±
            query_embedding = self.embedding_model.encode(query).tolist()

            # ConversationMemory ìƒì„±
            new_memory = ConversationMemory(
                user_id=user_id,
                query=query,
                response=None,
                response_summary=response_summary,
                relevance=kwargs.get('relevance', 'NORMAL'),
                session_id=kwargs.get('session_id'),
                intent_detected=kwargs.get('intent_detected'),
                entities_mentioned=kwargs.get('entities_mentioned', {}),
                conversation_metadata=kwargs.get('conversation_metadata', {}),
                query_embedding=query_embedding,  # âœ… ì„ë² ë”© ì¶”ê°€
                embedding_model=self.embedding_model_name
            )

            self.db.add(new_memory)
            await self.db.commit()

            logger.info(f"Saved conversation with embedding for user {user_id}")

            # ì—”í‹°í‹° ì¶”ì 
            if kwargs.get('entities_mentioned'):
                await self._update_entity_tracking(user_id, kwargs['entities_mentioned'])

            return True

        except Exception as e:
            logger.error(f"Failed to save conversation: {e}", exc_info=True)
            await self.db.rollback()
            return False

    async def consolidate_memories(self, user_id: int):
        """
        ë‹¨ê¸° ê¸°ì–µ í†µí•© (ì•¼ê°„ ë°°ì¹˜ ì‘ì—…ìš©)

        ì‘ì—…:
        1. ì˜¤ë˜ëœ IRRELEVANT ë©”ëª¨ë¦¬ ì‚­ì œ (7ì¼ ì´ìƒ)
        2. ìì£¼ ì–¸ê¸‰ëœ ì—”í‹°í‹° â†’ ì„ í˜¸ë„ ì—…ë°ì´íŠ¸
        3. ë©”ëª¨ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸
        """
        try:
            logger.info(f"Starting memory consolidation for user {user_id}")

            # 1. ì˜¤ë˜ëœ IRRELEVANT ë©”ëª¨ë¦¬ ì •ë¦¬
            cutoff_date = datetime.utcnow() - timedelta(days=7)

            delete_result = await self.db.execute(
                delete(ConversationMemory)
                .where(
                    ConversationMemory.user_id == user_id,
                    ConversationMemory.relevance == "IRRELEVANT",
                    ConversationMemory.created_at < cutoff_date
                )
            )
            deleted_count = delete_result.rowcount
            logger.info(f"Deleted {deleted_count} old IRRELEVANT memories")

            # 2. ìì£¼ ì–¸ê¸‰ëœ ì—”í‹°í‹° â†’ ì„ í˜¸ë„
            result = await self.db.execute(
                select(EntityMemory)
                .where(EntityMemory.user_id == user_id)
                .order_by(desc(EntityMemory.mention_count))
                .limit(10)
            )
            top_entities = result.scalars().all()

            if top_entities:
                # UserPreference ì—…ë°ì´íŠ¸
                preferences = await self.get_user_preferences(user_id)

                preferences['frequently_mentioned'] = [
                    {
                        "type": e.entity_type,
                        "name": e.entity_name,
                        "count": e.mention_count
                    }
                    for e in top_entities
                ]

                preferences['last_consolidation'] = datetime.utcnow().isoformat()

                await self.update_user_preferences(user_id, preferences)
                logger.info(f"Updated preferences with top {len(top_entities)} entities")

            await self.db.commit()
            logger.info(f"Memory consolidation complete for user {user_id}")

        except Exception as e:
            logger.error(f"Failed to consolidate memories: {e}", exc_info=True)
            await self.db.rollback()

    # ========================================================================
    # ë‚´ë¶€ ìœ í‹¸ë¦¬í‹°
    # ========================================================================

    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """
        Cosine Similarity ê³„ì‚°

        Args:
            vec1: ë²¡í„° 1
            vec2: ë²¡í„° 2

        Returns:
            float: ìœ ì‚¬ë„ (0.0 ~ 1.0)
        """
        try:
            arr1 = np.array(vec1)
            arr2 = np.array(vec2)

            dot_product = np.dot(arr1, arr2)
            norm1 = np.linalg.norm(arr1)
            norm2 = np.linalg.norm(arr2)

            if norm1 == 0 or norm2 == 0:
                return 0.0

            return float(dot_product / (norm1 * norm2))

        except Exception as e:
            logger.error(f"Failed to calculate cosine similarity: {e}")
            return 0.0

    def _calculate_recency_score(self, created_at: datetime) -> float:
        """
        ì‹œê°„ì  ê·¼ì ‘ì„± ì ìˆ˜ ê³„ì‚°

        Args:
            created_at: ìƒì„± ì‹œê°„

        Returns:
            float: ìµœì‹ ì„± ì ìˆ˜ (0.0 ~ 1.0)
        """
        try:
            now = datetime.utcnow()

            # Timezone-aware comparison
            if created_at.tzinfo is not None:
                from datetime import timezone
                now = now.replace(tzinfo=timezone.utc)

            time_diff = (now - created_at).total_seconds()
            days_diff = time_diff / 86400  # ì´ˆ â†’ ì¼

            # ì§€ìˆ˜ ê°ì‡  (30ì¼ ë°˜ê°ê¸°)
            score = np.exp(-days_diff / 30)

            return float(score)

        except Exception as e:
            logger.error(f"Failed to calculate recency score: {e}")
            return 0.5  # ê¸°ë³¸ê°’
```

### 3.5 memory_factory.py ì—…ë°ì´íŠ¸

```python
# complete_memory_service import ì¶”ê°€
from app.service_agent.foundation.complete_memory_service import CompleteMemoryService

def get_memory_service(db_session: AsyncSession):
    """ì„¤ì •ì— ë”°ë¼ Memory Service ë°˜í™˜"""
    service_type = getattr(settings, 'MEMORY_SERVICE_TYPE', 'simple').lower()

    if service_type == "complete":
        logger.info("Using CompleteMemoryService (Phase 3)")
        return CompleteMemoryService(db_session)  # âœ… Phase 3
    elif service_type == "enhanced":
        logger.info("Using EnhancedMemoryService (Phase 2)")
        return EnhancedMemoryService(db_session)
    else:
        logger.info("Using SimpleMemoryService (Phase 1)")
        return SimpleMemoryService(db_session)
```

### 3.6 Phase 3 ì²´í¬ë¦¬ìŠ¤íŠ¸

**êµ¬í˜„ ì™„ë£Œ ì¡°ê±´**:
- [ ] ì˜ì¡´ì„± ì„¤ì¹˜ (`chromadb`, `sentence-transformers`)
- [ ] ì„ë² ë”© ì»¬ëŸ¼ ë§ˆì´ê·¸ë ˆì´ì…˜
- [ ] ë°±í•„ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
- [ ] `complete_memory_service.py` êµ¬í˜„
- [ ] `memory_factory.py` ì—…ë°ì´íŠ¸
- [ ] `.env`ì—ì„œ `MEMORY_SERVICE_TYPE=complete` ì„¤ì •
- [ ] Semantic Search í…ŒìŠ¤íŠ¸
- [ ] `consolidate_memories` ë°°ì¹˜ ì‘ì—… ìŠ¤ì¼€ì¤„ë§

---

## ğŸ§ª í†µí•© í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

### Scenario 1: Phase 1 â†’ Phase 2 ë§ˆì´ê·¸ë ˆì´ì…˜

```bash
# 1. Phase 1 í…ŒìŠ¤íŠ¸
export MEMORY_SERVICE_TYPE=simple
python scripts/test_memory_integration.py

# 2. Phase 2ë¡œ ì „í™˜
export MEMORY_SERVICE_TYPE=enhanced
python scripts/test_memory_integration.py

# 3. ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ í™•ì¸
psql -U postgres -d real_estate -c "SELECT COUNT(*) FROM conversation_memories;"
```

### Scenario 2: Semantic Search ê²€ì¦

```python
# scripts/test_semantic_search.py
import asyncio
from app.service_agent.foundation.complete_memory_service import CompleteMemoryService
from app.db.postgre_db import get_async_db

async def test_semantic_search():
    async for db_session in get_async_db():
        service = CompleteMemoryService(db_session)

        # ëŒ€í™” ì €ì¥
        await service.save_conversation(
            user_id=1,
            query="ê°•ë‚¨ì—­ ê·¼ì²˜ ì›ë£¸ ì¶”ì²œí•´ì¤˜",
            response_summary="ê°•ë‚¨ì—­ ì›ë£¸ 3ê°œ ì¶”ì²œ"
        )

        # ìœ ì‚¬í•œ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰ (ë‹¤ë¥¸ í‘œí˜„)
        memories = await service.load_contextual_memories(
            user_id=1,
            current_query="ê°•ë‚¨ì—­ ì¸ê·¼ 1ì¸ì‹¤ ì•Œì•„ë´ì¤˜",  # ì˜ë¯¸ëŠ” ê°™ì§€ë§Œ ë‹¤ë¥¸ í‘œí˜„
            limit=5
        )

        print(f"Found {len(memories)} similar memories")
        for mem in memories:
            print(f"  - {mem['query']} (similarity: {mem['similarity']:.2f})")

        break

asyncio.run(test_semantic_search())
```

---

## ğŸ”„ ë¡¤ë°± ì „ëµ

### Phase 1 ë¡¤ë°±
```bash
# ì½”ë“œë§Œ ë˜ëŒë¦¬ê¸° (ë§ˆì´ê·¸ë ˆì´ì…˜ ì—†ì—ˆìœ¼ë¯€ë¡œ)
git revert <commit_hash>
```

### Phase 2 ë¡¤ë°±
```bash
# 1. ì„¤ì • ë³€ê²½
export MEMORY_SERVICE_TYPE=simple

# 2. Alembic ë¡¤ë°±
alembic downgrade -1

# 3. ë°±ì—…ì—ì„œ ë³µì› (í•„ìš” ì‹œ)
psql -U postgres -d real_estate < backups/before_phase2_YYYYMMDD_HHMMSS.sql
```

### Phase 3 ë¡¤ë°±
```bash
# 1. ì„¤ì • ë³€ê²½
export MEMORY_SERVICE_TYPE=enhanced

# 2. ì„ë² ë”© ì»¬ëŸ¼ ë§ˆì´ê·¸ë ˆì´ì…˜ ë¡¤ë°±
alembic downgrade -1
```

---

## ğŸ“‹ ìµœì¢… êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 0 (ì‚¬ì „ ì¤€ë¹„)
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
- [ ] Git ë¸Œëœì¹˜ ìƒì„±
- [ ] í…ŒìŠ¤íŠ¸ í™˜ê²½ ì¤€ë¹„
- [ ] í˜„ì¬ ìƒíƒœ ê²€ì¦

### Phase 1 (Quick Fix)
- [ ] `simple_memory_service.py` ìˆ˜ì •
- [ ] `load_recent_memories` êµ¬í˜„
- [ ] `save_conversation` êµ¬í˜„
- [ ] í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] team_supervisor ë™ì‘ í™•ì¸

### Phase 2 (Enhanced Memory)
- [ ] User ëª¨ë¸ relationship ì¶”ê°€
- [ ] `memory.py` ëª¨ë¸ ìƒì„±
- [ ] `models/__init__.py` ì—…ë°ì´íŠ¸
- [ ] Alembic ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
- [ ] `enhanced_memory_service.py` êµ¬í˜„
- [ ] `memory_factory.py` êµ¬í˜„
- [ ] team_supervisor í†µí•©
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼

### Phase 3 (Complete System)
- [ ] ì˜ì¡´ì„± ì„¤ì¹˜
- [ ] ì„ë² ë”© ì»¬ëŸ¼ ë§ˆì´ê·¸ë ˆì´ì…˜
- [ ] ë°±í•„ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
- [ ] `complete_memory_service.py` êµ¬í˜„
- [ ] Semantic Search í…ŒìŠ¤íŠ¸
- [ ] `consolidate_memories` êµ¬í˜„
- [ ] ë°°ì¹˜ ì‘ì—… ìŠ¤ì¼€ì¤„ë§

---

## ğŸ¯ ì„±ê³µ ì§€í‘œ

### Phase 1
- âœ… AttributeError í•´ê²°
- âœ… ê¸°ë³¸ ë©”ëª¨ë¦¬ ì €ì¥/ë¡œë“œ ë™ì‘
- âœ… ì‹œìŠ¤í…œ ì•ˆì •ì„± í™•ë³´

### Phase 2
- âœ… ì„¸ì…˜ ê°„ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ìœ¨ > 80%
- âœ… ì—”í‹°í‹° ì¸ì‹ ì •í™•ë„ > 90%
- âœ… ì‘ë‹µ ì‹œê°„ < 2ì´ˆ

### Phase 3
- âœ… Semantic Search ì •í™•ë„ > 85%
- âœ… ê°œì¸í™” ì‘ë‹µ í’ˆì§ˆ í–¥ìƒ
- âœ… ë©”ëª¨ë¦¬ ê´€ë ¨ì„± ì ìˆ˜ > 0.8

---

## ğŸ“ ê²°ë¡ 

ì´ ìˆ˜ì •ëœ ê³„íšì„œëŠ” **ì‹¤ì œ ì½”ë“œ ë¶„ì„ì„ ê¸°ë°˜**ìœ¼ë¡œ ì‘ì„±ë˜ì–´ **100% êµ¬í˜„ ê°€ëŠ¥**í•©ë‹ˆë‹¤.

**ì£¼ìš” ê°œì„ ì‚¬í•­**:
1. âœ… Phase 0 ì¶”ê°€ (ì‚¬ì „ ì¤€ë¹„)
2. âœ… Phase 1 ê°„ì†Œí™” (ë§ˆì´ê·¸ë ˆì´ì…˜ ì œê±°)
3. âœ… User relationship ëª…ì‹œì  ì¶”ê°€
4. âœ… Memory Factory íŒ¨í„´ ë„ì…
5. âœ… ë°±í•„ ì „ëµ ì¶”ê°€
6. âœ… ë¡¤ë°± ì „ëµ ì¶”ê°€
7. âœ… ì‹¤ì œ ë™ì‘í•˜ëŠ” í…ŒìŠ¤íŠ¸ ì½”ë“œ

**ì¦‰ì‹œ ì‹œì‘ ê°€ëŠ¥**: Phase 0ë¶€í„° ìˆœì°¨ì ìœ¼ë¡œ ì§„í–‰í•˜ë©´ ì•ˆì •ì ìœ¼ë¡œ 100% ì™„ì„±ë„ ë‹¬ì„± ê°€ëŠ¥í•©ë‹ˆë‹¤.

---

*ì‘ì„±ì¼: 2025-10-20 (Revised)*
*ê¸°ë°˜: plan_verification_report_251020.md (19ê°œ ì´ìŠˆ ëª¨ë‘ ìˆ˜ì •)*
*ìƒíƒœ: âœ… ê²€ì¦ ì™„ë£Œ, êµ¬í˜„ ì¤€ë¹„ ì™„ë£Œ*
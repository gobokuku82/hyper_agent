# Execute ë‹¨ê³„ LLM í˜¸ì¶œ í•„ìš”ì„± ë¶„ì„

**ì‘ì„±ì¼**: 2025-10-21
**ì§ˆë¬¸**: executeì—ì„œ LLMì„ í˜¸ì¶œí•˜ëŠ” ê²ƒì´ í•„ìš”í•œê°€?

---

## ğŸ“‹ í˜„ì¬ êµ¬ì¡° ë¶„ì„

### í˜„ì¬ LLM í˜¸ì¶œ ì§€ì 

```
initialize_node         (LLM 0íšŒ)
  â†“
planning_node           (LLM 3íšŒ) âœ… PlanningAgent
  â”œâ”€ analyze_intent()          # LLM #1
  â”œâ”€ _suggest_agents()          # LLM #2
  â””â”€ create_execution_plan()   # LLM #3
  â†“
execute_teams_node      (LLM 0íšŒ) âŒ ë‹¨ìˆœ ì‹¤í–‰
  â”œâ”€ _execute_teams_sequential()
  â””â”€ _execute_single_team()
      â”œâ”€ SearchExecutor.execute()     # LLM 2íšŒ (ë‚´ë¶€)
      â”œâ”€ AnalysisExecutor.execute()   # LLM 3-5íšŒ (ë‚´ë¶€)
      â””â”€ DocumentExecutor.execute()   # LLM 1-2íšŒ (ë‚´ë¶€)
  â†“
aggregate_results_node  (LLM 0íšŒ) âŒ ë‹¨ìˆœ ì§‘ê³„
  â†“
generate_response_node  (LLM 1íšŒ) âœ…
```

**ì´ LLM í˜¸ì¶œ**: 10-13íšŒ
- Planning: 3íšŒ
- Execute (ë‚´ë¶€ Executor): 6-9íšŒ
- Response: 1íšŒ

---

## ğŸ¤” Executeì—ì„œ LLMì„ í˜¸ì¶œí•´ì•¼ í•˜ëŠ”ê°€?

### Option 1: í˜„ì¬ ë°©ì‹ ìœ ì§€ (ê¶Œì¥) â­â­â­â­â­

**í˜„ì¬**: execute_teams_nodeëŠ” **ë‹¨ìˆœ ì‹¤í–‰ê¸° (Executor)**

```python
async def execute_teams_node(self, state):
    # 1. Planningì´ ë§Œë“  ê³„íš ì½ê¸°
    active_teams = state.get("active_teams", [])

    # 2. ìˆœì„œëŒ€ë¡œ ì‹¤í–‰ (LLM í˜¸ì¶œ ì—†ìŒ)
    for team in active_teams:
        result = await self._execute_single_team(team, ...)

    # 3. ê²°ê³¼ ì €ì¥
    return state
```

**ì¥ì **:
1. âœ… **ë‹¨ìˆœí•¨**: ê³„íš-ì‹¤í–‰ ë¶„ë¦¬ (SRP: Single Responsibility Principle)
2. âœ… **ì˜ˆì¸¡ ê°€ëŠ¥**: Planningì´ ê²°ì •, ExecuteëŠ” ì‹¤í–‰ë§Œ
3. âœ… **ë””ë²„ê¹… ìš©ì´**: ë¬¸ì œ ë°œìƒ ì‹œ Planning vs Execute ëª…í™•íˆ êµ¬ë¶„
4. âœ… **ì„±ëŠ¥**: ë¶ˆí•„ìš”í•œ LLM í˜¸ì¶œ ìµœì†Œí™”
5. âœ… **ë¹„ìš©**: LLM í˜¸ì¶œ ì¤„ì—¬ ë¹„ìš© ì ˆê°

**ë‹¨ì **:
1. âŒ **ìœ ì—°ì„± ë¶€ì¡±**: ì‹¤í–‰ ì¤‘ ë™ì  ì¡°ì • ë¶ˆê°€
2. âŒ **ì—ëŸ¬ ëŒ€ì‘ ì œí•œ**: íŒ€ ì‹¤íŒ¨ ì‹œ ëŒ€ì•ˆ ì „ëµ ì—†ìŒ

**ì í•©í•œ ê²½ìš°**:
- âœ… Planningì´ ì´ë¯¸ ì¶©ë¶„íˆ ì •í™•í•¨
- âœ… ì‹¤í–‰ ì¤‘ ë³€í™”ê°€ ì ìŒ
- âœ… ë¹„ìš©/ì„±ëŠ¥ ì¤‘ìš”

---

### Option 2: Executeì— LLM ì¶”ê°€ (ê³ ë„í™”) â­â­â­â­

**ê°œì„ **: execute_teams_nodeê°€ **ì§€ëŠ¥í˜• ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°**

#### 2-1. Pre-execution LLM (ì‹¤í–‰ ì „ ê²€í† )

**ëª©ì **: Planning ê²°ê³¼ ê²€ì¦ ë° ìµœì í™”

```python
async def execute_teams_node(self, state):
    # âœ… LLM í˜¸ì¶œ #1: ì‹¤í–‰ ì „ ê²€í† 
    execution_review = await self._review_execution_plan(state)

    if execution_review["needs_adjustment"]:
        # Planning ê³„íš ì¡°ì •
        state = self._adjust_execution_plan(state, execution_review)

    # ì‹¤í–‰
    for team in active_teams:
        result = await self._execute_single_team(team, ...)

    return state

async def _review_execution_plan(self, state):
    """ì‹¤í–‰ ì „ ê³„íš ê²€í†  (LLM)"""
    plan = state["planning_state"]["execution_steps"]
    query = state["query"]

    result = await self.llm_service.complete_json_async(
        prompt_name="execution/pre_execution_review",
        variables={
            "query": query,
            "execution_plan": plan
        },
        temperature=0.1,
        max_tokens=300
    )

    return {
        "needs_adjustment": result.get("needs_adjustment", False),
        "adjustments": result.get("adjustments", []),
        "reasoning": result.get("reasoning", "")
    }
```

**Prompt**: `execution/pre_execution_review.txt`
```text
# ì—­í• 
ì‹¤í–‰ ê³„íšì„ ê²€í† í•˜ê³  ë¬¸ì œë¥¼ ì°¾ëŠ” ê²€í† ì

# ì…ë ¥
ì§ˆë¬¸: {{query}}
ê³„íš: {{execution_plan}}

# ì‘ì—…
ë‹¤ìŒì„ ì²´í¬í•˜ì„¸ìš”:
1. ì‹¤í–‰ ìˆœì„œê°€ ì˜¬ë°”ë¥¸ê°€?
2. í•„ìš”í•œ íŒ€ì´ ë¹ ì¡ŒëŠ”ê°€?
3. ë¶ˆí•„ìš”í•œ íŒ€ì´ ìˆëŠ”ê°€?

# ì¶œë ¥ (JSON)
{
  "needs_adjustment": true|false,
  "adjustments": [
    {"type": "reorder", "reason": "searchê°€ analysisë³´ë‹¤ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•¨"},
    {"type": "add_team", "team": "document", "reason": "ê³„ì•½ì„œ ì‘ì„± í•„ìš”"},
    {"type": "remove_team", "team": "analysis", "reason": "ë‹¨ìˆœ ì¡°íšŒë¡œ ì¶©ë¶„"}
  ],
  "reasoning": "ê²€í†  ê²°ê³¼ ì„¤ëª…"
}
```

**ì¥ì **:
- âœ… Planning ì˜¤ë¥˜ ë³´ì •
- âœ… ì‹¤í–‰ ì „ ê²€ì¦

**ë‹¨ì **:
- âŒ LLM í˜¸ì¶œ +1íšŒ
- âŒ Planningê³¼ ì—­í•  ì¤‘ë³µ

**ì í•©í•œ ê²½ìš°**:
- Planningì˜ ì •í™•ë„ê°€ ë‚®ì„ ë•Œ
- ë³µì¡í•œ ì¿¼ë¦¬ê°€ ë§ì„ ë•Œ

---

#### 2-2. Mid-execution LLM (ì‹¤í–‰ ì¤‘ ì¡°ì •)

**ëª©ì **: íŒ€ ì‹¤í–‰ í›„ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •

```python
async def execute_teams_node(self, state):
    active_teams = state.get("active_teams", [])

    for i, team in enumerate(active_teams):
        # íŒ€ ì‹¤í–‰
        result = await self._execute_single_team(team, ...)

        # âœ… LLM í˜¸ì¶œ: ì¤‘ê°„ ê²°ê³¼ í‰ê°€
        if i < len(active_teams) - 1:  # ë§ˆì§€ë§‰ íŒ€ ì•„ë‹ˆë©´
            evaluation = await self._evaluate_intermediate_result(
                team, result, remaining_teams=active_teams[i+1:]
            )

            if evaluation["should_skip_next"]:
                # ë‹¤ìŒ íŒ€ ìŠ¤í‚µ (ì˜ˆ: search ê²°ê³¼ê°€ ì¶©ë¶„í•˜ë©´ analysis ìŠ¤í‚µ)
                logger.info(f"Skipping {active_teams[i+1]} based on {team} result")
                continue

            if evaluation["should_add_team"]:
                # ìƒˆ íŒ€ ì¶”ê°€
                active_teams.insert(i+1, evaluation["team_to_add"])

    return state

async def _evaluate_intermediate_result(self, team, result, remaining_teams):
    """ì¤‘ê°„ ê²°ê³¼ í‰ê°€ (LLM)"""
    result_summary = self._summarize_result(result)

    llm_result = await self.llm_service.complete_json_async(
        prompt_name="execution/mid_execution_evaluation",
        variables={
            "completed_team": team,
            "result_summary": result_summary,
            "remaining_teams": remaining_teams
        },
        temperature=0.1,
        max_tokens=300
    )

    return {
        "should_skip_next": llm_result.get("should_skip_next", False),
        "should_add_team": llm_result.get("should_add_team", False),
        "team_to_add": llm_result.get("team_to_add"),
        "reasoning": llm_result.get("reasoning", "")
    }
```

**Prompt**: `execution/mid_execution_evaluation.txt`
```text
# ì—­í• 
íŒ€ ì‹¤í–‰ ê²°ê³¼ë¥¼ í‰ê°€í•˜ê³  ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” ì¡°ìœ¨ì

# ì…ë ¥
ì™„ë£Œëœ íŒ€: {{completed_team}}
ê²°ê³¼ ìš”ì•½: {{result_summary}}
ë‚¨ì€ íŒ€: {{remaining_teams}}

# ì‘ì—…
ì™„ë£Œëœ íŒ€ì˜ ê²°ê³¼ë¥¼ ë³´ê³  íŒë‹¨í•˜ì„¸ìš”:
1. ê²°ê³¼ê°€ ì¶©ë¶„í•œê°€? (ë‹¤ìŒ íŒ€ ìŠ¤í‚µ ê°€ëŠ¥?)
2. ì¶”ê°€ íŒ€ì´ í•„ìš”í•œê°€?
3. ë‹¤ìŒ íŒ€ì„ ê·¸ëŒ€ë¡œ ì‹¤í–‰í•  ê²ƒì¸ê°€?

# ì˜ˆì‹œ
ì™„ë£Œëœ íŒ€: search
ê²°ê³¼ ìš”ì•½: ë²•ë¥  ì¡°í•­ 10ê±´ ê²€ìƒ‰ ì™„ë£Œ
ë‚¨ì€ íŒ€: [analysis]

íŒë‹¨: ê²€ìƒ‰ ê²°ê³¼ê°€ ì¶©ë¶„íˆ ë§ê³  ëª…í™•í•¨. ë¶„ì„ ë¶ˆí•„ìš”.

# ì¶œë ¥ (JSON)
{
  "should_skip_next": true,
  "should_add_team": false,
  "team_to_add": null,
  "reasoning": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì¶©ë¶„í•˜ì—¬ ë¶„ì„ ë¶ˆí•„ìš”"
}
```

**ì¥ì **:
- âœ… **ë™ì  ì¡°ì •**: ì‹¤í–‰ ì¤‘ ê³„íš ë³€ê²½
- âœ… **íš¨ìœ¨ì„±**: ë¶ˆí•„ìš”í•œ íŒ€ ìŠ¤í‚µ (ë¹„ìš© ì ˆê°)
- âœ… **ì ì‘ì„±**: ì¤‘ê°„ ê²°ê³¼ ê¸°ë°˜ ê²°ì •

**ë‹¨ì **:
- âŒ LLM í˜¸ì¶œ +NíšŒ (íŒ€ ìˆ˜ë§Œí¼)
- âŒ ì‹¤í–‰ ì‹œê°„ ì¦ê°€
- âŒ ë³µì¡ë„ ì¦ê°€

**ì í•©í•œ ê²½ìš°**:
- âœ… ì§ˆë¬¸ì´ ë³µì¡í•˜ê³  ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥
- âœ… íŒ€ ê°„ ì˜ì¡´ì„±ì´ ê°•í•¨
- âœ… ë¹„ìš©ë³´ë‹¤ ì •í™•ë„ê°€ ì¤‘ìš”

---

#### 2-3. Post-execution LLM (ì‹¤í–‰ í›„ ê²€í† )

**ëª©ì **: ê²°ê³¼ í’ˆì§ˆ í‰ê°€ ë° ë³´ì™„

```python
async def execute_teams_node(self, state):
    # ëª¨ë“  íŒ€ ì‹¤í–‰
    for team in active_teams:
        result = await self._execute_single_team(team, ...)

    # âœ… LLM í˜¸ì¶œ: ì‹¤í–‰ ì™„ë£Œ í›„ ê²€í† 
    review = await self._post_execution_review(state)

    if review["quality_low"]:
        # ë³´ì™„ ì‘ì—…
        if review["retry_team"]:
            # íŠ¹ì • íŒ€ ì¬ì‹¤í–‰
            retry_result = await self._execute_single_team(review["retry_team"], ...)

        if review["add_team"]:
            # ìƒˆ íŒ€ ì¶”ê°€ ì‹¤í–‰
            new_result = await self._execute_single_team(review["add_team"], ...)

    state["execution_review"] = review
    return state

async def _post_execution_review(self, state):
    """ì‹¤í–‰ ì™„ë£Œ í›„ ê²€í†  (LLM)"""
    query = state["query"]
    results = state["team_results"]

    llm_result = await self.llm_service.complete_json_async(
        prompt_name="execution/post_execution_review",
        variables={
            "query": query,
            "results": self._summarize_results(results)
        },
        temperature=0.1,
        max_tokens=400
    )

    return {
        "quality_low": llm_result.get("quality_score", 0.7) < 0.5,
        "quality_score": llm_result.get("quality_score", 0.7),
        "missing_info": llm_result.get("missing_info", []),
        "retry_team": llm_result.get("retry_team"),
        "add_team": llm_result.get("add_team"),
        "reasoning": llm_result.get("reasoning", "")
    }
```

**Prompt**: `execution/post_execution_review.txt`
```text
# ì—­í• 
ëª¨ë“  íŒ€ ì‹¤í–‰ í›„ ê²°ê³¼ë¥¼ ì¢…í•© ê²€í† í•˜ëŠ” í’ˆì§ˆ ê´€ë¦¬ì

# ì…ë ¥
ì§ˆë¬¸: {{query}}
ì‹¤í–‰ ê²°ê³¼: {{results}}

# ì‘ì—…
1. ì§ˆë¬¸ì— ë‹µí•˜ê¸° ì¶©ë¶„í•œ ì •ë³´ê°€ ëª¨ì˜€ëŠ”ê°€?
2. ëˆ„ë½ëœ ì •ë³´ê°€ ìˆëŠ”ê°€?
3. í’ˆì§ˆì´ ë‚®ì€ ê²°ê³¼ê°€ ìˆëŠ”ê°€?

# ì¶œë ¥ (JSON)
{
  "quality_score": 0.8,
  "missing_info": ["ëŒ€ì¶œ ê¸ˆë¦¬ ì •ë³´"],
  "retry_team": null,
  "add_team": "search",
  "reasoning": "ë²•ë¥  ì •ë³´ëŠ” ì¶©ë¶„í•˜ë‚˜ ëŒ€ì¶œ ê¸ˆë¦¬ ì •ë³´ ë¶€ì¡±"
}
```

**ì¥ì **:
- âœ… **í’ˆì§ˆ ë³´ì¥**: ê²°ê³¼ ê²€ì¦
- âœ… **ë³´ì™„ ê¸°íšŒ**: ë¶€ì¡±í•œ ë¶€ë¶„ ì¬ì‹¤í–‰

**ë‹¨ì **:
- âŒ LLM í˜¸ì¶œ +1íšŒ
- âŒ ì‹¤í–‰ ì‹œê°„ ì¦ê°€ (ì¬ì‹¤í–‰ ì‹œ)

**ì í•©í•œ ê²½ìš°**:
- âœ… ê²°ê³¼ í’ˆì§ˆì´ ì¤‘ìš”
- âœ… ì¬ì‹¤í–‰ ë¹„ìš©ì´ í—ˆìš© ê°€ëŠ¥

---

### Option 3: ExecutionOrchestrator í†µí•© (ë¯¸êµ¬í˜„ í™œìš©) â­â­â­

**ë°©ë²•**: ì´ë¯¸ êµ¬í˜„ëœ `execution_orchestrator.py` í™œìš©

```python
async def execute_teams_node(self, state):
    # ExecutionOrchestrator ì‚¬ìš©
    from app.service_agent.cognitive_agents.execution_orchestrator import ExecutionOrchestrator

    if not hasattr(self, 'orchestrator'):
        self.orchestrator = ExecutionOrchestrator(self.llm_context)

    # âœ… Pre-execution: ì‹¤í–‰ ì „ ìµœì í™”
    state = await self.orchestrator.orchestrate_with_state(
        state,
        progress_callback=self._progress_callbacks.get(state["session_id"])
    )

    # ì‹¤í–‰ (ê¸°ì¡´ ë¡œì§)
    for team in active_teams:
        result = await self._execute_single_team(team, ...)

        # âœ… Mid-execution: íŒ€ ì‹¤í–‰ í›„ ë¶„ì„
        state = await self.orchestrator.analyze_team_result(
            state, team, result, progress_callback
        )

    return state
```

**ì¥ì **:
- âœ… **ì´ë¯¸ êµ¬í˜„ë¨**: 516ì¤„ ì™„ì„± ì½”ë“œ
- âœ… **ë„êµ¬ ì¤‘ë³µ ë°©ì§€**: ì „ì—­ ê´€ì  ìµœì í™”
- âœ… **í•™ìŠµ ê¸°ëŠ¥**: ì‚¬ìš©ì íŒ¨í„´ Memory ì €ì¥

**ë‹¨ì **:
- âŒ LLM í˜¸ì¶œ +2-3íšŒ
- âŒ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì‘ì„± í•„ìš”

---

## ğŸ“Š ë¹„êµ ë¶„ì„

| ë°©ì‹ | LLM í˜¸ì¶œ | ë³µì¡ë„ | ìœ ì—°ì„± | ë¹„ìš© | í’ˆì§ˆ | ê¶Œì¥ë„ |
|-----|---------|--------|--------|------|------|--------|
| **Option 1: í˜„ì¬ ìœ ì§€** | 0íšŒ | ë‚®ìŒ | ë‚®ìŒ | ìµœì € | ì¤‘ê°„ | â­â­â­â­â­ |
| **Option 2-1: Pre-execution** | +1íšŒ | ì¤‘ê°„ | ì¤‘ê°„ | ë‚®ìŒ | ë†’ìŒ | â­â­â­â­ |
| **Option 2-2: Mid-execution** | +NíšŒ | ë†’ìŒ | ë†’ìŒ | ë†’ìŒ | ìµœê³  | â­â­â­ |
| **Option 2-3: Post-execution** | +1íšŒ | ì¤‘ê°„ | ì¤‘ê°„ | ì¤‘ê°„ | ë†’ìŒ | â­â­â­â­ |
| **Option 3: Orchestrator** | +2-3íšŒ | ì¤‘ê°„ | ë†’ìŒ | ì¤‘ê°„ | ë†’ìŒ | â­â­â­â­ |

---

## ğŸ¯ ìƒí™©ë³„ ê¶Œì¥ ë°©ì•ˆ

### í˜„ì¬ Agent Routing ë¬¸ì œì— ì§‘ì¤‘ (ê¸´ê¸‰)

**ê¶Œì¥**: **Option 1 (í˜„ì¬ ìœ ì§€)** â­â­â­â­â­

**ì´ìœ **:
1. âœ… **ë¬¸ì œì˜ ì›ì¸ì´ Executeê°€ ì•„ë‹˜**
   - í˜„ì¬ ë¬¸ì œ: Planningì˜ ìˆœì„œ ì†ì‹¤ (`set()` ì‚¬ìš©)
   - ExecuteëŠ” Planningì˜ ê³„íšì„ ì˜ ì‹¤í–‰í•˜ê³  ìˆìŒ

2. âœ… **Priority í•„ë“œ ì¶”ê°€ë§Œìœ¼ë¡œ í•´ê²° ê°€ëŠ¥**
   ```python
   # Planningì—ì„œ
   active_teams = sorted(steps, key=lambda x: x["priority"])  # ìˆœì„œ ë³´ì¥

   # ExecuteëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
   for team in active_teams:  # âœ… ì´ë¯¸ ìˆœì„œëŒ€ë¡œ ì •ë ¬ë¨
       result = await self._execute_single_team(team, ...)
   ```

3. âœ… **ìµœì†Œ ìˆ˜ì • ì›ì¹™**
   - ì‚¬ìš©ì ì˜ë„: "cognitive_agentsëŠ” ì™„ì„±, supervisorì˜ execute/aggregateë§Œ ìˆ˜ì •"
   - Executeì— LLM ì¶”ê°€ëŠ” ê³¼ë„í•œ ìˆ˜ì •

**ì¡°ì¹˜ì‚¬í•­**:
- Planningì˜ priority ìˆœì„œ ë³´ì¥ (30ë¶„)
- ExecuteëŠ” ìˆ˜ì • ì•ˆ í•¨ (0ë¶„)

---

### ì¥ê¸° ê°œì„  (ì„ íƒ)

**ê¶Œì¥**: **Option 2-3 (Post-execution)** + **Option 3 (Orchestrator)** â­â­â­â­

**ì´ìœ **:
1. âœ… **ë‹¨ê³„ì  ë„ì…**
   - Phase 1: Priority ìˆœì„œ ë³´ì¥ (í˜„ì¬ ë¬¸ì œ í•´ê²°)
   - Phase 2: Post-execution ê²€í†  (í’ˆì§ˆ í–¥ìƒ)
   - Phase 3: ExecutionOrchestrator í†µí•© (ë„êµ¬ ìµœì í™”)

2. âœ… **ì‹¤ìš©ì„±**
   - Post-execution: ê²°ê³¼ í’ˆì§ˆ ë³´ì¥
   - Orchestrator: ë„êµ¬ ì¤‘ë³µ ë°©ì§€ (30% â†’ 0%)

3. âœ… **ë¹„ìš© ëŒ€ë¹„ íš¨ê³¼**
   - LLM í˜¸ì¶œ: +1-2íšŒ (í—ˆìš© ë²”ìœ„)
   - íš¨ê³¼: í’ˆì§ˆ í–¥ìƒ + ë„êµ¬ ìµœì í™”

**êµ¬í˜„ ìˆœì„œ**:
```
Phase 1 (ê¸´ê¸‰):
  - Priority ìˆœì„œ ë³´ì¥
  - í‚¤ì›Œë“œ í•„í„°

Phase 2 (ì¤‘ê¸°):
  - Post-execution ê²€í†  LLM ì¶”ê°€
  - aggregate_results_nodeì— í’ˆì§ˆ í‰ê°€ ì¶”ê°€

Phase 3 (ì¥ê¸°):
  - ExecutionOrchestrator í†µí•©
  - í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì‘ì„±
```

---

## ğŸ’¡ ìµœì¢… ê¶Œì¥: Hybrid ì ‘ê·¼

### Phase 1: í˜„ì¬ ë¬¸ì œ í•´ê²° (2-3ì‹œê°„)

**Executeì— LLM ì¶”ê°€ ì•ˆ í•¨!** âœ…

```python
# planning_node: priority ìˆœì„œ ë³´ì¥
active_teams = sorted(
    planning_state["execution_steps"],
    key=lambda x: x.get("priority", 999)
)

# execute_teams_node: ìˆ˜ì • ì—†ìŒ (ê·¸ëŒ€ë¡œ ì‹¤í–‰)
for team in active_teams:  # âœ… ì´ë¯¸ ìˆœì„œëŒ€ë¡œ
    result = await self._execute_single_team(team, ...)
```

---

### Phase 2: Aggregateì— LLM ì¶”ê°€ (ì„ íƒ, 4ì‹œê°„)

**aggregate_results_node ê°œì„ ** â­â­â­â­

**í˜„ì¬**:
```python
async def aggregate_results_node(self, state):
    # ë‹¨ìˆœ ì§‘ê³„ë§Œ
    aggregated = {}
    for team, data in team_results.items():
        aggregated[team] = {"status": "success", "data": data}
    return state
```

**ê°œì„ **:
```python
async def aggregate_results_node(self, state):
    # 1. ê¸°ì¡´ ì§‘ê³„
    aggregated = {}
    for team, data in team_results.items():
        aggregated[team] = {"status": "success", "data": data}

    state["aggregated_results"] = aggregated

    # âœ… 2. LLM ì¶”ê°€: ê²°ê³¼ í’ˆì§ˆ í‰ê°€
    quality_review = await self._evaluate_aggregated_quality(state)

    state["quality_review"] = quality_review

    # âœ… 3. í’ˆì§ˆ ë‚®ìœ¼ë©´ ê²½ê³  (Responseì—ì„œ í™œìš©)
    if quality_review["quality_score"] < 0.5:
        state["quality_warning"] = {
            "missing_info": quality_review["missing_info"],
            "recommendations": quality_review["recommendations"]
        }

    return state

async def _evaluate_aggregated_quality(self, state):
    """ì§‘ê³„ ê²°ê³¼ í’ˆì§ˆ í‰ê°€ (LLM)"""
    query = state["query"]
    aggregated = state["aggregated_results"]

    result = await self.planning_agent.llm_service.complete_json_async(
        prompt_name="aggregation/quality_evaluation",
        variables={
            "query": query,
            "aggregated_results": self._summarize_aggregated(aggregated)
        },
        temperature=0.1,
        max_tokens=400
    )

    return {
        "quality_score": result.get("quality_score", 0.7),
        "missing_info": result.get("missing_info", []),
        "recommendations": result.get("recommendations", []),
        "reasoning": result.get("reasoning", "")
    }
```

**Prompt**: `aggregation/quality_evaluation.txt`
```text
# ì—­í• 
íŒ€ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” ê²€í† ì

# ì…ë ¥
ì§ˆë¬¸: {{query}}
ì§‘ê³„ ê²°ê³¼: {{aggregated_results}}

# ì‘ì—…
1. ì§ˆë¬¸ì— ë‹µí•˜ê¸° ì¶©ë¶„í•œê°€?
2. ëˆ„ë½ëœ ì •ë³´ëŠ”?
3. í’ˆì§ˆ ì ìˆ˜ (0.0-1.0)

# ì¶œë ¥ (JSON)
{
  "quality_score": 0.8,
  "missing_info": ["ëŒ€ì¶œ ê¸ˆë¦¬ ì„¸ë¶€ ì •ë³´"],
  "recommendations": ["ëŒ€ì¶œ ìƒë‹´ íŒ€ ì¶”ê°€ ì‹¤í–‰ ê¶Œì¥"],
  "reasoning": "ë²•ë¥ /ì‹œì„¸ ì •ë³´ëŠ” ì¶©ë¶„í•˜ë‚˜ ëŒ€ì¶œ ì •ë³´ ë¶€ì¡±"
}
```

**ì¥ì **:
- âœ… ExecuteëŠ” ìˆ˜ì • ì•ˆ í•¨ (ë‹¨ìˆœ ì‹¤í–‰ ìœ ì§€)
- âœ… Aggregateì—ì„œ í’ˆì§ˆ í‰ê°€ (ì±…ì„ ë¶„ë¦¬)
- âœ… Responseì—ì„œ ê²½ê³  ë©”ì‹œì§€ í™œìš© ê°€ëŠ¥
- âœ… LLM í˜¸ì¶œ +1íšŒë§Œ

---

## ğŸ“ ê²°ë¡ 

### ì§ˆë¬¸: "executeì—ì„œ LLMì„ í˜¸ì¶œí•˜ëŠ” ê±´ ì–´ë–¤ê°€?"

**ë‹µë³€**: **í˜„ì¬ëŠ” ë¶ˆí•„ìš”í•˜ì§€ë§Œ, ì¥ê¸°ì ìœ¼ë¡œ Aggregateì— ì¶”ê°€í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.**

### ì´ìœ 

1. **í˜„ì¬ ë¬¸ì œëŠ” Executeê°€ ì•„ë‹˜**
   - ë¬¸ì œ: Planningì˜ ìˆœì„œ ì†ì‹¤
   - í•´ê²°: Priority í•„ë“œ ì¶”ê°€ (Execute ìˆ˜ì • ë¶ˆí•„ìš”)

2. **ExecuteëŠ” ì´ë¯¸ ì˜ ì‘ë™ ì¤‘**
   - Planningì˜ ê³„íšì„ ì¶©ì‹¤íˆ ì‹¤í–‰
   - ë‹¨ìˆœ ì‹¤í–‰ê¸°ë¡œì„œ ì—­í•  ëª…í™•

3. **LLM ì¶”ê°€ ì‹œ ì ì ˆí•œ ìœ„ì¹˜ëŠ” Aggregate**
   - Execute: ì‹¤í–‰ë§Œ ë‹´ë‹¹
   - Aggregate: ê²°ê³¼ ê²€í†  ë° í’ˆì§ˆ í‰ê°€
   - ì±…ì„ ë¶„ë¦¬ (SRP)

### ìµœì¢… ê¶Œì¥ êµ¬ì¡°

```
planning_node (LLM 3íšŒ)
  â”œâ”€ Intent Analysis
  â”œâ”€ Agent Selection
  â””â”€ Execution Plan (priority í¬í•¨) âœ…
  â†“
execute_teams_node (LLM 0íšŒ) âœ… ë‹¨ìˆœ ì‹¤í–‰
  â””â”€ priority ìˆœì„œëŒ€ë¡œ ì‹¤í–‰ âœ…
  â†“
aggregate_results_node (LLM 1íšŒ) â­ ê°œì„  ê¶Œì¥
  â”œâ”€ ê²°ê³¼ ì§‘ê³„
  â””â”€ í’ˆì§ˆ í‰ê°€ (LLM) âœ…
  â†“
generate_response_node (LLM 1íšŒ)
  â””â”€ í’ˆì§ˆ ê²½ê³  ë°˜ì˜ âœ…
```

**LLM í˜¸ì¶œ**: 10-13íšŒ â†’ 11-14íšŒ (+1íšŒë§Œ, Aggregateì—ì„œ)

---

**ì‘ì„± ì™„ë£Œ**: 2025-10-21
**ê¶Œì¥**: Phase 1 (Execute ìˆ˜ì • ì•ˆ í•¨) + Phase 2 (Aggregate LLM ì¶”ê°€, ì„ íƒ)

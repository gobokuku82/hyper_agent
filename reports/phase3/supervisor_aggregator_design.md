# Supervisor Aggregator + Generator ì„¤ê³„

**ì‘ì„±ì¼**: 2025-11-03
**Phase**: Phase 3.5 (Answer Generation)
**ëª©ì **: ë‹¤ì–‘í•œ Frontend ìš”êµ¬ì‚¬í•­ì„ ì§€ì›í•˜ëŠ” ë‹µë³€ ìƒì„± ì‹œìŠ¤í…œ ì„¤ê³„

---

## 1. ê°œìš”

### 1.1 ì™œ Aggregator + Generator êµ¬ì¡°ì¸ê°€?

OctostratorëŠ” ì¼ë°˜ì ì¸ LLM ì±—ë´‡(ChatGPT, Gemini)ê³¼ì˜ ì°¨ë³„í™”ë¥¼ ëª©í‘œë¡œ í•©ë‹ˆë‹¤:

| êµ¬ë¶„ | ì¼ë°˜ LLM ì±—ë´‡ | Octostrator |
|------|--------------|-------------|
| **ë‹µë³€ í˜•ì‹** | í…ìŠ¤íŠ¸ë§Œ | í…ìŠ¤íŠ¸ + ê·¸ë˜í”„ + ë³´ê³ ì„œ |
| **íˆ¬ëª…ì„±** | ë‚®ìŒ (ë¸”ë™ë°•ìŠ¤) | ë†’ìŒ (ëª¨ë“  ë‹¨ê³„ ì¶”ì ) |
| **ì‹ ë¢°ì„±** | ì„¤ëª… ì—†ìŒ | ê° ë‹¨ê³„ë³„ ê·¼ê±° ì œê³µ |
| **ì „ë¬¸ì„±** | ì¼ë°˜ì  ë‹µë³€ | ë„ë©”ì¸ë³„ Agent ê¸°ë°˜ |
| **Frontend** | ë‹¨ì¼ ì±„íŒ…ì°½ | ê·¸ë˜í”„ í˜ì´ì§€, ëŒ€ì‹œë³´ë“œ, ë³´ê³ ì„œ ë“± ë‹¤ì–‘ |

### 1.2 ì•„í‚¤í…ì²˜ ê°œìš”

```
Executor â†’ All Agents â†’ Aggregator â†’ [Conditional Router] â†’ Generators â†’ Final Result
                                              â†“
                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”
                                      â†“       â†“       â†“
                               Chat  Graph  Report
                             Generator Generator Generator
```

**í•µì‹¬ ì›ì¹™**:
- **Aggregator**: Frontend ë¬´ê´€í•˜ê²Œ êµ¬ì¡°í™”ëœ ë°ì´í„° ìƒì„± (ì¬ì‚¬ìš© ê°€ëŠ¥)
- **Generator**: Frontend í˜•ì‹ì— ë§ê²Œ ë³€í™˜ (êµì²´ ê°€ëŠ¥)
- **Conditional Router**: ì‚¬ìš©ì ìš”ì²­/ì„¤ì •ì— ë”°ë¼ ì ì ˆí•œ Generator ì„ íƒ

---

## 2. Aggregator Node ì„¤ê³„

### 2.1 ì—­í• 

ëª¨ë“  Agent ì‹¤í–‰ ê²°ê³¼ë¥¼ **êµ¬ì¡°í™”ëœ ì¤‘ê°„ ë°ì´í„°**ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

**ì…ë ¥**:
- `state["plan"]`: ëª¨ë“  TaskStepì˜ ì‹¤í–‰ ê²°ê³¼
- `state["messages"]`: ì „ì²´ ë©”ì‹œì§€ íë¦„
- `state["user_intent"]`: ì‚¬ìš©ì ì˜ë„

**ì¶œë ¥**:
- `aggregated_data`: Frontend ë¬´ê´€í•œ êµ¬ì¡°í™”ëœ JSON

### 2.2 êµ¬í˜„

```python
# backend/app/octostrator/nodes/aggregator.py

from typing import Dict, List
from pydantic import BaseModel
from langchain_core.messages import AIMessage
from langchain_openai import ChatOpenAI
from backend.app.octostrator.states.supervisor_state import SupervisorState


class ExecutionSummary(BaseModel):
    """ì „ì²´ ì‹¤í–‰ ìš”ì•½"""
    total_steps: int
    completed_steps: int
    failed_steps: int
    execution_time: float  # seconds
    hitl_interactions: int


class StepResult(BaseModel):
    """ê° ë‹¨ê³„ë³„ ê²°ê³¼"""
    step_id: int
    agent: str
    description: str
    status: str
    result: str
    confidence: float = 0.9  # Agentë³„ë¡œ ì„¤ì • ê°€ëŠ¥
    evidence: List[str] = []  # ê·¼ê±° ìë£Œ


class Insight(BaseModel):
    """ë¶„ì„ ì¸ì‚¬ì´íŠ¸"""
    category: str  # "trend", "anomaly", "recommendation"
    description: str
    importance: float  # 0.0 ~ 1.0
    related_steps: List[int]


class AggregatedResult(BaseModel):
    """ìµœì¢… êµ¬ì¡°í™” ê²°ê³¼"""
    execution_summary: ExecutionSummary
    steps: List[StepResult]
    insights: List[Insight]
    final_answer: str  # ê°„ë‹¨í•œ ìš”ì•½ (ëª¨ë“  Generatorê°€ ì‚¬ìš©)
    metadata: Dict  # ì¶”ê°€ ì •ë³´


async def aggregator_node(
    state: SupervisorState,
    llm: ChatOpenAI
) -> Dict:
    """Aggregator - ëª¨ë“  Agent ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜

    Phase 3.5: Frontend ë¬´ê´€í•œ êµ¬ì¡°í™”ëœ ë°ì´í„° ìƒì„±

    Args:
        state: í˜„ì¬ SupervisorState
        llm: ChatOpenAI instance

    Returns:
        Dict: aggregated_dataë¥¼ í¬í•¨í•œ state ì—…ë°ì´íŠ¸
    """
    plan = state["plan"]

    # 1. Execution Summary ìƒì„±
    execution_summary = ExecutionSummary(
        total_steps=len(plan),
        completed_steps=sum(1 for s in plan if s["status"] == "completed"),
        failed_steps=sum(1 for s in plan if s["status"] == "failed"),
        execution_time=0.0,  # TODO: ì‹¤ì œ ì‹œê°„ ì¶”ì 
        hitl_interactions=sum(1 for s in plan if s["agent"] == "hitl")
    )

    # 2. ê° ë‹¨ê³„ë³„ ê²°ê³¼ êµ¬ì¡°í™”
    steps = []
    for step in plan:
        steps.append(StepResult(
            step_id=step["step_id"],
            agent=step["agent"],
            description=step["description"],
            status=step["status"],
            result=step.get("result", ""),
            evidence=[]  # TODO: Agentì—ì„œ ê·¼ê±° ìë£Œ ìˆ˜ì§‘
        ))

    # 3. LLMìœ¼ë¡œ ì¸ì‚¬ì´íŠ¸ ìƒì„±
    insight_prompt = f"""
    ë‹¤ìŒ ì‘ì—… ì‹¤í–‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì£¼ìš” ì¸ì‚¬ì´íŠ¸ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:

    ì‚¬ìš©ì ì˜ë„: {state.get('user_intent', '')}

    ì‹¤í–‰ ë‹¨ê³„:
    {format_steps_for_llm(plan)}

    ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”:
    1. íŠ¸ë Œë“œ (trend): ë°ì´í„°ì—ì„œ ë°œê²¬ëœ ê²½í–¥ì„±
    2. ì´ìƒ ì§•í›„ (anomaly): ì˜ˆìƒê³¼ ë‹¤ë¥¸ íŒ¨í„´
    3. ê¶Œì¥ ì‚¬í•­ (recommendation): ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ

    ê° ì¸ì‚¬ì´íŠ¸ëŠ” ì¤‘ìš”ë„(0.0~1.0)ì™€ ê´€ë ¨ ë‹¨ê³„ë¥¼ í¬í•¨í•˜ì„¸ìš”.
    """

    # LLMìœ¼ë¡œ ì¸ì‚¬ì´íŠ¸ ìƒì„± (Structured Output)
    from pydantic import BaseModel

    class InsightList(BaseModel):
        insights: List[Insight]
        final_answer: str

    structured_llm = llm.with_structured_output(InsightList)
    insight_result = await structured_llm.ainvoke([
        {"role": "system", "content": "You are an expert analyst."},
        {"role": "user", "content": insight_prompt}
    ])

    # 4. ìµœì¢… êµ¬ì¡°í™” ê²°ê³¼ ìƒì„±
    aggregated_data = AggregatedResult(
        execution_summary=execution_summary,
        steps=steps,
        insights=insight_result.insights,
        final_answer=insight_result.final_answer,
        metadata={
            "user_intent": state.get("user_intent", ""),
            "timestamp": "2025-11-03T10:00:00Z",  # TODO: ì‹¤ì œ íƒ€ì„ìŠ¤íƒ¬í”„
        }
    )

    return {
        "aggregated_data": aggregated_data.model_dump(),
        "messages": [
            AIMessage(content=f"[Aggregator] ì „ì²´ ì‹¤í–‰ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”í–ˆìŠµë‹ˆë‹¤.\n\n"
                             f"ì´ {execution_summary.total_steps}ê°œ ë‹¨ê³„ ì¤‘ "
                             f"{execution_summary.completed_steps}ê°œ ì™„ë£Œ")
        ]
    }


def format_steps_for_llm(plan: List[dict]) -> str:
    """Planì„ LLMì´ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    lines = []
    for step in plan:
        lines.append(f"Step {step['step_id']}: [{step['agent']}] {step['description']}")
        lines.append(f"  Status: {step['status']}")
        if step.get('result'):
            lines.append(f"  Result: {step['result'][:200]}")
    return "\n".join(lines)
```

### 2.3 SupervisorState í™•ì¥

```python
# backend/app/octostrator/states/supervisor_state.py

class SupervisorState(TypedDict, total=False):
    """Supervisor State with Plan Management"""
    messages: Annotated[Sequence[BaseMessage], add_messages]

    # Planning
    user_intent: Optional[str]
    plan: List[dict]
    current_step: int

    # Execution Flags
    is_planning: bool
    is_executing: bool
    is_waiting_human: bool

    # NEW: Aggregation & Generation
    aggregated_data: Optional[dict]  # Aggregator ê²°ê³¼
    output_format: str  # "chat", "graph", "report"

    # Results
    final_result: Optional[str]
```

---

## 3. Generator Nodes ì„¤ê³„

### 3.1 Chat Generator (ëŒ€í™”í˜• ì±—ë´‡)

**ëª©ì **: ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” í˜•ì‹ìœ¼ë¡œ ë‹µë³€ ìƒì„± (ê¸°ì¡´ LLMê³¼ ìœ ì‚¬í•˜ì§€ë§Œ ë” êµ¬ì¡°ì )

```python
# backend/app/octostrator/nodes/generators/chat_generator.py

from langchain_core.messages import AIMessage
from backend.app.octostrator.states.supervisor_state import SupervisorState


async def chat_generator_node(state: SupervisorState) -> dict:
    """Chat Generator - ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”í˜• ë‹µë³€ ìƒì„±

    Frontend: ì¼ë°˜ì ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    """
    aggregated_data = state["aggregated_data"]

    # êµ¬ì¡°í™”ëœ ë°ì´í„° â†’ ìì—°ì–´ ë³€í™˜
    chat_response = f"""
{aggregated_data['final_answer']}

---

ğŸ“Š **ì‹¤í–‰ ìš”ì•½**
- ì´ {aggregated_data['execution_summary']['total_steps']}ê°œ ë‹¨ê³„ ì‹¤í–‰
- ì™„ë£Œ: {aggregated_data['execution_summary']['completed_steps']}ê°œ
- ì‚¬ìš©ì ìŠ¹ì¸: {aggregated_data['execution_summary']['hitl_interactions']}íšŒ

ğŸ’¡ **ì£¼ìš” ì¸ì‚¬ì´íŠ¸**
"""

    # ì¸ì‚¬ì´íŠ¸ ì¶”ê°€ (ì¤‘ìš”ë„ ë†’ì€ ìˆœ)
    insights = sorted(
        aggregated_data['insights'],
        key=lambda x: x['importance'],
        reverse=True
    )

    for i, insight in enumerate(insights[:3], 1):  # ìƒìœ„ 3ê°œë§Œ
        emoji = {
            "trend": "ğŸ“ˆ",
            "anomaly": "âš ï¸",
            "recommendation": "âœ…"
        }.get(insight['category'], "â€¢")

        chat_response += f"\n{emoji} {insight['description']}"

    chat_response += "\n\n---\n\n"
    chat_response += "ë” ìì„¸í•œ ë‚´ìš©ì€ ê° ë‹¨ê³„ë³„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”. (ê·¸ë˜í”„ ë³´ê¸° ë²„íŠ¼ í´ë¦­)"

    return {
        "final_result": chat_response,
        "messages": [AIMessage(content=chat_response)]
    }
```

**Frontend ì˜ˆì‹œ**:
```
ì‚¬ìš©ì ì§ˆë¬¸: "ì§€ë‚œ ë¶„ê¸° ë§¤ì¶œ ë¶„ì„í•´ì¤˜"

ë‹µë³€:
ì§€ë‚œ ë¶„ê¸° ë§¤ì¶œì€ ì „ë…„ ëŒ€ë¹„ 15% ì¦ê°€í–ˆìœ¼ë©°, íŠ¹íˆ ì˜¨ë¼ì¸ ì±„ë„ì—ì„œ
í° ì„±ì¥ì´ ìˆì—ˆìŠµë‹ˆë‹¤. ë‹¤ë§Œ ì˜¤í”„ë¼ì¸ ë§¤ì¥ì€ 5% ê°ì†Œí–ˆìŠµë‹ˆë‹¤.

---

ğŸ“Š ì‹¤í–‰ ìš”ì•½
- ì´ 9ê°œ ë‹¨ê³„ ì‹¤í–‰
- ì™„ë£Œ: 9ê°œ
- ì‚¬ìš©ì ìŠ¹ì¸: 3íšŒ

ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸
ğŸ“ˆ ì˜¨ë¼ì¸ ë§¤ì¶œì´ ì „ë…„ ëŒ€ë¹„ 35% ì¦ê°€
âš ï¸ ì˜¤í”„ë¼ì¸ ë§¤ì¥ 3ê³³ì—ì„œ ë§¤ì¶œ ê¸‰ê°
âœ… ì˜¨ë¼ì¸ ë§ˆì¼€íŒ… ì˜ˆì‚° í™•ëŒ€ ê¶Œì¥

---

ë” ìì„¸í•œ ë‚´ìš©ì€ ê° ë‹¨ê³„ë³„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”. (ê·¸ë˜í”„ ë³´ê¸° ë²„íŠ¼ í´ë¦­)
```

---

### 3.2 Graph Generator (ì‹œê°í™” í˜ì´ì§€)

**ëª©ì **: ì‹¤í–‰ íë¦„ì„ ê·¸ë˜í”„ë¡œ ì‹œê°í™” (íˆ¬ëª…ì„± ê·¹ëŒ€í™”)

```python
# backend/app/octostrator/nodes/generators/graph_generator.py

from typing import List, Dict
from backend.app.octostrator.states.supervisor_state import SupervisorState


async def graph_generator_node(state: SupervisorState) -> dict:
    """Graph Generator - ê·¸ë˜í”„ ì‹œê°í™” ë°ì´í„° ìƒì„±

    Frontend: D3.js, Cytoscape.js ë“±ìœ¼ë¡œ ë Œë”ë§
    """
    aggregated_data = state["aggregated_data"]

    # ë…¸ë“œ ìƒì„±
    nodes = []
    edges = []

    # START ë…¸ë“œ
    nodes.append({
        "id": "start",
        "label": "START",
        "type": "start",
        "color": "#4CAF50"
    })

    # ê° ë‹¨ê³„ë³„ ë…¸ë“œ ìƒì„±
    steps = aggregated_data["steps"]
    for i, step in enumerate(steps):
        node_id = f"step_{step['step_id']}"

        # ë…¸ë“œ ìƒ‰ìƒ (ìƒíƒœë³„)
        color = {
            "completed": "#4CAF50",
            "failed": "#F44336",
            "running": "#2196F3",
            "pending": "#9E9E9E"
        }.get(step["status"], "#9E9E9E")

        nodes.append({
            "id": node_id,
            "label": f"{step['agent']}\n{step['description'][:30]}...",
            "type": step["agent"],
            "status": step["status"],
            "color": color,
            "metadata": {
                "result": step["result"],
                "confidence": step["confidence"]
            }
        })

        # ì—£ì§€ ìƒì„± (ì´ì „ ë‹¨ê³„ â†’ í˜„ì¬ ë‹¨ê³„)
        if i == 0:
            edges.append({
                "source": "start",
                "target": node_id,
                "label": ""
            })
        else:
            edges.append({
                "source": f"step_{steps[i-1]['step_id']}",
                "target": node_id,
                "label": ""
            })

    # END ë…¸ë“œ
    nodes.append({
        "id": "end",
        "label": "END",
        "type": "end",
        "color": "#4CAF50"
    })

    if steps:
        edges.append({
            "source": f"step_{steps[-1]['step_id']}",
            "target": "end",
            "label": ""
        })

    # ì¸ì‚¬ì´íŠ¸ë¥¼ ì£¼ì„ ë…¸ë“œë¡œ ì¶”ê°€
    for insight in aggregated_data["insights"]:
        if insight["importance"] > 0.7:  # ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ë§Œ
            # ê´€ë ¨ ë‹¨ê³„ì— ì£¼ì„ ë…¸ë“œ ì—°ê²°
            for step_id in insight["related_steps"]:
                annotation_id = f"insight_{step_id}_{insight['category']}"
                nodes.append({
                    "id": annotation_id,
                    "label": insight["description"][:50] + "...",
                    "type": "insight",
                    "color": "#FF9800"
                })
                edges.append({
                    "source": f"step_{step_id}",
                    "target": annotation_id,
                    "label": "insight",
                    "style": "dashed"
                })

    graph_data = {
        "nodes": nodes,
        "edges": edges,
        "metadata": {
            "total_steps": len(steps),
            "completed": aggregated_data["execution_summary"]["completed_steps"],
            "failed": aggregated_data["execution_summary"]["failed_steps"]
        }
    }

    return {
        "final_result": graph_data,
        "messages": []  # ê·¸ë˜í”„ëŠ” ë©”ì‹œì§€ ë¶ˆí•„ìš”
    }
```

**Frontend ì˜ˆì‹œ** (JSON ì‘ë‹µ):
```json
{
  "nodes": [
    {"id": "start", "label": "START", "type": "start", "color": "#4CAF50"},
    {"id": "step_0", "label": "search\nì§€ë‚œ ë¶„ê¸° ë§¤ì¶œ ë°ì´í„° ê²€ìƒ‰", "type": "search", "status": "completed", "color": "#4CAF50"},
    {"id": "step_1", "label": "validation\në°ì´í„° ìœ íš¨ì„± ê²€ì¦", "type": "validation", "status": "completed", "color": "#4CAF50"},
    {"id": "step_2", "label": "hitl\në°ì´í„° í™•ì¸ ìŠ¹ì¸ ìš”ì²­", "type": "hitl", "status": "completed", "color": "#4CAF50"},
    {"id": "insight_0_trend", "label": "ì˜¨ë¼ì¸ ë§¤ì¶œ 35% ì¦ê°€...", "type": "insight", "color": "#FF9800"},
    {"id": "end", "label": "END", "type": "end", "color": "#4CAF50"}
  ],
  "edges": [
    {"source": "start", "target": "step_0"},
    {"source": "step_0", "target": "step_1"},
    {"source": "step_1", "target": "step_2"},
    {"source": "step_0", "target": "insight_0_trend", "style": "dashed"},
    {"source": "step_2", "target": "end"}
  ]
}
```

---

### 3.3 Report Generator (ë¬¸ì„œ ìƒì„±)

**ëª©ì **: Markdown/PDF ë³´ê³ ì„œ ìƒì„± (ì „ë¬¸ì„± ê·¹ëŒ€í™”)

```python
# backend/app/octostrator/nodes/generators/report_generator.py

from datetime import datetime
from backend.app.octostrator.states.supervisor_state import SupervisorState


async def report_generator_node(state: SupervisorState) -> dict:
    """Report Generator - Markdown ë³´ê³ ì„œ ìƒì„±

    Frontend: Markdown ë Œë”ë§ ë˜ëŠ” PDF ë³€í™˜
    """
    aggregated_data = state["aggregated_data"]

    # Markdown ë³´ê³ ì„œ ìƒì„±
    report = f"""# ë¶„ì„ ë³´ê³ ì„œ

**ìƒì„± ì¼ì‹œ**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
**ìš”ì²­ ë‚´ìš©**: {aggregated_data['metadata']['user_intent']}

---

## ğŸ“‹ ìš”ì•½

{aggregated_data['final_answer']}

---

## ğŸ“Š ì‹¤í–‰ í†µê³„

| í•­ëª© | ìˆ˜ì¹˜ |
|------|------|
| ì´ ì‹¤í–‰ ë‹¨ê³„ | {aggregated_data['execution_summary']['total_steps']}ê°œ |
| ì™„ë£Œëœ ë‹¨ê³„ | {aggregated_data['execution_summary']['completed_steps']}ê°œ |
| ì‹¤íŒ¨í•œ ë‹¨ê³„ | {aggregated_data['execution_summary']['failed_steps']}ê°œ |
| ì‚¬ìš©ì ìŠ¹ì¸ | {aggregated_data['execution_summary']['hitl_interactions']}íšŒ |
| ì´ ì‹¤í–‰ ì‹œê°„ | {aggregated_data['execution_summary']['execution_time']:.2f}ì´ˆ |

---

## ğŸ” ìƒì„¸ ì‹¤í–‰ ë‚´ì—­

"""

    # ê° ë‹¨ê³„ë³„ ìƒì„¸ ë‚´ì—­
    for step in aggregated_data["steps"]:
        status_emoji = {
            "completed": "âœ…",
            "failed": "âŒ",
            "running": "ğŸ”„",
            "pending": "â³"
        }.get(step["status"], "â“")

        report += f"""
### {status_emoji} Step {step['step_id']}: {step['description']}

- **Agent**: `{step['agent']}`
- **ìƒíƒœ**: {step['status']}
- **ì‹ ë¢°ë„**: {step['confidence'] * 100:.1f}%

**ì‹¤í–‰ ê²°ê³¼**:
```
{step['result']}
```

"""

        # ê·¼ê±° ìë£Œê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if step.get('evidence'):
            report += "**ê·¼ê±° ìë£Œ**:\n"
            for evidence in step['evidence']:
                report += f"- {evidence}\n"
            report += "\n"

    # ì¸ì‚¬ì´íŠ¸ ì„¹ì…˜
    report += "\n---\n\n## ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸\n\n"

    # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
    insights_by_category = {}
    for insight in aggregated_data["insights"]:
        category = insight["category"]
        if category not in insights_by_category:
            insights_by_category[category] = []
        insights_by_category[category].append(insight)

    category_names = {
        "trend": "ğŸ“ˆ íŠ¸ë Œë“œ",
        "anomaly": "âš ï¸ ì´ìƒ ì§•í›„",
        "recommendation": "âœ… ê¶Œì¥ ì‚¬í•­"
    }

    for category, category_name in category_names.items():
        if category in insights_by_category:
            report += f"\n### {category_name}\n\n"
            for insight in sorted(insights_by_category[category], key=lambda x: x['importance'], reverse=True):
                report += f"- **[ì¤‘ìš”ë„: {insight['importance']:.1%}]** {insight['description']}\n"
                if insight['related_steps']:
                    report += f"  - ê´€ë ¨ ë‹¨ê³„: {', '.join(f'Step {s}' for s in insight['related_steps'])}\n"
            report += "\n"

    # ê²°ë¡ 
    report += """
---

## ğŸ“Œ ê²°ë¡ 

"""
    report += aggregated_data['final_answer']

    report += """

---

*ì´ ë³´ê³ ì„œëŠ” Octostrator Planning-Based Multi-Agent Systemì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
"""

    return {
        "final_result": report,
        "messages": []
    }
```

**Frontend ì˜ˆì‹œ** (Markdown ë Œë”ë§):

```
# ë¶„ì„ ë³´ê³ ì„œ

ìƒì„± ì¼ì‹œ: 2025-11-03 14:30:45
ìš”ì²­ ë‚´ìš©: ì§€ë‚œ ë¶„ê¸° ë§¤ì¶œ ë¶„ì„ í›„ ì „ë…„ ë™ê¸° ëŒ€ë¹„ ë¹„êµí•˜ê³  ë³´ê³ ì„œ ì‘ì„±í•´ì¤˜

---

## ğŸ“‹ ìš”ì•½

ì§€ë‚œ ë¶„ê¸° ë§¤ì¶œì€ ì „ë…„ ëŒ€ë¹„ 15% ì¦ê°€í–ˆìœ¼ë©°...

---

## ğŸ“Š ì‹¤í–‰ í†µê³„

| í•­ëª© | ìˆ˜ì¹˜ |
|------|------|
| ì´ ì‹¤í–‰ ë‹¨ê³„ | 9ê°œ |
| ì™„ë£Œëœ ë‹¨ê³„ | 9ê°œ |
...
```

---

## 4. Conditional Router ì„¤ê³„

**ëª©ì **: ì‚¬ìš©ì ìš”ì²­/ì„¤ì •ì— ë”°ë¼ ì ì ˆí•œ Generator ì„ íƒ

```python
# backend/app/octostrator/nodes/router.py

from langgraph.types import Command
from backend.app.octostrator.states.supervisor_state import SupervisorState


async def output_router_node(state: SupervisorState) -> Command:
    """Output Router - ì¶œë ¥ í˜•ì‹ì— ë”°ë¼ ì ì ˆí•œ Generatorë¡œ ë¼ìš°íŒ…

    state["output_format"]ì— ë”°ë¼ ë¶„ê¸°:
    - "chat": chat_generator
    - "graph": graph_generator
    - "report": report_generator
    - "all": ëª¨ë“  Generator ì‹¤í–‰ (ë³‘ë ¬)
    """
    output_format = state.get("output_format", "chat")  # ê¸°ë³¸ê°’: chat

    if output_format == "chat":
        return Command(goto="chat_generator")
    elif output_format == "graph":
        return Command(goto="graph_generator")
    elif output_format == "report":
        return Command(goto="report_generator")
    elif output_format == "all":
        # TODO Phase 4: ë³‘ë ¬ ì‹¤í–‰ ì§€ì›
        # í˜„ì¬ëŠ” ìˆœì°¨ ì‹¤í–‰
        return Command(goto="chat_generator")
    else:
        # ê¸°ë³¸ê°’
        return Command(goto="chat_generator")
```

---

## 5. Graph í†µí•©

```python
# backend/app/octostrator/supervisor/graph.py

from backend.app.octostrator.nodes.aggregator import aggregator_node
from backend.app.octostrator.nodes.router import output_router_node
from backend.app.octostrator.nodes.generators.chat_generator import chat_generator_node
from backend.app.octostrator.nodes.generators.graph_generator import graph_generator_node
from backend.app.octostrator.nodes.generators.report_generator import report_generator_node


def build_supervisor_graph(context: Optional[AppContext] = None):
    """Supervisor Graph ìƒì„± - Phase 3.5: Aggregator + Generators ì¶”ê°€"""

    # ... ê¸°ì¡´ ì½”ë“œ ...

    # === Phase 3.5: Aggregator + Generators ===

    async def aggregator_wrapper(state: SupervisorState) -> dict:
        return await aggregator_node(state, llm)

    workflow.add_node("aggregator", aggregator_wrapper)
    workflow.add_node("output_router", output_router_node, ends=["chat_generator", "graph_generator", "report_generator"])
    workflow.add_node("chat_generator", chat_generator_node)
    workflow.add_node("graph_generator", graph_generator_node)
    workflow.add_node("report_generator", report_generator_node)

    # === ì—£ì§€ ìˆ˜ì • ===

    # Executorê°€ ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ ì‹œ â†’ Aggregatorë¡œ ì´ë™
    # executor_nodeì˜ END ì¡°ê±´ì„ Aggregatorë¡œ ë³€ê²½
    # (executor_node ë‚´ë¶€ ìˆ˜ì • í•„ìš”)

    workflow.add_edge("aggregator", "output_router")
    workflow.add_edge("chat_generator", END)
    workflow.add_edge("graph_generator", END)
    workflow.add_edge("report_generator", END)

    return workflow.compile()
```

**Executor Node ìˆ˜ì •** (executor.py):

```python
# ê¸°ì¡´:
# return Command(update={"final_result": final_result, "is_executing": False}, goto=END)

# ë³€ê²½:
return Command(
    update={"is_executing": False},
    goto="aggregator"  # END ëŒ€ì‹  Aggregatorë¡œ
)
```

---

## 6. FastAPI ì—”ë“œí¬ì¸íŠ¸ ì˜ˆì‹œ

### 6.1 ì±„íŒ… ì¸í„°í˜ì´ìŠ¤

```python
# backend/app/api/endpoints/chat.py

@router.post("/chat")
async def chat_endpoint(request: ChatRequest):
    """ì¼ë°˜ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤"""
    result = await graph.ainvoke({
        "messages": [HumanMessage(content=request.message)],
        "output_format": "chat"  # Chat Generator ì‚¬ìš©
    })

    return {
        "response": result["final_result"],
        "steps_count": len(result["plan"])
    }
```

### 6.2 ê·¸ë˜í”„ ì‹œê°í™”

```python
# backend/app/api/endpoints/graph_view.py

@router.post("/analyze/graph")
async def graph_view_endpoint(request: AnalysisRequest):
    """ê·¸ë˜í”„ ì‹œê°í™” í˜ì´ì§€ìš©"""
    result = await graph.ainvoke({
        "messages": [HumanMessage(content=request.query)],
        "output_format": "graph"  # Graph Generator ì‚¬ìš©
    })

    # final_resultì— graph_data (nodes, edges) í¬í•¨
    return result["final_result"]
```

### 6.3 ë³´ê³ ì„œ ìƒì„±

```python
# backend/app/api/endpoints/report.py

@router.post("/report/generate")
async def generate_report(request: ReportRequest):
    """ë³´ê³ ì„œ ìƒì„±"""
    result = await graph.ainvoke({
        "messages": [HumanMessage(content=request.query)],
        "output_format": "report"  # Report Generator ì‚¬ìš©
    })

    # Markdownì„ PDFë¡œ ë³€í™˜ (ì„ íƒì‚¬í•­)
    if request.format == "pdf":
        pdf_bytes = markdown_to_pdf(result["final_result"])
        return Response(content=pdf_bytes, media_type="application/pdf")
    else:
        return {"markdown": result["final_result"]}
```

---

## 7. ChatGPT/Geminiì™€ì˜ ì°¨ë³„í™”

| ì¸¡ë©´ | ChatGPT/Gemini | Octostrator |
|------|----------------|-------------|
| **íˆ¬ëª…ì„±** | ë‹µë³€ë§Œ ì œê³µ (ê³¼ì • ìˆ¨ê¹€) | ëª¨ë“  ë‹¨ê³„ ì‹œê°í™” (ê·¸ë˜í”„ ë³´ê¸°) |
| **ì‹ ë¢°ì„±** | ê·¼ê±° ë¶ˆëª…í™• | ê° ë‹¨ê³„ë³„ ê·¼ê±° ìë£Œ ì œê³µ |
| **ë‹¤ì–‘ì„±** | í…ìŠ¤íŠ¸ ë‹µë³€ë§Œ | ì±„íŒ… + ê·¸ë˜í”„ + ë³´ê³ ì„œ |
| **ì „ë¬¸ì„±** | ì¼ë°˜ì  ë‹µë³€ | Agentë³„ ì „ë¬¸ ì˜ì—­ (ë¶„ì„/ë¹„êµ/ê²€ì¦) |
| **í˜‘ì—…** | ì—†ìŒ | HITLë¡œ ì¤‘ê°„ ìŠ¹ì¸ ê°€ëŠ¥ |
| **í™•ì¥ì„±** | ê³ ì •ëœ ëª¨ë¸ | Agent/Tool êµì²´ ê°€ëŠ¥ |

**ì‚¬ìš©ì ê²½í—˜ ì‹œë‚˜ë¦¬ì˜¤**:

1. **ì¼ë°˜ ì‚¬ìš©ì**: ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš© (ChatGPTì™€ ìœ ì‚¬)
2. **ë¶„ì„ê°€**: ê·¸ë˜í”„ í˜ì´ì§€ì—ì„œ ì‹¤í–‰ íë¦„ í™•ì¸ (íˆ¬ëª…ì„±)
3. **ê²½ì˜ì§„**: ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ (PDF) â†’ ê³µìœ  ë° ë³´ê´€

---

## 8. êµ¬í˜„ ìš°ì„ ìˆœìœ„

### Phase 3.5 (í˜„ì¬)
1. âœ… Aggregator Node êµ¬í˜„
2. âœ… Chat Generator êµ¬í˜„ (ê¸°ë³¸)
3. âœ… Conditional Router êµ¬í˜„
4. âœ… Graph í†µí•©

### Phase 3.6 (ë‹¤ìŒ)
1. Graph Generator êµ¬í˜„
2. Report Generator êµ¬í˜„
3. FastAPI ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
4. Frontend ì—°ë™ í…ŒìŠ¤íŠ¸

### Phase 4 (ë¯¸ë˜)
1. ë³‘ë ¬ Generator ì‹¤í–‰ (all ì˜µì…˜)
2. PDF ë³€í™˜ ê¸°ëŠ¥
3. Real-time ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ (WebSocket)
4. ì»¤ìŠ¤í…€ Generator í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ

---

## 9. ê²°ë¡ 

**Aggregator + Generator êµ¬ì¡°ì˜ ì¥ì **:

1. **ì¬ì‚¬ìš©ì„±**: AggregatorëŠ” í•œ ë²ˆë§Œ ì‹¤í–‰, ì—¬ëŸ¬ Generatorê°€ ì¬ì‚¬ìš©
2. **í™•ì¥ì„±**: ìƒˆë¡œìš´ Frontend í˜•ì‹ ì¶”ê°€ ì‹œ Generatorë§Œ ì¶”ê°€
3. **í…ŒìŠ¤íŠ¸**: ê° Generatorë¥¼ ë…ë¦½ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
4. **ì„±ëŠ¥**: Aggregator ê²°ê³¼ë¥¼ ìºì‹±í•˜ì—¬ ì—¬ëŸ¬ í˜•ì‹ ë™ì‹œ ì œê³µ
5. **ì°¨ë³„í™”**: ë‹¤ì–‘í•œ ì¶œë ¥ í˜•ì‹ìœ¼ë¡œ ChatGPT/Geminiì™€ ëª…í™•íˆ êµ¬ë¶„

**ë‹¤ìŒ ë‹¨ê³„**: `nested_graph_hitl_guide.md` ì‘ì„±
